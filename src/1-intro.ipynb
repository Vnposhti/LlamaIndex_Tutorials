{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.readers.file.base.SimpleDirectoryReader at 0x2b820169130>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "docs = SimpleDirectoryReader('../src/data')\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='7392c46d-5b4d-436e-a7c1-b3283f21c096', embedding=None, metadata={'page_label': '1', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\" Breakdown of the Imports:\\n1. import torch – This imports PyTorch, which we’ll use for tensor computations, autograd, and \\nmodel building.\\n2. import torch.nn as nn – This brings in PyTorch’s neural network module (nn), which contains \\nlayers like nn.Linear, nn.Transformer, etc.\\n3. import torch.optim as optim – This imports PyTorch’s optimization library, which helps in training \\nthe model (like Adam, SGD).\\n4. import gzip – This is a built-in Python library to handle .gz compressed files. (Maybe we are \\ndealing with a compressed dataset?)\\n5. import time – Used for measuring execution time, probably for tracking training speed.\\n6. import math – Might be used for mathematical operations like scaling, exponentials, etc. (often \\nused in the Transformer’s positional encoding).\\n7. import spacy – A popular NLP library, often used for tokenization. It helps in processing text (like \\nsplitting sentences into words).\\n8. from torch.utils.data import Dataset, DataLoader –\\n○ Dataset helps define a custom dataset.\\n○ DataLoader is used to load data in batches efficiently.\\n9. from torch.nn.utils.rnn import pad_sequence – Helps pad sequences to the same length \\n(important for batch processing in NLP models).\\n10. from tqdm import tqdm – A progress bar library, used for displaying progress during training or \\ndata processing.\\n What This Tells Us About the Code?\\n• This is an NLP-based Transformer model (because of spacy and pad_sequence).\\n• It will involve batch processing (because of Dataset and DataLoader).\\n• It might be trained from scratch (since we are not importing Hugging Face's Transformer library).\\n• Positional encoding or some math-based scaling might be involved (math library).\\n• The dataset might be compressed (gzip), so we’ll likely load .gz files.\\n Why Use a Compressed .gz File?\\n1.               –  arge te t datasets take up a lot of disk space.  ompressing them reduces \\nstorage re uirements.\\n2. Faster Loading  – Instead of storing raw text, compressed files can be read directly while \\ntraining, reducing I/O overhead.\\n3. Common in NLP Datasets  – Many public datasets (like WikiText, OpenWebText, or large \\ncorpora) come in .gz format to keep downloads manageable.\\n4. Efficient for Streaming ⏳– We can read data in chunks rather than loading everything into \\nmemory at once.\\n Ex m l  of Why It’  U  d:\\n et’s say we have a dataset of 500MB in raw text. If we compress it using .gz, it might become 50MB, \\nmaking it easier to download and load into memory while training.\\n Next: If you share the code where the .gz file is actually being read, I can explain exactly how it's \\nbeing handled! \\n What These Commands Do?\\nSunday, February 2, 2025 6:18 PM\\n   transformer Page 1    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f648df64-0a96-4e99-a75f-bc250606c95f', embedding=None, metadata={'page_label': '2', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=' What These Commands Do?\\n1. !python -m spacy download de_core_news_sm\\n○ Downloads the German (de) small language model for spaCy.\\n○ \"core_news\" means it’s designed for news-style text.\\n○ \"sm\" means small model (faster, but less accurate).\\n2. !python -m spacy download en_core_web_sm\\n○ Downloads the English (en) small language model.\\n○ \"core_web\" means it’s trained on web text (more general-purpose).\\n○ \"sm\" means small model, suitable for lightweight processing.\\n Why Are We Downloading These?\\n• These models help with tokenization, lemmatization, and POS tagging.\\n• In NLP pipelines, we often need to split text into words, remove unnecessary elements, and \\nextract useful features.\\n• Since we are working on a Transformer model, we might need to preprocess text before passing \\nit into the model.\\n Wh t’  N xt?If your code is using spaCy for tokenization, share that part, and I\\'ll explain exactly \\nhow it fits into your Transformer pipeline!  \\n What Does This Code Do?\\nspacy_de = spacy.load(\\'de_core_news_sm\\')\\nspacy_en = spacy.load(\\'en_core_web_sm\\')\\n• This loads the pre-trained spaCy language models for German (de) and English (en).\\n• These models contain pre-trained tokenizers, part-of-speech (POS) taggers, lemmatizers, and \\nnamed entity recognition (NER) systems.\\n• The variable names (spacy_de and spacy_en) indicate that these will be used for processing \\nGerman and English text, respectively.\\n Why Are We Using spaCy?\\nSince we are building a Transformer model, we need to process text before feeding it into the model. \\nspaCy helps us:\\n1. Tokenize Sentences – Converts text into a list of words (tokens).\\n2. Normalize Text – Handles punctuation, special characters, etc.\\n3. Lemmatization (if needed) –  onverts words to their base form (e.g., \"running\" → \"run\").\\n4. Language-Specific Rules – Helps deal with differences in German and English grammar.\\n Example of How spaCy Works\\ntext = \"Hallo, wie geht es dir?\"\\ntokens = [tok.text for tok in spacy_de(text)]\\nprint(tokens)\\nOutput:\\n[\\'Hallo\\', \\',\\', \\'wie\\', \\'geht\\', \\'es\\', \\'dir\\', \\'?\\']\\nAs you can see, it splits the sentence into individual words and punctuation, which is important for NLP \\ntasks.\\n Next Step: Your Transformer code will likely use spaCy for tokenization before converting text into \\nnumerical data (embeddings). If that part is next, send it over, and I\\'ll break it down!   \\n What Does This Code Do?\\n   transformer Page 2    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='55b33995-c5a4-4fd0-b273-d624f524fe2b', embedding=None, metadata={'page_label': '3', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\" What Does This Code Do?\\nSEED = 123\\ntorch.manual_seed(SEED)\\ntorch.backends.cudnn.deterministic = True\\n1. SEED = 123 \\n○ This sets a random seed. In machine learning, using a fixed random seed ensures \\nreproducibility—so every time you run your code, you'll get the same results. It's essential \\nfor debugging and comparing experiments.\\n2. torch.manual_seed(SEED) \\n○ This sets the seed for PyTorch's random number generator. This ensures that any random \\noperations (like weight initialization, shuffling data, etc.) give the same results across runs.\\n○ This is especially useful if you're doing experiments or training models, and you want to \\nmake sure that your results are consistent.\\n3. torch.backends.cudnn.deterministic = True \\n○ This is related to CUDA (GPU). When training on a GPU, some operations can be non-\\ndeterministic (i.e., produce slightly different results each time due to optimization for \\nspeed).\\n○ By setting this flag to True, we make the operations deterministic on NVIDIA GPUs using \\ncuDNN, ensuring the results are exactly the same every time (given the same input, same \\nseed).\\n Why Is This Important?\\n• Reproducibility is a key aspect of machine learning. Setting a fixed seed ensures that: \\n1. If you or anyone else runs the code multiple times, you'll get consistent results (same \\noutput, same metrics).\\n2. Helps debug effectively, because if there’s a bug or performance drop, you can isolate it and \\nknow it's not due to randomness.\\n• CUDA Determinism: When working on GPUs, it's easy to get tiny differences in results because of \\nparallel operations. This setting ensures exact replication of results, making it easier to compare \\nexperiments.\\n Next Step: If you have more code that involves model building or \\ntraining, feel free to share it! I can help explain how all these pieces \\ncome together in the Transformer model.  \\n What Does This Code Do?\\nThis part of the code defines a custom Dataset class called Multi30kDataset. This class is responsible for \\nloading, transforming, and providing access to the data in a convenient way for training the model.\\n1. class Multi30kDataset(Dataset):\\n• This is creating a custom dataset class that inherits from torch.utils.data.Dataset, which is the \\nstandard way of working with datasets in PyTorch.\\n• The Multi30k dataset is likely related to machine translation, where the source and target \\nlanguages are provided in separate files.\\n2. def __init__(self, src_file, trg_file, src_transform=None, trg_transform=None):\\n• Constructor to initialize the dataset. \\n○ src_file: Path to the source language file (e.g., German).\\n○ trg_file: Path to the target language file (e.g., English).\\n○ src_transform: Optional transformation for the source sentences (like tokenization or \\npadding).\\ntrg_transform: Optional transformation for the target sentences.\\n   transformer Page 3    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='bad7ee9f-8397-49c7-aca1-22da2107d17c', embedding=None, metadata={'page_label': '4', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='○ trg_transform: Optional transformation for the target sentences.\\n3. self.src_data = self.load_data(src_file) and self.trg_data = self.load_data(trg_file)\\n• Loading the Data: \\n○ The function load_data is called for both the source (src_file) and target (trg_file) data files.\\n○ The gzip.open method reads the compressed files (.gz format), and the data is loaded line-\\nby-line as a list of sentences.\\n○ The strip() method removes any unnecessary whitespace or newline characters from the \\nsentences.\\n4. def load_data(self, file_path):\\n• This method opens and reads the contents of the dataset files.\\n• The dataset is expected to be one sentence per line in the .gz compressed files.\\n5. def __len__(self):\\n• Returns the length of the dataset, i.e., the number of source sentences (assuming source and \\ntarget files are of equal length).\\n6. def __getitem__(self, idx):\\n• The getitem method allows us to index into the dataset and get a specific item (sentence pair) by \\nits index idx.\\n• It returns a dictionary with: \\n○ \"src\": The source sentence.\\n○ \"trg\": The target sentence.\\n• Transforms: If any transformations (like tokenization, lowercasing, or padding) were provided, \\nthey are applied to both the source and target sentences before returning them.\\n Why Is This Important?\\n1. Custom Dataset Class: This class makes it easy to work with custom data by using PyTorch’s \\nDataLoader. The dataset can be used in training loops, and since it supports transformations, you \\ncan preprocess data (like tokenization or padding) before it reaches the model.\\n2. Efficient Data Handling:\\n○ The data is read line by line from a compressed file, saving both disk space and loading \\ntime.\\n○ By using gzip and transformations, you ensure that the data is ready for feeding into a \\nneural network without extra overhead.\\n3. Language Pairs: This is likely part of a machine translation task where the source language (e.g., \\nGerman) is mapped to a target language (e.g., English).\\n Next Step:\\nIf you\\'re using this dataset for a Transformer, you\\'ll likely need to tokenize these sentences and convert \\nthem into numerical formats (like word IDs). If there\\'s more code, share it, and I can help explain how \\neverything fits together!  \\nSteps to Run the Code:\\n1. Install the Required Libraries:\\n○ You need torch and spaCy for this to work. Install them using pip if you haven’t already: \\npip install torch spacy tqdm\\n2. Download the Language Models:\\n○ Download the language models as per your earlier code: \\npython -m spacy download de_core_news_sm\\npython -m spacy download en_core_web_sm\\n3. Prepare Sample Data:\\n○ If you don’t have the actual .gz files (src_file and trg_file), you can create dummy text files\\nfor testing: \\n   transformer Page 4    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='69a74af0-200c-4f3d-9995-8d9461dbe8b1', embedding=None, metadata={'page_label': '5', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"for testing: \\n▪ Create two simple text files src.txt (for German) and trg.txt (for English).\\n▪ Put a few sentences in each file to simulate the dataset (e.g., German sentence in \\nsrc.txt and corresponding English sentence in trg.txt).\\n4. Code for Testing the Dataset:\\n○ Here’s how you can test it with sample files: \\nimport torch\\nimport spacy\\nfrom torch.utils.data import DataLoader\\n# Load the language models\\nspacy_de = spacy.load('de_core_news_sm')\\nspacy_en = spacy.load('en_core_web_sm')\\n# Define a simple transformation (e.g., tokenize)\\ndef tokenize_de(sentence):\\n    return [token.text for token in spacy_de(sentence)]\\ndef tokenize_en(sentence):\\n    return [token.text for token in spacy_en(sentence)]\\n# Assuming you have `src.txt` and `trg.txt` files\\nsrc_file = 'src.txt'  # Replace with actual path\\ntrg_file = 'trg.txt'  # Replace with actual path\\n# Create the dataset\\ndataset = Multi30kDataset(src_file, trg_file, src_transform=tokenize_de, \\ntrg_transform=tokenize_en)\\n# Create a DataLoader to batch and shuffle the dataset\\ndata_loader = DataLoader(dataset, batch_size=2, shuffle=True)\\n# Fetch one batch of data\\nfor batch in data_loader:\\n    print(batch)\\n5. Run the Code:\\n○ Run the script in your Python environment. It will: \\n1. Load the dataset.\\n2. Apply tokenization using spaCy.\\n3. Print out a batch of tokenized sentences.\\nExpected Output:\\nAfter running the script, you should see output like this (example with a batch size of 2):\\n{'src': [['Hallo', ',', 'wie', 'geht', 'es', 'dir', '?'], ['Guten', 'Morgen', '!']], 'trg': [['Hello', ',', 'how', 'are', 'you', \\n'?'], ['Good', 'morning', '!']]}\\n Tip:\\nIf you encounter issues, feel free to share the error message here, and I'll help you debug it!\\n What These Functions Do?\\ndef tokenize_de(text):\\n    return [token.text.lower() for token in spacy_de.tokenizer(text)]\\n   transformer Page 5    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='47440797-be04-4c3e-92bf-e6a0f1d16040', embedding=None, metadata={'page_label': '6', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='    return [token.text.lower() for token in spacy_de.tokenizer(text)]\\ndef tokenize_en(text):\\n    return [token.text.lower() for token in spacy_en.tokenizer(text)]\\n1. tokenize_de(text)\\n• This function takes a German text (text) as input and processes it through the spaCy tokenizer for \\nGerman (spacy_de).\\n• .tokenizer(text): Tokenizes the sentence into individual words or subword units based on spaCy’s \\nbuilt-in rules.\\n• .lower(): Converts every token to lowercase, ensuring that the model doesn’t treat words like \\n\"Hello\" and \"hello\" as separate entities. This can help in reducing vocabulary size and improving \\ngeneralization.\\n2. tokenize_en(text)\\n• This is the same as tokenize_de, but it works for English text using the English tokenizer \\n(spacy_en).\\n Why Lowercasing?\\n• Consistency: Lowercasing makes sure that the model doesn\\'t treat words with different cases \\n(e.g., \"Apple\" and \"apple\") as separate entities. This is particularly useful for small datasets or \\nwhen you don\\'t want to overfit to the case of words.\\n• Simplification: Helps reduce the size of the vocabulary, as the model doesn’t have to learn \\nseparate embeddings for upper- and lowercase versions of the same word.\\n Example:\\nLet\\'s assume we pass a sentence like \"Hallo, Wie geht es dir?\" through tokenize_de and \"Hello, how are \\nyou?\" through tokenize_en.\\n# Test tokenization\\ngerman_text = \"Hallo, Wie geht es dir?\"\\nenglish_text = \"Hello, how are you?\"\\nprint(tokenize_de(german_text))  # Output: [\\'hallo\\', \\',\\', \\'wie\\', \\'geht\\', \\'es\\', \\'dir\\', \\'?\\']\\nprint(tokenize_en(english_text))  # Output: [\\'hello\\', \\',\\', \\'how\\', \\'are\\', \\'you\\', \\'?\\']\\nNext Step:\\nIf you\\'re using these functions in your Multi30kDataset class (as the transform functions), your dataset \\nwill now return tokenized and lowercase sentences. If you have more parts of the code (like padding, \\nbatch processing, or model definitions), feel free to share them! I\\'ll help explain how they all work \\ntogether.  \\n What Does This Code Do?\\n1. Loading Datasets:\\ntrain_data = Multi30kDataset(train_de_path, train_en_path, src_transform=tokenize_de, \\ntrg_transform=tokenize_en)\\nval_data = Multi30kDataset(val_de_path, val_en_path, src_transform=tokenize_de, \\ntrg_transform=tokenize_en)\\ntest_data = Multi30kDataset(test_de_path, test_en_path, src_transform=tokenize_de, \\ntrg_transform=tokenize_en)\\n• Loading Datasets: \\n○ These lines are creating three instances of the Multi30kDataset class for the training, \\nvalidation, and test datasets.\\n○ train_de_path, train_en_path: These variables store the paths to the German and English\\ntraining data files (same for validation and test data).\\n○ src_transform=tokenize_de: This applies the tokenize_de function to the German \\nsentences. This means every sentence in the source language will be tokenized into \\nindividual words and converted to lowercase.\\n   transformer Page 6    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='fa508c27-f9ab-4b63-8508-5a1baeb708c4', embedding=None, metadata={'page_label': '7', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='individual words and converted to lowercase.\\n○ trg_transform=tokenize_en: Similarly, the tokenize_en function is applied to the English \\nsentences.\\nResult: After loading the dataset, the Multi30kDataset class will return a list of tokenized \\nsentences in both German and English when you index into it.\\n2. Defining Special Tokens:\\nPAD_TOKEN = \\'<pad>\\'\\nSOS_TOKEN = \\'<sos>\\'\\nEOS_TOKEN = \\'<eos>\\'\\nUNK_TOKEN = \\'<unk>\\'\\nThese lines define special tokens that will be used during the model training and tokenization process. \\nLet\\'s break them down:\\n1. PAD_TOKEN = \\'<pad>\\':\\n○ This is the padding token. Padding is used when sentences of varying lengths are batched \\ntogether for training.\\n○ The model uses the padding token to \"fill in\" shorter sequences, so all sequences in the \\nbatch are of equal length (usually the length of the longest sentence in the batch).\\n2. SOS_TOKEN = \\'<sos>\\':\\n○ This stands for Start Of Sequence. It is typically added at the beginning of a sequence in \\nsequence-to-sequence models (like machine translation) to signal the start of the target \\nsentence.\\n○ In machine translation, the model generates tokens one by one, starting with the <sos> \\ntoken.\\n3. EOS_TOKEN = \\'<eos>\\':\\n○ This stands for End Of Sequence. It is used to mark the end of a generated sequence.\\n○ When the model predicts the <eos> token, it stops generating further tokens.\\n4. UNK_TOKEN = \\'<unk>\\':\\n○ This stands for Unknown. It\\'s used when the model encounters a word that is not in its \\nvocabulary.\\n○ The model replaces any unknown or rare words with this token, preventing errors during \\nprocessing.\\n Why Are These Special Tokens Important?\\n• Padding (<pad>): Ensures that all sequences in a batch have the same length, making them easier \\nto process in parallel. It\\'s ignored by the model during training.\\n• Start and End Tokens (<sos>, <eos>): These help the model know when to start and stop \\ngenerating output. It’s essential for training and testing models like machine translation or \\nsummarization.\\n• Unknown Token (<unk>): This is a fallback mechanism to handle out-of-vocabulary (OOV) words, \\npreventing the model from crashing or producing nonsense if it encounters an unseen word \\nduring inference.\\n Next Step:\\nNow that you’ve set up your dataset and special tokens, you’ll likely need to build a vocabulary and \\nconvert these tokens into numerical IDs for training the model. Let me know if you want me to walk you \\nthrough that process, or if you need help with any other part of the code!  \\n What Does This Function Do?\\nThis function builds a vocabulary from a list of tokenized sentences. The vocabulary maps each unique \\ntoken (word) to a unique index. Additionally, it ensures that the special tokens (like <pad>, <sos>, etc.) \\nare included in the vocabulary.\\n   transformer Page 7    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4f968278-465f-4073-9468-bc9beb3839bb', embedding=None, metadata={'page_label': '8', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"are included in the vocabulary.\\nHere’s the code you shared:\\ndef create_vocab(tokenized_sentences, special_tokens):\\n    vocab = {token: idx for idx, token in enumerate(special_tokens)}  # Step 1\\n    \\n    for sentence in tokenized_sentences:  # Step 2\\n        for token in sentence:\\n            if token not in vocab:  # Step 3\\n                vocab[token] = len(vocab)  # Step 4\\n    return vocab\\nStep-by-Step Explanation:\\n1. Initialize Vocabulary with Special Tokens:\\nvocab = {token: idx for idx, token in enumerate(special_tokens)}\\n○ This initializes the vocabulary with the special tokens that you defined earlier (<pad>, <sos>, \\n<eos>, <unk>).\\n○ enumerate(special_tokens) gives each token an index starting from 0. The special tokens are \\nassigned indices in the order in which they appear in the special_tokens list.\\nFor example, if special_tokens = ['<pad>', '<sos>', '<eos>', '<unk>'], the initial vocabulary \\nwould look like this:\\nvocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\\n2. Iterate Over the Tokenized Sentences:\\nfor sentence in tokenized_sentences:\\n    for token in sentence:\\n○ The function loops through each sentence in the tokenized_sentences list, where each \\nsentence is a list of tokens (words).\\n○ For each sentence, it iterates over the individual tokens (words).\\n3. Add New Tokens to Vocabulary:\\nif token not in vocab:\\n    vocab[token] = len(vocab)\\n○ This checks if a token is not already in the vocabulary. If it's a new token (that wasn’t in the \\noriginal list of special tokens), it assigns the token a unique index.\\n○ The index is the current length of the vocabulary, ensuring that each new token gets a \\nunique ID that’s one greater than the previous token’s index.\\nExample:\\nLet’s say you have the following tokenized sentence:\\ntokenized_sentences = [['hello', 'world'], ['how', 'are', 'you']]\\nInitially, the vocabulary is:\\nvocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\\nAfter processing all the sentences, the vocabulary will become:\\nvocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3, 'hello': 4, 'world': 5, 'how': 6, 'are': 7, \\n'you': 8}\\n4. Return the Vocabulary:\\nreturn vocab\\n○ Finally, the function returns the completed vocabulary, which contains both the special \\ntokens and any additional tokens found in the sentences.\\n Why Is This Function Important?\\n• Mapping Words to Indices: Neural networks work with numerical data, so you need to convert \\nwords into numbers. This vocabulary serves as a lookup table for converting tokens into indices \\nand vice versa.\\n   transformer Page 8    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8288ff90-f499-40b7-bfd9-55647dabd13e', embedding=None, metadata={'page_label': '9', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"and vice versa.\\n• Handling Special Tokens: Special tokens like <pad>, <sos>, etc., are crucial for sequence \\nprocessing. Padding ensures sequences are of equal length, and the start and end tokens help \\nwith generation tasks.\\n• Extending Vocabulary: The function also allows you to dynamically add any new words that \\nappear in the training data to the vocabulary. This is useful for models that need to handle out-of-\\nvocabulary words.\\n Next Step:\\nOnce you have this vocabulary, you'll need to convert both the source and target sentences into \\nsequences of indices (numerical representation) before passing them to the model. Let me know if you \\nwant to move forward with that part or if you have any more questions!  \\n What is Positional Encoding?\\nTransformers don't have recurrence (like RNNs) or any notion of sequence order. To help them \\nunderstand the order of words in a sequence, we add positional encodings to the input embeddings.\\nEach position in the sequence gets a unique sinusoidal (sine & cosine) encoding.\\n Step-by-Step Breakdown\\nHere's the code you shared:\\nclass PositionalEncoding(nn.Module):\\n    def __init__(self, d_model, max_len=1000):\\n        super().__init__()\\n• This is a PyTorch module (nn.Module), meaning it can be used like a layer in a neural network.\\n• d_model: The embedding size (how many features per token).\\n• max_len: Maximum length of input sequences. Default is 1000, meaning we assume a sentence \\ncan be at most 1000 tokens long.\\n      t     o   o  l E  od      t  x\\npe = torch.zeros(max_len, d_model)\\n• Creates a max_len × d_model matrix filled with zeros.\\n• Each row represents a position (1st word, 2nd word, etc.).\\n• Each column represents a dimension of the embedding.\\n        t   o   o  I d    \\nposition = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\\n• torch.arange(0, max_len) creates a vector of positions: [0, 1, 2, ..., max_len-1]\\n• .unsqueeze(1) changes its shape from [max_len] → [ma _len, 1], making it a column vector.\\nExample for max_len=5:\\nposition = [[0],  \\n            [1],  \\n            [2],  \\n            [3],  \\n            [4]]\\n   om  t          y    l       m\\ndiv_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\\n• This calculates different frequency scales for sine and cosine functions.\\n• The 10000.0 factor helps distribute values smoothly.\\n• The arange(0, d_model, 2) selects every even index (for sine) and every odd index (for cosine).\\n   transformer Page 9    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='6ca99dcc-f0c1-49d3-8aeb-180b877f2a00', embedding=None, metadata={'page_label': '10', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"• The arange(0, d_model, 2) selects every even index (for sine) and every odd index (for cosine).\\nExample when d_model=6:\\n[0, 2, 4]  → for sine\\n[1, 3, 5]  → for cosine\\nEach position gets different sinusoidal values based on these scales.\\n     ly         o    \\npe[:, 0::2] = torch.sin(position * div_term)  # Even indices → sine\\npe[:, 1::2] = torch.cos(position * div_term)  # Odd indices → cosine\\n• Even columns (0, 2, 4, …) get sine values.\\n• Odd columns (1, 3, 5, …) get cosine values.\\n• This ensures different frequencies for different dimensions, giving a rich encoding.\\nExample output for first 3 positions (d_model=6):\\nPosition 0: [ 0.000,  1.000,  0.000,  1.000,  0.000,  1.000]\\nPosition 1: [ 0.841,  0.540,  0.909,  0.416,  0.951,  0.309]\\nPosition 2: [ 0.909, -0.416,  0.755, -0.655,  0.588, -0.809]\\n• Notice how sine values oscillate between -1 and 1 as the position increases.\\n     h      d  to           \\npe = pe.unsqueeze(0).transpose(0, 1)\\n• .unsqueeze(0): Adds a batch dimension → [1, ma _len, d_model]\\n• .transpose(0, 1): Swaps first two dimensions → [ma _len, 1, d_model] \\n○ This helps in adding positional encoding across batches.\\nself.register_buffer('pe', pe)\\n• register_buffer stores pe inside the model, but it won't be updated during training (since it's not \\na learnable parameter).\\n   o    d     \\ndef forward(self, x):\\n    return x + self.pe[:x.size(0), :]\\n• Takes x (word embeddings) as input.\\n• Adds the positional encoding (pe[:x.size(0), :]) to it.\\n• The x.size(0) ensures we only take the first N positions corresponding to the input length.\\n Why Use Sin & Cos Functions?\\n1. Periodic Nature: Words at similar positions get similar encodings, helping the model learn \\nposition-related patterns.\\n2. Unique Representation: Each position has a distinct encoding due to different sine & cosine \\nfrequencies.\\n3. Extrapolation: Unlike learned embeddings, sinusoidal encodings can generalize to unseen lengths.\\n Summary\\n• This adds positional information to word embeddings in a Transformer model.\\n• Uses sinusoidal encodings (sine for even, cosine for odd).\\n• Stored as a buffer so it doesn't update during training.\\n• During forward(), adds positional encodings to input embeddings.\\n What's Next?\\n   transformer Page 10    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='772b9db4-473c-490d-b7bd-8dd33cf61f11', embedding=None, metadata={'page_label': '11', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\" What's Next?\\nThis is a key part of Transformer models. If you're building an encoder-decoder model, next you'll likely \\ndefine the embedding layer and self-attention mechanism. Let me know if you need help with that!  \\n Example: Understanding Positional Encoding\\nLet's manually run the PositionalEncoding class for a small example and see how it modifies an \\nembedding.\\nStep 1: Define Positional Encoding Class (Same as Before)\\nimport torch\\nimport math\\nimport torch.nn as nn\\nclass PositionalEncoding(nn.Module):\\n    def __init__(self, d_model, max_len=10):  # Keeping max_len small for easy understanding\\n        super().__init__()\\n        pe = torch.zeros(max_len, d_model)\\nposition = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # Shape: [max_len, 1]\\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\\npe[:, 0::2] = torch.sin(position * div_term)  # Apply sin to even indices\\n        pe[:, 1::2] = torch.cos(position * div_term)  # Apply cos to odd indices\\npe = pe.unsqueeze(0)  # Shape becomes [1, max_len, d_model] (for batch compatibility)\\n        self.register_buffer('pe', pe)\\ndef forward(self, x):\\n        return x + self.pe[:x.size(1), :]\\nStep 2: Create a Dummy Input\\nLet’s assume we have a sentence with 5 words, and each word is represented by a 4-dimensional \\nembedding (d_model=4).\\n# Define embedding size\\nd_model = 4\\nmax_len = 10  # Maximum sentence length\\n# Create Positional Encoding Layer\\npos_encoder = PositionalEncoding(d_model, max_len)\\n# Create a dummy embedding for a 5-word sentence (batch size = 1, seq_len = 5, d_model = 4)\\ndummy_embedding = torch.zeros(1, 5, d_model)  # Shape: [batch, seq_len, d_model]\\n# Apply positional encoding\\nencoded_embedding = pos_encoder(dummy_embedding)\\nprint(encoded_embedding)\\n Step 3: Understanding the Output\\nBefore Positional Encoding (Original dummy_embedding):\\n[[[0.0000, 0.0000, 0.0000, 0.0000],  # Word 1\\n  [0.0000, 0.0000, 0.0000, 0.0000],  # Word 2\\n  [0.0000, 0.0000, 0.0000, 0.0000],  # Word 3\\n  [0.0000, 0.0000, 0.0000, 0.0000],  # Word 4\\n  [0.0000, 0.0000, 0.0000, 0.0000]]] # Word 5\\nSince it was initialized with all zeros, each word starts with no unique information.\\nAfter Applying Positional Encoding:\\n[[[ 0.0000,  1.0000,  0.0000,  1.0000],  # Position 0\\n  [ 0.8415,  0.5403,  0.0909,  0.9959],  # Position 1\\n   transformer Page 11    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4a2cda1d-1a27-48a1-ba21-2be43b90da91', embedding=None, metadata={'page_label': '12', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='  [ 0.8415,  0.5403,  0.0909,  0.9959],  # Position 1\\n  [ 0.9093, -0.4161,  0.1818,  0.9839],  # Position 2\\n  [ 0.1411, -0.9900,  0.2727,  0.9640],  # Position 3\\n  [-0.7568, -0.6536,  0.3636,  0.9361]]] # Position 4\\n Wh t’  H         H   ?\\n• The values are no longer zeros; each word in the sequence now has a unique positional encoding.\\n• Even indices (0, 2) → Sinusoidal values (sin function).\\n• Odd indices (1, 3) → Cosine values (cos function).\\n• Patterns emerge in the position encodings, which the Transformer uses to understand word \\norder.\\n Summary\\n1. Before: All embeddings were zero, meaning no positional information.\\n2. After: Each word got a unique position-based modification, allowing the Transformer to \\ndifferentiate between positions.\\n3. Now, when these encoded embeddings go into the self-attention mechanism, the model \\nunderstands their relative positions without recurrence.\\n Next Steps\\nNow that we have positional encodings, the next steps in a Transformer would be: ✅Word \\nEmbeddings (instead of zero vectors).\\n✅Self-Attention Mechanism.\\n✅Feed-Forward Network.\\n Code for forward() Function\\ndef forward(self, x):\\n    return x + self.pe[:x.size(0), :]\\n Breakdown Step-by-Step\\n  x    th  I   t Em  dd   \\ndef forward(self, x):\\n• x yaha ek word embedding tensor hoga.\\n• Shape: [seq_len, batch_size, d_model] \\n○ seq_len = Kitne words hain sequence me\\n○ batch_size = Kitne sentences ek saath pass ho rahe hain\\n○ d_model = Embedding size (jitne features per word)\\nFor example, agar ek batch me 3 sentences hain, har ek 5 words ka aur embedding size 4 hai, to x ka \\nshape hoga:\\nx.shape = [5, 3, 4]\\nMtlb:\\n• 5 words per sentence\\n• 3 sentences ek saath\\n• 4-dimensional embeddings per word\\n   dd  o   o  l E  od   \\nreturn x + self.pe[:x.size(0), :]\\n• self.pe positional encoding matrix hai (size [max_len, 1, d_model]).\\n• x.size(0) mtlb jitna x ka sequence length hoga utna hi pe ka part select hoga.\\n   transformer Page 12    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='96b53d13-6ac1-40da-aa24-1f8afe0ecfcb', embedding=None, metadata={'page_label': '13', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='• x.size(0) mtlb jitna x ka sequence length hoga utna hi pe ka part select hoga.\\n• Broadcasting hoti hai, yani har batch ke liye positional encoding automatically apply ho jata hai.\\n Example Run\\nAgar x ek random embedding ho:\\nx = torch.tensor([\\n    [ [1.0, 2.0, 3.0, 4.0] ],  # Word 1\\n    [ [5.0, 6.0, 7.0, 8.0] ],  # Word 2\\n    [ [9.0, 10.0, 11.0, 12.0] ] # Word 3\\n])  # Shape: [3, 1, 4] (3 words, batch=1, 4 features per word)\\nAur positional encoding pe kuch aisa ho:\\npe = [\\n    [ 0.0,  1.0,  0.0,  1.0],  # Position 1\\n    [ 0.8,  0.5,  0.1,  0.9],  # Position 2\\n    [ 0.9, -0.4,  0.2,  0.8]   # Position 3\\n]  # Shape: [3, 1, 4]\\nTo final output hoga:\\nx + pe = [\\n    [ 1.0+0.0,  2.0+1.0,  3.0+0.0,  4.0+1.0 ],  # Word 1\\n    [ 5.0+0.8,  6.0+0.5,  7.0+0.1,  8.0+0.9 ],  # Word 2\\n    [ 9.0+0.9, 10.0-0.4, 11.0+0.2, 12.0+0.8 ]   # Word 3\\n]\\nFinal Result:\\n[\\n    [1.0, 3.0, 3.0, 5.0],\\n    [5.8, 6.5, 7.1, 8.9],\\n    [9.9, 9.6, 11.2, 12.8]\\n]\\n Summary\\n✅x hota hai word embeddings.\\n✅self.pe hota hai precomputed positional encodings.\\n✅x + self.pe[:x.size(0), :] har word embedding me positional encoding add kar deta hai.\\n✅Ye model ko word ka position samjhne me madad karta hai bina recurrence ke!\\n Multi-Head Attention Overview\\n Attention ka kaam kya hai?\\n Ye decides karta hai ki input ke kaunse words important hai while processing a sentence.\\n Multi-Head Attention ka kya fayda hai?\\n Ek hi input me multiple attention mechanisms parallelly kaam karte hain to capture different \\nrelationships.\\n   o  t   to        t      I    l    o \\nclass MultiHeadAttention(nn.Module):\\n    def __init__(self, d_model, num_heads):\\n        super().__init__()\\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\\nself.d_model = d_model\\n        self.num_heads = num_heads\\n        self.d_k = d_model // num_heads  # Each head ka dimension\\n   transformer Page 13    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b78ea85e-05c7-4b25-86fb-89793ca403c8', embedding=None, metadata={'page_label': '14', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='        self.d_k = d_model // num_heads  # Each head ka dimension\\nself.W_q = nn.Linear(d_model, d_model)  # Query matrix\\n        self.W_k = nn.Linear(d_model, d_model)  # Key matrix\\n        self.W_v = nn.Linear(d_model, d_model)  # Value matrix\\n        self.W_o = nn.Linear(d_model, d_model)  # Final output linear layer\\n Explanation\\n1. d_model → Input embedding ka size (usually 512 or 768).\\n2. num_heads → Kitne attention heads chahiye (e.g. 8 heads).\\n3. Each head ke liye dimension:\\nself.d_k = d_model // num_heads  # e.g. 512/8 = 64\\nHar head ka size d_k hota hai (64 in this case).\\n4. W_q, W_k, W_v → Ye Query (Q), Key (K), aur Value (V) vectors generate karte hain.\\n○ Query (Q) → Kis word ko dhyan dena hai?\\n○ Key (K) → Kaunse words important hai?\\n○ Value (V) → Actual information jo pass hogi.\\n     l d dot   od  t      o       om  t       o \\ndef scaled_dot_product_attention(self, Q, K, V, mask=None):\\n    attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\\n    if mask is not None:\\n        attn_scores = attn_scores.masked_fill(mask == 0, -1e9)  # Ignore padding tokens\\nattn_probs = torch.softmax(attn_scores, dim=-1)  # Normalize scores\\n    output = torch.matmul(attn_probs, V)  # Multiply with Values\\n    return output\\n Explanation\\n1. Dot Product between Q and K\\nattn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\\n○ Query aur Key ka dot product le rahe hain.\\n○ Scaling factor 1/sqrt(d_k) ensure karta hai ki values stable rahe (NaN na aaye).\\n2. Apply Mask (if needed)\\nif mask is not None:\\n    attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\\n○ Padding ya future words ignore karne ke liye mask use hota hai.\\n3. Softmax Normalization\\nattn_probs = torch.softmax(attn_scores, dim=-1)\\n○ Ye probability distribution generate karta hai.\\n4. Multiply with Values\\noutput = torch.matmul(attn_probs, V)\\n○ Important words ki values ko weightage milta hai.\\n  fo    d      om l t   lo \\ndef forward(self, Q, K, V, mask=None):\\n    batch_size = Q.size(0)\\nQ = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\\n    K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\\n    V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\\noutput = self.scaled_dot_product_attention(Q, K, V, mask)\\noutput = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\\n    return self.W_o(output)\\n Explanation\\n   transformer Page 14    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='28e732bb-d22b-47a5-b332-a8b6634faf14', embedding=None, metadata={'page_label': '15', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=' Explanation\\n1. Q, K, V Generate\\nQ = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\\n○ W_q(Q): Query generate kiya\\n○ .view(...): Multi-heads me reshape kiya\\n○ .transpose(1, 2): Batch aur heads swap kiya (shape [batch, heads, seq_len, d_k] ban gaya)\\n2. Apply Scaled Dot Product Attention\\noutput = self.scaled_dot_product_attention(Q, K, V, mask)\\n○ Ye attention weights calculate karke values multiply karta hai.\\n3. Concatenate Multi-Heads\\noutput = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\\n○ Heads ko combine karke wapas ek single vector banaya.\\n○ .contiguous() memory ko optimize karta hai.\\n4. Final Linear Layer\\nreturn self.W_o(output)\\n○ Ye final output layer hai jo next transformer block me jayega.\\n Example - Running Multi-Head Attention\\n# Define Attention layer\\nmha = MultiHeadAttention(d_model=8, num_heads=2)\\n# Dummy Input (batch=1, seq_len=4, d_model=8)\\nx = torch.rand(1, 4, 8)\\n# Run forward pass\\noutput = mha(x, x, x)\\nprint(output.shape)  # Output: [1, 4, 8]\\n What Happens Here?\\n1. Q, K, V banega (embedding ke liye projection layer lagegi).\\n2. Multi-head attention compute hoga (scaled dot-product attention).\\n3. Concatenation hoke final output milega (size d_model ka hi hoga).\\n Summary\\nStep Explanation\\n1. Q, K, V Generate Input embeddings ko query, key, aur value vectors me map \\nkiya\\n2. Dot-Product Attention Q aur K ka dot product leke attention scores nikala\\n3. Softmax & Value Multiplication Softmax apply kiya aur V ke saath multiply kiya\\n4. Multi-Heads Apply Multiple heads ko parallelly apply kiya\\n5. Concatenation & Output Linear \\nLayer\\nHeads ka output combine karke linear layer se pass kiya\\n Final Thoughts\\n✅Multi-Head Attention se model ek hi sentence me multiple relationships detect kar sakta hai!\\n✅Ye Transformer ka most important layer hai, jo self-attention ko enhance karta hai.\\n✅Iske bina Transformer properly kaam nahi karega.\\n Example Sentence\\n   transformer Page 15    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e7020f88-8394-467b-9b6a-5c611ef616e2', embedding=None, metadata={'page_label': '16', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=' Example Sentence\\n Suppose, we have this English sentence:\\n\"The cat sat on the mat.\"\\n                                              \\nHar word ek vector ban jayega (embedding size = 8).\\nMaan lo, word embeddings kuch aise hain:\\nWord Embedding (Size 8)\\n\"The\" [0.1, 0.3, 0.5, ...]\\n\"cat\" [0.2, 0.4, 0.6, ...]\\n\"sat\" [0.7, 0.1, 0.9, ...]\\n\"on\" [0.3, 0.6, 0.8, ...]\\n\"the\" [0.1, 0.3, 0.5, ...]\\n\"mat\" [0.4, 0.7, 0.2, ...]\\nIska tensor representation hoga:\\nimport torch\\n# Batch = 1, Seq_Len = 6, d_model = 8\\nx = torch.rand(1, 6, 8)  # (Random embeddings)\\n      y        y        l         t            t \\nimport torch.nn as nn\\nmha = MultiHeadAttention(d_model=8, num_heads=2)  # 2 heads\\nQ = mha.W_q(x)  # Query\\nK = mha.W_k(x)  # Key\\nV = mha.W_v(x)  # Value\\n  Wh t h      ?\\n• Query (Q): Kis word ko focus karna hai?\\n• Key (K): Kaunse words important hai?\\n• Value (V): Jo actual information pass hogi.\\n   ot   od  t      o     m l   ty   l  l  o  \\nattn_scores = torch.matmul(Q, K.transpose(-2, -1)) / (8 ** 0.5)  \\n  Ex m l    t  t:\\nWord \"The\" \"cat\" \"sat\" \"on\" \"the\" \"mat\"\\nThe 1.0 0.7 0.5 0.3 1.0 0.4\\ncat 0.7 1.0 0.8 0.4 0.7 0.5\\nsat 0.5 0.8 1.0 0.6 0.5 0.7\\non 0.3 0.4 0.6 1.0 0.3 0.8\\nthe 1.0 0.7 0.5 0.3 1.0 0.4\\nmat 0.4 0.5 0.7 0.8 0.4 1.0\\n High Attention Values   S      R la     h  \\n• \"cat\" ne \"sat\" par zyada attention diya (0.8) ✅\\n• \"on\" ne \"mat\" par zyada attention diya (0.8) ✅\\n   o m x   W   ht d   m      l      o    t  t \\n   transformer Page 16    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='adbfeec2-5a5f-4ff4-9aef-1474496dc35e', embedding=None, metadata={'page_label': '17', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='   o m x   W   ht d   m      l      o    t  t \\nimport torch.nn.functional as F\\nattn_probs = F.softmax(attn_scores, dim=-1)  # Normalize\\noutput = torch.matmul(attn_probs, V)\\n  Ex m l   o m x   t  t:\\nWord \"The\" \"cat\" \"sat\" \"on\" \"the\" \"mat\"\\nThe 0.25 0.20 0.15 0.10 0.25 0.05\\ncat 0.20 0.30 0.25 0.10 0.10 0.05\\nsat 0.15 0.25 0.30 0.15 0.05 0.10\\non 0.10 0.10 0.15 0.35 0.10 0.20\\nthe 0.25 0.20 0.15 0.10 0.25 0.05\\nmat 0.05 0.05 0.10 0.20 0.05 0.55\\nKaise interpret kare?\\n• \"cat\" ka focus zyada hai \"sat\" (0.25) aur khud par (0.30)\\n• \"on\" ka focus \"mat\" (0.20) aur khud par (0.35)\\n  Yahi reason hai ki Self-Attention sentence me relationships ko samajhne me madad karta hai!\\n    l  H  d      o       ll l H  d  \\nEk attention multiple heads me parallelly kaam karta hai.\\n 1st Head → Focuses on subject-object relations\\n 2nd Head → Focuses on positional dependencies\\noutput = output.view(1, 6, 8)  # Merge heads\\nfinal_output = mha.W_o(output)  # Final linear layer\\n Final Output bhi 8-dimension ka hota hai (same as input size).\\n Summary\\nStep Explanation\\n1. Create Q, K, V Words ko Query, Key, aur Value vectors me convert kiya\\n2. Dot-Product Attention Words ka similarity score calculate kiya\\n3. Softmax Normalize Scores ko probabilities me convert kiya\\n4. Weighted Sum with Values Important words ka final output nikala\\n5. Multi-Head Attention Multiple perspectives add kiye\\n Real-World Use Case\\n   a h      a  la      a  l      l  h       a  \\nEnglish Input: \"The cat sat on the mat.\"\\nGerman Output: \"Die Katze saß auf der Matte.\"\\nMulti-Head Attention ensure karega ki: ✅\"The\" ka attention \"Die\" par ho\\n✅\"cat\" ka attention \"Katze\" par ho\\n✅\"sat\" ka a         \" aß\"  a  h \\n Without Attention, ye alignment problematic ho sakti thi.  \\n Final Thoughts\\n✅Multi-Head Attention Transformer ka core hai!\\n   transformer Page 17    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='10a790e5-5165-4b89-bd06-8e554e694b9d', embedding=None, metadata={'page_label': '18', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='✅Multi-Head Attention Transformer ka core hai!\\n✅Words ke relationships detect karne me help karta hai.\\n✅Ye Self-Attention ko aur powerful banata hai.\\nClass Overview:\\nThe feedforward network is an important component of the Transformer architecture. It is applied \\nindependently to each position in the sequence (hence \"position-wise\"). This means that the same \\nfeedforward neural network is applied to each token in the sequence, one at a time, without any \\ninteraction between them.\\nNow, let\\'s dive into the code:\\nclass PositionwiseFeedforward(nn.Module):\\n    def __init__(self, d_model, d_ff):\\n        super().__init__()\\n        self.fc1 = nn.Linear(d_model, d_ff)  # First linear layer\\n        self.fc2 = nn.Linear(d_ff, d_model)  # Second linear layer\\n        self.relu = nn.ReLU()  # ReLU activation function\\ndef forward(self, x):\\n        return self.fc2(self.relu(self.fc1(x)))  # Apply two linear layers with ReLU activation\\nExplanation of Code:\\n1. Constructor (__init__ method):\\n○ d_model: This is the dimensionality of the input (and output) of the model. In the \\nTransformer, this corresponds to the size of the input vector for each token.\\n○ d_ff: This is the dimensionality of the intermediate layer in the feedforward network, i.e., \\nhow many neurons there will be in the hidden layer between the two linear \\ntransformations.\\nThe feedforward network consists of two linear layers:\\n○ self.fc1: The first linear transformation takes the input of dimension d_model and \\ntransforms it to the higher dimensional space of d_ff.\\n○ self.fc2: The second linear transformation projects the result from d_ff back to d_model.\\n○ self.relu: A ReLU activation function is applied between the two linear transformations. This \\nintroduces non-linearity into the model, which is crucial for learning complex patterns.\\n1. Forward Method:\\n○ The forward method defines how the input tensor x (which is passed through this layer) is \\nprocessed.\\n○ Flow:\\n1. The input x passes through the first linear layer fc1, which transforms the input from \\nd_model dimensions to d_ff dimensions.\\n2. The output of fc1 is passed through the ReLU activation function (self.relu). This step \\nadds non-linearity to the transformation.\\n3. Then, the activated output is passed through the second linear layer fc2, which brings \\nit back to the original dimension d_model.\\nSo, this feedforward layer takes the input, applies a transformation, adds non-\\nlinearity, and transforms it again back to the original dimension.\\nRole of Positionwise Feedforward in Transformer:\\nIn the Transformer model:\\n• This position-wise feedforward layer is applied independently to each token (or position) in the \\nsequence.\\n• The reason it\\'s called \"position-wise\" is that each token is treated separately and is transformed \\nindependently of the others, unlike the attention layers, which allow tokens to attend to each \\n   transformer Page 18    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4611a9e2-15bf-402e-9373-af165e09db4c', embedding=None, metadata={'page_label': '19', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"independently of the others, unlike the attention layers, which allow tokens to attend to each \\nother.\\nThis operation is repeated for each token in the sequence after the multi-head attention block. This \\nallows each token to have its representation refined.\\nSummary:\\n• PositionwiseFeedforward is a simple two-layer feedforward network used in the Transformer.\\n• It processes each token's representation independently, applying a non-linear transformation.\\n• It consists of two linear layers with a ReLU activation function between them.\\nLet me know if you need more details or examples on this!  \\nThis class EncoderLayer represents one layer of the encoder in the Transformer model. The encoder \\nlayer is the building block of the transformer encoder, and it consists of two main components: a multi-\\nhead self-attention layer and a position-wise feedforward layer.\\nLet's break down the code step by step.\\nClass Breakdown:\\nclass EncoderLayer(nn.Module):\\n    def __init__(self, d_model, num_heads, d_ff, dropout):\\n        super().__init__()\\n        self.self_attn = MultiHeadAttention(d_model, num_heads)  # Multi-head attention layer\\n        self.feed_forward = PositionwiseFeedforward(d_model, d_ff)  # Position-wise feedforward layer\\n        self.norm1 = nn.LayerNorm(d_model)  # Layer normalization for the first component (attention)\\n        self.norm2 = nn.LayerNorm(d_model)  # Layer normalization for the second component \\n(feedforward)\\n        self.dropout = nn.Dropout(dropout)  # Dropout to prevent overfitting\\ndef forward(self, x, mask):\\n        # Step 1: Self-attention\\n        attn_output = self.self_attn(x, x, x, mask)  # Query, Key, Value all come from 'x' (self-attention)\\n        x = self.norm1(x + self.dropout(attn_output))  # Apply residual connection, dropout, and \\nnormalization\\n# Step 2: Feedforward layer\\n        ff_output = self.feed_forward(x)  # Apply position-wise feedforward network\\n        x = self.norm2(x + self.dropout(ff_output))  # Apply residual connection, dropout, and normalization\\nreturn x\\nExplanation of Components:\\n1. self.self_attn = MultiHeadAttention(d_model, num_heads)\\n○ This initializes the multi-head attention layer. It takes the input x (which represents the \\ntokens' embeddings) as the query, key, and value. The self-attention mechanism allows \\neach token to attend to all other tokens in the sequence.\\n2. self.feed_forward = PositionwiseFeedforward(d_model, d_ff)\\n○ This initializes the position-wise feedforward layer. It is applied after the attention \\nmechanism, independently to each token, as explained earlier.\\n3. self.norm1 = nn.LayerNorm(d_model)\\n○ Layer normalization is applied after the self-attention block. Layer normalization helps \\nstabilize and speed up training by normalizing the activations.\\n○ It ensures that the output of the attention layer has zero mean and unit variance across \\neach batch.\\n4. self.norm2 = nn.LayerNorm(d_model)\\n○ Similarly, layer normalization is applied after the feedforward layer for stability.\\n5. self.dropout = nn.Dropout(dropout)\\nDropout is a regularization technique applied to the outputs of the attention and \\n   transformer Page 19    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='23cc4249-e09f-49b7-9dc6-02d5669dfc39', embedding=None, metadata={'page_label': '20', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"○ Dropout is a regularization technique applied to the outputs of the attention and \\nfeedforward layers to prevent overfitting during training. dropout is the probability of \\nsetting a unit to zero during training.\\nForward Method:\\nThe forward method defines how the data flows through the encoder layer. Here's how it works:\\n1. Self-Attention:\\n○ The input x passes through the multi-head attention mechanism (self.self_attn(x, x, x, \\nmask)).\\n○ The mask can be used to prevent certain tokens from attending to others (e.g., padding \\ntokens or future tokens).\\n○ The result of the attention (attn_output) is then added to the original input x as a residual \\nconnection. This allows the model to learn both the attention output and the original input \\nin parallel.\\n○ Dropout is applied to the attention output, and then layer normalization is applied on top \\nof the sum (x + attn_output).\\n2. Feedforward Layer:\\n○ The output from the attention mechanism (after normalization) passes through the \\nposition-wise feedforward layer (self.feed_forward(x)).\\n○ Again, a residual connection is applied by adding the original input x to the output of the \\nfeedforward layer. This helps the network retain information from earlier stages.\\n○ Dropout is applied again, and layer normalization is done on the final output.\\n3. Return:\\n○ The final output x after the attention and feedforward operations is returned, which is \\npassed to the next layer of the encoder (or used for further processing, depending on the \\narchitecture).\\nSummary:\\n• The EncoderLayer consists of two main components:\\n1. Self-Attention: Helps the model focus on different parts of the input sequence.\\n2. Feedforward Layer: Processes each token independently after attention.\\n• Residual Connections: After each of the two operations, the input is added to the output (residual \\nconnection). This helps with gradient flow during backpropagation and prevents \\nvanishing/exploding gradients.\\n• Layer Normalization: Normalizes the output after each operation (attention and feedforward) for \\nstable training.\\n• Dropout: Applied to prevent overfitting during training.\\nThis architecture is repeated in the encoder stack, with each layer applying self-attention and \\nfeedforward processing.\\nThis class DecoderLayer implements a decoder layer for the Transformer model. The decoder in the \\nTransformer consists of three main components:\\n1. Self-attention mechanism (similar to the encoder but with a mask to prevent future tokens from \\nattending to previous ones)\\n2. Cross-attention mechanism (to attend to the encoder's output)\\n3. Feedforward layer (applied independently to each position in the sequence)\\nLet's break down the code step by step to understand how it works.\\nClass Breakdown:\\nclass DecoderLayer(nn.Module):\\n    def __init__(self, d_model, num_heads, d_ff, dropout):\\n        super().__init__()\\n        self.self_attn = MultiHeadAttention(d_model, num_heads)  # Self-attention mechanism\\n        self.cross_attn = MultiHeadAttention(d_model, num_heads)  # Cross-attention mechanism\\n   transformer Page 20    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='1c34b811-bb5c-4b74-a7c8-5132e5f0fbd8', embedding=None, metadata={'page_label': '21', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"        self.cross_attn = MultiHeadAttention(d_model, num_heads)  # Cross-attention mechanism\\n        self.feed_forward = PositionwiseFeedforward(d_model, d_ff)  # Feedforward network\\n        self.norm1 = nn.LayerNorm(d_model)  # Layer normalization after self-attention\\n        self.norm2 = nn.LayerNorm(d_model)  # Layer normalization after cross-attention\\n        self.norm3 = nn.LayerNorm(d_model)  # Layer normalization after feedforward\\n        self.dropout = nn.Dropout(dropout)  # Dropout to prevent overfitting\\ndef forward(self, x, enc_output, src_mask, trg_mask):\\n        # Step 1: Self-attention (using the target sequence with masking)\\n        attn_output = self.self_attn(x, x, x, trg_mask)  # Query, Key, Value = x (self-attention)\\n        x = self.norm1(x + self.dropout(attn_output))  # Apply residual connection, dropout, and \\nnormalization\\n# Step 2: Cross-attention (using the encoder output with source masking)\\n        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)  # Query = x, Key/Value = \\nencoder output\\n        x = self.norm2(x + self.dropout(attn_output))  # Apply residual connection, dropout, and \\nnormalization\\n# Step 3: Feedforward layer\\n        ff_output = self.feed_forward(x)  # Apply position-wise feedforward network\\n        x = self.norm3(x + self.dropout(ff_output))  # Apply residual connection, dropout, and normalization\\nreturn x\\nExplanation of Components:\\n1. self.self_attn = MultiHeadAttention(d_model, num_heads):\\n○ This initializes the multi-head self-attention layer. It processes the target sequence (x) to \\nallow the model to attend to all previous tokens in the sequence (during training) while \\npreventing attending to future tokens (via masking).\\n○ This step ensures that during training, the model doesn't cheat by looking at future tokens.\\n2. self.cross_attn = MultiHeadAttention(d_model, num_heads):\\n○ This is the cross-attention mechanism. Here, the model attends to the output of the \\nencoder (enc_output) while processing the target sequence (x).\\n○ The query comes from the target sequence (x), while the key and value come from the \\nencoder's output (enc_output).\\n○ This mechanism allows the decoder to focus on relevant parts of the input (source) \\nsequence.\\n3. self.feed_forward = PositionwiseFeedforward(d_model, d_ff):\\n○ This is the position-wise feedforward network, applied to each token independently, as \\ndescribed in previous explanations.\\n○ This component is responsible for learning more complex representations after the \\nattention steps.\\n4. self.norm1, self.norm2, self.norm3:\\n○ Layer normalization is applied after each of the three steps: \\n1. After self-attention (to normalize the result of self-attention)\\n2. After cross-attention (to normalize the result of cross-attention)\\n3. After the feedforward network (to normalize the output of the feedforward network)\\n○ This normalization helps stabilize training and allows for faster convergence.\\n5. self.dropout:\\n○ Dropout is applied to prevent overfitting during training. It randomly sets some values to \\nzero in the output, forcing the model to generalize better.\\nForward Method:\\nThe forward method defines the data flow through the decoder layer. Here's how it works:\\n1. Self-Attention:\\nThe input x (the target sequence) passes through the self-attention mechanism.\\n   transformer Page 21    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='523d422c-6f89-49f0-8548-2ceb6209177a', embedding=None, metadata={'page_label': '22', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"○ The input x (the target sequence) passes through the self-attention mechanism.\\n○ The trg_mask (target mask) is used to prevent attending to future tokens during training, \\nensuring that the model predicts each token only using previous tokens (auto-regressive \\nproperty).\\n○ After applying the attention, a residual connection is added (x + attn_output), followed by \\ndropout and layer normalization.\\n2. Cross-Attention:\\n○ The output of the self-attention mechanism (after normalization) is passed to the cross-\\nattention mechanism.\\n○ Here, the encoder output (enc_output) is used as the key and value, while the target \\nsequence (x) is used as the query.\\n○ This allows the decoder to focus on relevant parts of the source (input) sequence.\\n○ Again, a residual connection, followed by dropout and layer normalization, is applied.\\n3. Feedforward Layer:\\n○ The output of the cross-attention mechanism (after normalization) passes through the \\nposition-wise feedforward network.\\n○ This further refines the representations for each token in the sequence.\\n○ A final residual connection, followed by dropout and layer normalization, is applied.\\n4. Return:\\n○ The final output x is returned, which represents the processed target sequence after \\nattention and feedforward processing. This output is passed to the next decoder layer (or \\nthe output layer if it's the last decoder layer).\\nSummary:\\n• Self-Attention: Allows the decoder to focus on relevant tokens in the target sequence while \\nensuring that future tokens aren't attended to (via masking).\\n• Cross-Attention: Allows the decoder to attend to relevant parts of the source sequence (from the \\nencoder).\\n• Feedforward Layer: Refines the representations of each token independently.\\n• Residual Connections: Help with gradient flow and prevent vanishing/exploding gradients.\\n• Layer Normalization: Stabilizes the training by normalizing the output at each stage.\\n• Dropout: Prevents overfitting by randomly setting values to zero during training.\\nThis architecture is repeated across multiple decoder layers to process and refine the target sequence's \\nrepresentation. Each decoder layer refines the sequence based on both the target sequence (via self-\\nattention) and the source sequence (via cross-attention).\\nThis code defines the Transformer model, which is the complete architecture that combines the encoder \\nand decoder layers with additional components such as embeddings, positional encoding, and the final \\noutput layer.\\nClass Breakdown:\\n__init__ Method:\\nThis method initializes all the components of the Transformer model, including embeddings, positional \\nencoding, layers, and final output layer.\\ndef __init__(self, src_vocab_size, trg_vocab_size, d_model, num_heads, num_layers, d_ff, \\nmax_seq_length, dropout):\\n    super().__init__()\\n    \\n    # Embeddings for source and target sequences\\n    self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)  # Source sequence embedding\\n    self.decoder_embedding = nn.Embedding(trg_vocab_size, d_model)  # Target sequence embedding\\n    \\n    # Positional encoding to add positional information to the embeddings\\n    self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\\n   transformer Page 22    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f22d37ed-ada0-4778-9e4d-4588c832f236', embedding=None, metadata={'page_label': '23', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='    self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\\n    \\n    # Stacks of encoder and decoder layers\\n    self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in \\nrange(num_layers)])\\n    self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in \\nrange(num_layers)])\\n    \\n    # Final output layer (to produce predictions for each token)\\n    self.fc_out = nn.Linear(d_model, trg_vocab_size)\\n    \\n    # Dropout to prevent overfitting\\n    self.dropout = nn.Dropout(dropout)\\n    \\n    # Scaling factor for the embeddings\\n    self.scale = torch.sqrt(torch.FloatTensor([d_model]))\\nExplanation of Each Component:\\n1. encoder_embedding and decoder_embedding:\\n○ These are embedding layers for the source (src) and target (trg) sequences. These layers \\ntransform input tokens (words) into dense vector representations of size d_model.\\n2. positional_encoding:\\n○ Positional Encoding is added to the embeddings to incorporate the order of tokens in the \\nsequence. Since the Transformer doesn’t inherently have any sense of order, this encoding \\nadds information about the position of each token in the sequence.\\n3. encoder_layers and decoder_layers:\\n○ These are lists of encoder and decoder layers, which are instances of the EncoderLayer and \\nDecoderLayer classes, respectively. The number of layers in the encoder and decoder is \\ndetermined by num_layers.\\n4. fc_out:\\n○ This is a fully connected layer that maps the output of the decoder to the target vocabulary \\nsize (trg_vocab_size). It produces logits for each word in the vocabulary at each position in \\nthe sequence.\\n5. dropout:\\n○ A dropout layer is used for regularization, which randomly drops a proportion of neurons \\nduring training to prevent overfitting.\\n6. scale:\\n○ The embeddings are scaled by a factor of the square root of the model dimension \\n(d_model). This scaling helps stabilize the training.\\ngenerate_mask Method:\\ndef generate_mask(self, src, trg):\\n    # Mask for the source sequence (to ignore padding tokens in the source)\\n    src_mask = (src != SRC_VOCAB[PAD_TOKEN]).unsqueeze(1).unsqueeze(2)\\n    \\n    # Mask for the target sequence (to ignore padding tokens in the target)\\n    trg_mask = (trg != TRG_VOCAB[PAD_TOKEN]).unsqueeze(1).unsqueeze(3)\\n    \\n    # Create a \"no-peak\" mask for the target sequence (to prevent attending to future tokens in the \\ndecoder)\\n    seq_length = trg.shape[1]\\n    nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\\n    trg_mask = trg_mask & nopeak_mask  # Combine padding mask and no-peak mask\\n    \\n    return src_mask, trg_mask\\n   transformer Page 23    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='808a7ae9-6b1a-41ee-b194-63087b7fdcb7', embedding=None, metadata={'page_label': '24', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"    return src_mask, trg_mask\\n• src_mask: This mask ensures that padding tokens in the source sequence are ignored during \\nattention computation in both the encoder and decoder.\\n• trg_mask: This mask ensures that padding tokens in the target sequence are ignored during \\nattention computation in the decoder.\\n• nopeak_mask: This mask ensures that during training, the decoder can only attend to earlier \\npositions and not future positions in the target sequence (causing the model to generate tokens in \\nan auto-regressive manner). It's a key part of the causal masking in the decoder.\\nforward Method:\\ndef forward(self, src, trg):\\n    src_mask, trg_mask = self.generate_mask(src, trg)\\n    \\n    # Embedding and positional encoding for the source and target sequences\\n    src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src) * self.scale))\\n    trg_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(trg) * self.scale))\\n    \\n    # Encoder forward pass\\n    enc_output = src_embedded\\n    for enc_layer in self.encoder_layers:\\n        enc_output = enc_layer(enc_output, src_mask)\\n    \\n    # Decoder forward pass\\n    dec_output = trg_embedded\\n    for dec_layer in self.decoder_layers:\\n        dec_output = dec_layer(dec_output, enc_output, src_mask, trg_mask)\\n    \\n    # Final output (logits for each token in the target sequence)\\n    output = self.fc_out(dec_output)\\n    return output\\n1. Generate Masks:\\n○ The generate_mask function is called to create masks for the source and target sequences.\\n2. Embedding and Positional Encoding:\\n○ The input src (source) and trg (target) sequences are first passed through their respective \\nembedding layers and then multiplied by the scaling factor (scale).\\n○ Positional encoding is added to the embeddings to introduce information about the position \\nof each token in the sequence.\\n○ Dropout is applied for regularization.\\n3. Encoder Forward Pass:\\n○ The embedded source sequence is passed through the stack of encoder layers. The \\nsrc_mask ensures that padding tokens are ignored during attention calculations.\\n4. Decoder Forward Pass:\\n○ The embedded target sequence is passed through the stack of decoder layers.\\n○ Both the encoder output (enc_output) and the masks (src_mask and trg_mask) are passed \\nto the decoder layers.\\n5. Final Output:\\n○ The decoder output is passed through the final fully connected layer (fc_out) to produce \\nthe logits for each token in the target vocabulary.\\n○ These logits are used to predict the next token in the sequence.\\nSummary:\\n• The Transformer model consists of embedding layers for both the source and target sequences, \\npositional encoding, and a stack of encoder and decoder layers.\\n• The generate_mask function creates the necessary masks to ignore padding and prevent the \\n   transformer Page 24    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8805232e-3503-418b-b19e-e81313da17ec', embedding=None, metadata={'page_label': '25', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"• The generate_mask function creates the necessary masks to ignore padding and prevent the \\nmodel from attending to future tokens during training.\\n• The forward pass involves embedding the input sequences, passing them through the encoder and \\ndecoder layers, and producing logits for the target sequence.\\nThis Transformer model can be trained to perform tasks like machine translation, where the goal is to \\ntranslate a source sentence into a target sentence.\\nLet's break down the code step by step:\\nOptimizer Definition:\\noptimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\\n• optim.Adam: This is the Adam optimizer used for training the model. Adam is an adaptive \\nlearning rate optimization algorithm that computes individual learning rates for different \\nparameters based on the first and second moments of the gradients.\\n• model.parameters(): This refers to the parameters of the model (which is your Transformer \\nmodel). These are the weights and biases that will be optimized during training.\\n• lr=0.0001: This is the learning rate, which controls how much the model's weights are adjusted \\nwith respect to the loss gradient. A smaller learning rate can lead to more stable training but may \\ntake longer to converge.\\n• betas=(0.9, 0.98): These are the beta values used in the calculation of running averages for the \\nfirst and second moments of the gradients. In Adam, beta1 (0.9) is typically used for the moving \\naverage of the first moment (mean), and beta2 (0.98) is used for the second moment (uncentered \\nvariance).\\n• eps=1e-9: This is a small constant added to avoid division by zero during the computation of the \\nlearning rate update. It's a safeguard to ensure stability.\\nLoss Function Definition:\\nPAD_IDX = SRC_VOCAB[PAD_TOKEN]\\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\\n• PAD_IDX = SRC_VOCAB[PAD_TOKEN]: \\n○ This gets the index of the padding token (<pad>) in the source vocabulary (SRC_VOCAB). \\nPadding tokens are used to make all sentences in a batch have the same length, but they \\ndon't contribute to the actual content of the sentence.\\n• criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX): \\n○ CrossEntropyLoss is a commonly used loss function for multi-class classification tasks. In the \\ncontext of sequence generation (like translation), it computes the loss for each predicted \\ntoken (logits) against the true token labels in the target sequence.\\n○ ignore_index=PAD_IDX: This ensures that padding tokens (which do not carry any \\nmeaningful information) are ignored during the loss calculation. That means if the model \\npredicts a padding token, it won’t contribute to the loss and won't affect training.\\nSummary:\\n• The Adam optimizer is used to update the parameters of the Transformer model during training \\nwith an appropriate learning rate and gradient moment settings.\\n• The CrossEntropyLoss is used to measure the performance of the model by comparing its \\npredictions to the actual target sequence. Padding tokens are ignored during loss computation to \\nensure that they don't negatively affect the model's training.\\nWith this setup, you can now proceed to train the model by using these components.\\nLet's break down the code step by step:\\nCollate Function for DataLoader:\\ndef collate_fn(batch):\\n    src_batch, trg_batch = [], []\\n    for sample in batch:\\n        src_batch.append(torch.tensor([SRC_VOCAB.get(token, SRC_VOCAB[UNK_TOKEN]) for token in \\n   transformer Page 25    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='35d354fc-bc8b-46b6-8c25-6bd0de7c4bbe', embedding=None, metadata={'page_label': '26', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='        src_batch.append(torch.tensor([SRC_VOCAB.get(token, SRC_VOCAB[UNK_TOKEN]) for token in \\n[SOS_TOKEN] + sample[\\'src\\'] + [EOS_TOKEN]]))\\n        trg_batch.append(torch.tensor([TRG_VOCAB.get(token, TRG_VOCAB[UNK_TOKEN]) for token in \\n[SOS_TOKEN] + sample[\\'trg\\'] + [EOS_TOKEN]]))\\nsrc_batch = pad_sequence(src_batch, padding_value=SRC_VOCAB[PAD_TOKEN])\\n    trg_batch = pad_sequence(trg_batch, padding_value=TRG_VOCAB[PAD_TOKEN])\\nreturn src_batch.transpose(0, 1), trg_batch.transpose(0, 1)\\n• Purpose: This is a collate function used by the DataLoader to batch the data.\\n○ It takes a list of individual samples (each containing source and target sentences) and \\nprocesses them into batches.\\n○ Padding: It pads the sequences so that all sequences in the batch are the same length. \\nPadding is done using the <pad> token from the vocabulary.\\n• Steps:\\n○ Add special tokens: Adds SOS_TOKEN and EOS_TOKEN to the source (src) and target (trg) \\nsentences.\\n○ Convert tokens to indices: The sentences are converted to indices using the SRC_VOCAB \\nand TRG_VOCAB vocabularies. If a token is not found, it is replaced with <unk> (unknown \\ntoken).\\n○ Pad sequences: Sequences are padded using pad_sequence so they are all of equal length \\nwithin the batch.\\n○ Return: It returns the padded source and target batches, transposed to fit the model\\'s input \\nrequirements.\\nTraining Function:\\ndef train(model, iterator, optimizer, criterion, clip):\\n    model.train()\\n    epoch_loss = 0\\n    print(len(iterator))\\n    for src, trg in tqdm(iterator, desc=\"Training\", leave=False):\\n        optimizer.zero_grad()\\noutput = model(src, trg[:, :-1])\\noutput_dim = output.shape[-1]\\noutput = output.contiguous().view(-1, output_dim)\\n        trg = trg[:, 1:].contiguous().view(-1)\\nloss = criterion(output, trg)\\nloss.backward()\\ntorch.nn.utils.clip_grad_norm_(model.parameters(), clip)\\noptimizer.step()\\nepoch_loss += loss.item()\\nreturn epoch_loss / len(iterator)\\n• Purpose: This function trains the model for one epoch (one pass through the entire dataset).\\n• Steps:\\n○ Model in training mode: model.train() puts the model in training mode (so dropout layers, \\netc., are active).\\n○ Iterate through batches: For each batch (src, trg), it performs the following: \\n▪ Forward pass: Passes the source and target sequences (excluding the last token in \\ntarget, trg[:, :-1]) through the model.\\n▪ Reshape outputs: The output tensor is reshaped and flattened to calculate the loss for \\neach token.\\n▪ Loss calculation: The loss is calculated using the criterion (CrossEntropyLoss).\\n▪ Backpropagation: The loss is backpropagated, and the model parameters are \\nupdated.\\n▪ Gradient clipping: To avoid exploding gradients, gradient clipping is applied \\n(clip_grad_norm_).\\n   transformer Page 26    ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='cbeecace-e833-4199-8735-5a0bb1513094', embedding=None, metadata={'page_label': '27', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"(clip_grad_norm_).\\n▪ Update weights: The optimizer steps forward and updates the model's weights.\\n○ The function returns the average loss for the epoch.\\nEvaluation Function:\\ndef evaluate(model, iterator, criterion):\\n    model.eval()\\n    epoch_loss = 0\\n    with torch.no_grad():\\n        for i, batch in enumerate(iterator):\\n            src, trg = batch\\noutput = model(src, trg[:, :-1])\\noutput_dim = output.shape[-1]\\noutput = output.contiguous().view(-1, output_dim)\\n            trg = trg[:, 1:].contiguous().view(-1)\\nloss = criterion(output, trg)\\nepoch_loss += loss.item()\\nreturn epoch_loss / len(iterator)\\n• Purpose: This function evaluates the model performance on the validation or test set. It's similar \\nto the training loop but without backpropagation.\\n• Steps:\\n○ Model in evaluation mode: model.eval() sets the model to evaluation mode (disables \\ndropout).\\n○ Iterate through validation/test batches: For each batch, it calculates the loss the same way \\nas in training, but without updating model weights (no backpropagation).\\n○ No gradient computation: torch.no_grad() disables the computation of gradients, which \\nsaves memory and computation time during inference.\\n○ It returns the average loss for the epoch.\\nTranslation Function:\\ndef translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\\n    model.eval()\\ntokens = [SOS_TOKEN] + tokenize_de(sentence) + [EOS_TOKEN]\\nsrc_indexes = [src_vocab.get(token, src_vocab[UNK_TOKEN]) for token in tokens]\\nsrc_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\\nsrc_mask = model.generate_mask(src_tensor, src_tensor)\\nwith torch.no_grad():\\n        enc_src = model.encoder_embedding(src_tensor)\\n        for enc_layer in model.encoder_layers:\\n            enc_src = enc_layer(enc_src, src_mask[0])\\ntrg_indexes = [trg_vocab[SOS_TOKEN]]\\nfor i in range(max_len):\\n        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\\ntrg_mask = model.generate_mask(src_tensor, trg_tensor)\\nwith torch.no_grad():\\n            output = model.decoder_embedding(trg_tensor)\\n            for dec_layer in model.decoder_layers:\\n                output = dec_layer(output, enc_src, src_mask[0], trg_mask[1])\\n            output = model.fc_out(output)\\npred_token = output.argmax(2)[:,-1].item()\\ntrg_indexes.append(pred_token)\\nif pred_token == trg_vocab[EOS_TOKEN]:\\n            break\\n   transformer Page 27    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='6f3147e3-bb89-45f3-96da-190140a2d457', embedding=None, metadata={'page_label': '28', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"            break\\ntrg_tokens = [list(trg_vocab.keys())[list(trg_vocab.values()).index(i)] for i in trg_indexes]\\nreturn trg_tokens[1:-1]\\n• Purpose: This function translates a given sentence from the source language to the target \\nlanguage using the trained model.\\n• Steps:\\n○ Tokenize and prepare source sentence: The source sentence is tokenized, and special \\ntokens (SOS_TOKEN, EOS_TOKEN) are added. It is then converted into token indices using \\nthe src_vocab.\\n○ Generate source mask: A mask is generated to prevent attention to padding tokens during \\nencoding.\\n○ Encoder: The input sequence is passed through the encoder layers.\\n○ Initialize target sequence: The target sequence starts with the SOS_TOKEN.\\n○ Iteratively generate target tokens: The model generates one token at a time. The target \\nsequence is extended by the predicted token.\\n○ Stop at EOS: The process stops when the model predicts the EOS_TOKEN.\\n○ Convert token indices to words: Finally, the indices of the generated tokens are mapped \\nback to words using the target vocabulary.\\nSummary:\\n• Collate Function: Prepares batches by adding special tokens and padding sequences.\\n• Training Function: Trains the model by performing forward passes, loss calculation, \\nbackpropagation, and optimization.\\n• Evaluation Function: Evaluates the model on validation/test data without updating the model \\nparameters.\\n• Translation Function: Uses the trained model to generate translations for a given input sentence.\\nThe vocab (vocabulary) is critical because it is the bridge between words (or tokens) and their \\ncorresponding integer indices, which the model can process. Let's look at where and how the vocab is \\nused:\\nWhere is vocab used in the code?\\n1. In the Collate Function: The vocab is used when preparing the batches of data (in the collate_fn \\nfunction) before passing them into the model.\\nsrc_batch.append(torch.tensor([SRC_VOCAB.get(token, SRC_VOCAB[UNK_TOKEN]) for token in \\n[SOS_TOKEN] + sample['src'] + [EOS_TOKEN]]))\\ntrg_batch.append(torch.tensor([TRG_VOCAB.get(token, TRG_VOCAB[UNK_TOKEN]) for token in \\n[SOS_TOKEN] + sample['trg'] + [EOS_TOKEN]]))\\n○ Explanation: \\n▪ SRC_VOCAB.get(token, SRC_VOCAB[UNK_TOKEN]): For each token in the source \\nsentence (with added SOS_TOKEN and EOS_TOKEN), we look up the token in the \\nSRC_VOCAB dictionary. If the token is not found, we replace it with the <unk> token \\nindex (using SRC_VOCAB[UNK_TOKEN]).\\n▪ TRG_VOCAB.get(token, TRG_VOCAB[UNK_TOKEN]): Similarly, for the target \\nsentence, we look up the token in the TRG_VOCAB dictionary. If the token is not \\nfound, it’s replaced with the <unk> token index.\\n2. During Translation (translate_sentence function): The vocab is used to convert tokens into their \\nrespective indices (before feeding them into the model) and then convert the predicted indices \\nback into tokens.\\nsrc_indexes = [src_vocab.get(token, src_vocab[UNK_TOKEN]) for token in tokens]\\n○ Explanation: The sentence is tokenized, and each token (including SOS_TOKEN and \\nEOS_TOKEN) is converted into an index using src_vocab (for the source language). This is \\nwhat the model understands—numerical representations of words.\\nAfter the model predicts indices (for the target language), we use the target vocab to \\n   transformer Page 28    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='729179ed-47b7-4fae-a665-f616a811afd9', embedding=None, metadata={'page_label': '29', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"After the model predicts indices (for the target language), we use the target vocab to \\nconvert those indices back into words:\\ntrg_tokens = [list(trg_vocab.keys())[list(trg_vocab.values()).index(i)] for i in trg_indexes]\\n○ Explanation: This part maps the predicted target token indices (trg_indexes) back to their \\ncorresponding words using trg_vocab.\\n3. When Training: In the training loop (both train and evaluate functions), vocab is indirectly used in \\nthe loss calculation:\\nloss = criterion(output, trg)\\n○ The output from the model contains predicted indices for the target sequence. These \\npredicted indices are compared to the true target indices (trg) to calculate the loss.\\n○ The vocab (especially TRG_VOCAB) is used to convert tokens to indices before the model \\nprocesses them and to map predicted indices back to tokens during evaluation or \\ntranslation.\\nWhy is vocab important in this context?\\n• Tokens to Indices: The neural network can only process numerical values, so we need to convert \\nwords (tokens) into numerical representations (indices). This conversion is done using vocab.\\n• Handling Unknown Tokens: The vocab allows us to handle unknown words by mapping them to a \\nspecial <unk> token.\\n• Decoding the Output: The model generates indices, and the vocab helps us map those indices \\nback to readable words for evaluation or translation.\\nSummary:\\n• SRC_VOCAB and TRG_VOCAB are used to convert words into indices (before feeding them to the \\nmodel) and convert predicted indices back into words (after the model generates them).\\n• In the collate function, vocab helps prepare the batches.\\n• In the training and evaluation loops, vocab helps convert between tokens and indices to calculate \\nloss.\\n• In the translation function, vocab helps convert tokens into indices before passing them to the \\nmodel and then converts predicted indices back to readable words.\\nThe code you’ve shared implements the training loop for training a Transformer-based model for \\nmachine translation. Let me break it down for you step by step:\\n1. Hyperparameters Setup\\nN_EPOCHS = 1\\nCLIP = 1.0\\nBATCH_SIZE = 32\\n• N_EPOCHS: Number of training epochs (1 in this case). This means the model will go through the \\nentire training data once.\\n• CLIP: The gradient clipping value. This helps avoid exploding gradients by limiting the size of \\ngradients during backpropagation.\\n• BATCH_SIZE: Number of examples in each batch when training.\\n2. Data Loaders\\ntrain_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\\nval_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, collate_fn=collate_fn)\\n• DataLoader: This is used to load the data in batches.\\n○ train_dataloader: Loads the training data in batches of size BATCH_SIZE and shuffles the \\ndata.\\n○ val_dataloader: Loads the validation data in batches. It does not shuffle the data as it's only \\nused for evaluation during training.\\n• collate_fn: This is used to prepare batches. It takes care of padding sequences to ensure all \\nsentences in a batch are of the same length (since transformer models require fixed-length \\n   transformer Page 29    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='22ad2972-52c0-45df-9571-738f1682ff77', embedding=None, metadata={'page_label': '30', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"sentences in a batch are of the same length (since transformer models require fixed-length \\ninputs).\\n3. Training Loop (For Each Epoch)\\nfor epoch in range(N_EPOCHS):\\n    start_time = time.time()\\ntrain_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\\n    valid_loss = evaluate(model, val_dataloader, criterion)\\nend_time = time.time()\\n• start_time and end_time: Measure the time taken to complete one epoch.\\n• The loop runs for the number of epochs defined by N_EPOCHS.\\n• During each epoch: \\n○ train_loss: The loss computed on the training data by calling the train function.\\n○ valid_loss: The loss computed on the validation data by calling the evaluate function.\\n4. Saving the Best Model\\nif valid_loss < best_valid_loss:\\n    best_valid_loss = valid_loss\\n    torch.save(model.state_dict(), 'transformer-translation-model.pt')\\n• If the current valid_loss (validation loss) is lower than the best_valid_loss, the model is saved \\nusing torch.save(model.state_dict(), 'transformer-translation-model.pt'). This ensures that the \\nbest-performing model (with the lowest validation loss) is saved and can be loaded later for \\ninference.\\n5. Logging Epoch Information\\nepoch_mins, epoch_secs = divmod(end_time - start_time, 60)\\nprint(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\\nprint(f'\\\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\\nprint(f'\\\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\\n• epoch_mins, epoch_secs: These compute the total time for the epoch (in minutes and seconds).\\n• The loss values are printed for both training and validation sets. \\n○ PPL (Perplexity) is printed as math.exp(train_loss) and math.exp(valid_loss). Perplexity is a \\ncommon metric for evaluating language models. It's the exponentiation of the cross-entropy \\nloss, and a lower perplexity means better performance.\\n6. Loading the Best Model\\nmodel.load_state_dict(torch.load('transformer-translation-model.pt'))\\n• After training, the best model (the one with the lowest validation loss) is loaded using torch.load. \\nThis model is now ready for evaluation or inference.\\nKey Takeaways:\\n• Training and Validation Loss: During each epoch, the model is trained on the training set and \\nevaluated on the validation set.\\n• Model Saving: The best model (based on validation loss) is saved.\\n• Logging: Loss and perplexity metrics are printed for both training and validation.\\n• Loading the Best Model: After training, the best model is loaded for further evaluation or \\ninference.\\nIn summary:\\nThis training loop trains your Transformer model for a defined number of epochs. It tracks the training \\nloss and validation loss, and after each epoch, it saves the best model if it improves on the validation \\ndata. The final model with the lowest validation loss is loaded and saved for future use.\\n   transformer Page 30    \", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=docs.load_data()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x000002B81967AAE0>, num_workers=None, max_length=512, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None, show_progress_bar=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "Settings.embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "[0.017773352563381195, -0.026311516761779785, -0.010715308599174023, 0.09249845892190933, 0.059014905244112015, -0.05219223350286484, 0.03183029964566231, 0.0315842404961586, 0.018293585628271103, 0.010523504577577114, -0.07242640852928162, -0.07518339902162552, 0.03899151086807251, 0.007030792068690062, 0.005894538946449757, -0.015238869935274124, 0.04990237206220627, -0.013445298187434673, -0.08619800209999084, 0.06485205888748169, -0.058302734047174454, 0.014859593473374844, -0.026552777737379074, -0.037582751363515854, -0.04921269416809082, 0.056993518024683, -0.021751316264271736, 0.0634465292096138, -0.03945092484354973, -0.05733480677008629, -0.02479013428092003, -0.017419954761862755, 0.0021395559888333082, 0.015224208123981953, 0.040672678500413895, -0.0038720553275197744, 0.02177206426858902, -0.0313495509326458, 0.0022080063354223967, 0.03819335624575615, 0.004114842973649502, -0.00786332506686449, -0.0929982140660286, -0.01432387251406908, -0.02459550090134144, -0.009579070843756199, 0.007769125979393721, -0.024412864819169044, 0.04612937569618225, -0.0645611435174942, 0.05814046412706375, 0.004545759875327349, 0.0014673880068585277, -0.00961911678314209, 0.007120907306671143, 0.006819987203925848, 0.03499937802553177, 0.057215988636016846, 0.015475346706807613, -0.020221635699272156, -0.03003242425620556, 0.04880908876657486, -0.12332962453365326, 0.07440132647752762, 0.03821185231208801, -0.0643901526927948, -0.05021192133426666, 0.010583946481347084, 0.037086959928274155, 0.0014397038612514734, -0.05008488893508911, 0.008020108565688133, 0.08644411712884903, 0.01818639226257801, 0.049820225685834885, 0.026274414733052254, -0.05101999267935753, 0.04687051475048065, -0.012532475404441357, -0.050748541951179504, -0.01521056704223156, 0.006240616552531719, 0.008065921254456043, -0.027962543070316315, -0.03836100921034813, 0.02423074096441269, 0.007710211910307407, 0.01895875856280327, 0.012313746847212315, 0.004655164200812578, -0.04328653961420059, -0.004685468506067991, -0.06819453090429306, 0.037132345139980316, 0.0035601817071437836, -0.007595736999064684, 0.05587952956557274, 0.002908357884734869, -0.014403578825294971, 0.3730229139328003, -0.08525904268026352, 0.02389802224934101, 0.10508043318986893, 0.020103413611650467, -0.020132316276431084, 0.0035470917355269194, -0.0014142453437671065, -0.04429599270224571, 0.0022296588867902756, 0.019087089225649834, -0.00733383372426033, -0.08735373616218567, 0.060036011040210724, -0.005242364481091499, 0.015179650858044624, 0.002078551799058914, 0.05554265156388283, 0.0006024543545208871, 0.00998777337372303, -0.018106209114193916, 0.03333036229014397, 0.021887632086873055, -0.009585371240973473, 0.010616624727845192, 0.09208598732948303, -0.02336251549422741, -0.0024519062135368586, 0.05503658205270767, 0.001154320198111236, 0.01138496957719326, 0.009339915588498116, -0.0011511126067489386, 0.03662283346056938, -0.04090125113725662, -0.017866872251033783, -0.03324266895651817, -0.023072363808751106, 0.015414558351039886, -0.017187941819429398, -0.053372904658317566, 0.025068478658795357, -0.11054178327322006, -0.021098285913467407, -0.17549541592597961, 0.06044788286089897, 0.006438320502638817, -0.05270620435476303, 0.011593444272875786, 0.01371873077005148, -0.048015035688877106, 0.005901608150452375, 0.015333696268498898, 0.008453243412077427, 0.02124744839966297, 0.025041019544005394, 0.012085613794624805, 0.013780085369944572, 0.08921506255865097, -0.012647442519664764, -0.004736815579235554, 0.04222258925437927, 0.023079661652445793, 0.006297283805906773, -0.06743339449167252, -0.043963026255369186, -0.026333825662732124, -0.019812121987342834, -0.054399870336055756, -0.032009225338697433, -0.0030234227888286114, -0.05168357491493225, 0.01813880167901516, -0.03965466469526291, 0.04547528177499771, 0.021025381982326508, -0.008199123665690422, -0.02474375255405903, 0.07693862915039062, 0.008874275721609592, 0.0068065812811255455, -0.0010859668254852295, 0.012993856333196163, 0.0026858069468289614, 0.01592724211513996, 0.005750254727900028, 0.021923081949353218, -0.07268831878900528, -0.0163571760058403, -0.0657581090927124, -0.01830234006047249, 0.004664802923798561, -0.03579249233007431, 0.03826441988348961, -0.0952107235789299, -0.020468374714255333, 0.03130394592881203, -0.026448989287018776, 0.03258221969008446, 0.03978196159005165, -0.008141592144966125, 0.025606775656342506, -0.06903375685214996, -0.06374761462211609, 0.0001186883746413514, 0.04562055319547653, -0.011998710222542286, 0.045779645442962646, -0.009961188770830631, -0.018119612708687782, -0.03855554386973381, 0.09735032171010971, -0.019817767664790154, 0.08792992681264877, -0.06417583674192429, 0.019976476207375526, 0.06492331624031067, -0.037138763815164566, 0.05053297057747841, 0.02690892294049263, 0.0034969369880855083, 0.07857857644557953, -0.11795950680971146, 0.04488670453429222, -0.22054016590118408, -0.018959593027830124, -0.0006524435011669993, -0.09309712052345276, 0.026018301025032997, 0.0030343204271048307, 0.038394611328840256, -0.04426488280296326, 0.08088313043117523, -0.006556407548487186, 0.136811301112175, -0.07598179578781128, 0.06764356046915054, -0.03715228661894798, 0.04312792420387268, 0.056575749069452286, -0.04481484368443489, -0.012302142567932606, 0.04908148944377899, 0.04756579175591469, 0.029395943507552147, 0.005782933905720711, -0.023525813594460487, -0.02235516346991062, 0.0278759952634573, -0.012078679166734219, 0.15331615507602692, 0.08454243093729019, 0.006028405390679836, 0.003505947068333626, -0.04362013563513756, 0.005799503065645695, -0.05719943717122078, -0.06478540599346161, -0.019025659188628197, 0.07771375775337219, 0.045928485691547394, 0.006999655161052942, -0.07024437934160233, 0.003116107080131769, -0.0008843400864861906, 0.06819790601730347, 0.027318786829710007, -0.019425926730036736, 0.038315605372190475, -0.017362922430038452, -0.03264201432466507, 0.11215970665216446, -0.05496187135577202, -0.06479093432426453, -0.006246531847864389, -0.0057748425751924515, 0.04495534300804138, 0.008825506083667278, 0.016243761405348778, -0.04228948429226875, -0.011633671820163727, 0.032233789563179016, -0.030101429671049118, -0.0037735591176897287, 0.06646982580423355, -0.06093598157167435, 0.028077704831957817, -0.014501193538308144, 0.04298674315214157, 0.002452415181323886, -0.03506861999630928, -0.020505240187048912, 0.028299599885940552, 0.017039423808455467, -0.03975358605384827, 0.005068778060376644, 0.02612074464559555, -0.019837262108922005, 0.0012886101612821221, -0.005327166989445686, -0.027524802833795547, 0.021497711539268494, 0.0169865433126688, -0.016835492104291916, 0.07533066719770432, -0.05633341521024704, 0.007189171854406595, 0.013672941364347935, 0.03464599698781967, -0.02060006372630596, -0.04335230961441994, 0.039499055594205856, 0.02241227775812149, -0.08469925075769424, 0.04893200844526291, 0.014601998962461948, -0.05132155120372772, -0.003274668473750353, 0.008706651628017426, 0.020157240331172943, -0.27532798051834106, -0.021782971918582916, 0.03153872862458229, -0.08245082944631577, -0.03374454379081726, -0.013151220977306366, -0.03516557440161705, 0.018425296992063522, -0.015055574476718903, -0.0014206317719072104, 0.014217626303434372, 0.045105598866939545, -0.03040267899632454, 0.0394623838365078, 0.06125522777438164, 0.00613392423838377, 0.0010253526270389557, 0.04691894352436066, -0.04124346375465393, 0.020110521465539932, -0.00853910855948925, -0.026844408363103867, 0.15217547118663788, -0.08747647702693939, -0.0034894561395049095, 0.05267082154750824, -0.02245320938527584, -0.06024148315191269, -0.008460311219096184, 0.01243683323264122, 0.023851878941059113, -0.002724047750234604, -0.014900553971529007, -0.06379099190235138, -0.049566056579351425, 0.027235133573412895, -0.015415933914482594, 0.059931471943855286, 0.0032271172385662794, -0.011206776835024357, -0.01999061182141304, 0.050066445022821426, 0.0022710172925144434, -0.07483895123004913, 0.0002280121116200462, -0.03823299705982208, 0.056731756776571274, 0.014984729699790478, 0.08708833903074265, 0.05573480948805809, -0.024843432009220123, -0.015028233639895916, 0.014730425551533699, -0.01589100807905197, 0.009048574604094028, 0.07985173165798187, -0.05331538990139961, -0.015804370865225792, -0.019115101546049118, -0.033383049070835114, 0.005989901255816221, -0.08283844590187073, 0.0010586774442344904, -0.011206592433154583, 0.0699206218123436]\n"
     ]
    }
   ],
   "source": [
    "embeddings = Settings.embed_model.get_text_embedding(\"It is raining cats and dogs here!\")\n",
    "print(len(embeddings))\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 30/30 [00:00<00:00, 405.33it/s]\n",
      "Generating embeddings: 100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x2b819c80dd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs,show_progress=True)\n",
    "index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"../src/vdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x000002B8206628D0>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x000002B820126420>, vector_stores={'default': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={'7640c971-d974-4a3c-a75b-072b5008ec05': [-0.06349977850914001, 0.031074456870555878, -0.0198642797768116, -0.017937615513801575, 0.026424182578921318, 0.01931745558977127, -0.045697666704654694, -0.036361388862133026, -0.02772308513522148, 0.004448611754924059, 0.00954881776124239, -0.044176775962114334, 0.022101635113358498, 0.049437735229730606, -0.011174279265105724, 0.008375357836484909, -0.04411604255437851, -0.01660342887043953, -0.05550959333777428, -0.059856511652469635, 0.03760366886854172, -0.04093070328235626, 0.030248619616031647, -0.03308464214205742, 0.0397665910422802, 0.012341940775513649, -0.024457087740302086, -0.0023449817672371864, -0.012697634287178516, -0.2479139268398285, 0.012886990793049335, -0.014212021604180336, 0.04832712933421135, 0.002635621465742588, -0.07674501836299896, 0.051075324416160583, -0.0020024084951728582, 0.013358625583350658, -0.013210182078182697, 0.013366064988076687, 0.016811762005090714, 0.005144672468304634, -0.09367725253105164, 0.03203248605132103, 0.06457412987947464, -0.03248770907521248, 0.03424777835607529, -0.01589302159845829, -0.03560845926403999, 0.020226003602147102, -0.012908910401165485, -0.023134715855121613, 0.017180124297738075, 0.026288233697414398, 0.0024340359959751368, 0.00324460631236434, 0.0865049660205841, 0.012838895432651043, 0.07770051807165146, 0.009796049445867538, 0.03613616153597832, -0.005439750384539366, -0.15401871502399445, 0.0634235367178917, 0.03907747194170952, 0.028952499851584435, -0.06525479257106781, -0.04227333515882492, -0.006006114650517702, 0.052555255591869354, -0.053541094064712524, 0.01757984422147274, 0.01110425591468811, 0.049086812883615494, -0.03885729983448982, 0.003990021534264088, 0.021686052903532982, 0.0034698890522122383, 0.028797650709748268, 0.00854591466486454, 0.03533642739057541, -0.010218972340226173, 0.001674323808401823, -0.03353795409202576, 0.032068587839603424, 0.0024489029310643673, -0.01855863258242607, 0.018027406185865402, -0.02414487861096859, -0.027646472677588463, -0.00956389307975769, -0.035832036286592484, -0.005599416792392731, 0.07404540479183197, -0.011223483830690384, -0.032381072640419006, 0.019092252478003502, 0.05347706377506256, -0.017585063353180885, 0.3629038333892822, 0.008198120631277561, -0.045836977660655975, -0.042090289294719696, 0.03818853199481964, -0.020049601793289185, -0.04841042682528496, -0.0003762088599614799, 0.020357979461550713, -0.023176519200205803, 0.04517079144716263, -0.016752084717154503, -0.018060313537716866, -0.013346804305911064, -0.09773712605237961, 0.021499350666999817, -0.047086603939533234, -0.05736076831817627, -0.035659059882164, -0.05067581683397293, 0.07939208298921585, -0.011725024320185184, -0.03104259818792343, 0.004993986338376999, 0.027336835861206055, -0.0008578236447647214, 0.07049589604139328, -0.01051282323896885, 0.021785184741020203, -0.011348017491400242, 0.04758147522807121, 0.03898285701870918, 0.025822846218943596, -0.07239051163196564, 0.03417893499135971, 0.041555747389793396, 0.02793954312801361, 0.08271966874599457, 0.0222595427185297, -0.03317412734031677, -0.023134281858801842, 0.008767022751271725, 0.054740630090236664, 0.06085766851902008, 0.0014590825885534286, -0.05070286616683006, 0.09140855818986893, -0.03225727751851082, -0.016430078074336052, -0.04198093339800835, -0.05480288341641426, 0.022411655634641647, 0.062442999333143234, -0.04840478673577309, -0.04389556869864464, 0.02353116124868393, 0.02972252294421196, 0.03223893791437149, -0.026417700573801994, -0.0723690614104271, -0.02633766643702984, -0.05339600890874863, -0.049552928656339645, 0.03111470676958561, 0.041208863258361816, 0.04415018483996391, -0.06713554263114929, 0.002737537259235978, -0.01976906508207321, -0.021800130605697632, -0.0524870790541172, 0.03892838582396507, 0.025474246591329575, 0.01749872788786888, 0.032320521771907806, 0.0160982608795166, -0.002541213994845748, -0.03999098762869835, -0.04831371828913689, 0.01750141941010952, 0.05287906527519226, -0.0012069552903994918, -0.012921887449920177, -0.0013499611523002386, -0.008191213943064213, 0.0162222757935524, -0.004226698540151119, -0.020812716335058212, 0.01930980570614338, -0.007754158694297075, -0.02266274020075798, -0.03994086757302284, 0.06238758563995361, -0.012755190022289753, 0.02378656156361103, -0.019235288724303246, 0.017322739586234093, -0.015528707765042782, 0.02202291041612625, -0.04219440370798111, -0.036700017750263214, 0.04389261081814766, 0.026005350053310394, 0.023855645209550858, -0.02850397862493992, -0.01958680897951126, 0.027105247601866722, 0.013198642060160637, -0.028885437175631523, 0.01688872091472149, -0.007987325079739094, -0.05744960159063339, -0.042091306298971176, 0.019011517986655235, 0.0021058768033981323, -0.046159643679857254, -0.011137700639665127, 0.03137701004743576, -0.004048530478030443, -0.0042946673929691315, 0.0631197839975357, -0.05172193795442581, -0.05707332864403725, -0.03988824412226677, -0.35094571113586426, 0.01931004971265793, 0.048945147544145584, 0.04265935719013214, 0.04687485471367836, -0.08823215216398239, 0.04115201160311699, 0.002057938138023019, -0.010550767183303833, 0.06605496257543564, 0.07332722097635269, 0.004742241930216551, 0.006205233279615641, -0.06539561599493027, 0.005277811549603939, -0.02170930989086628, 0.02545871213078499, -0.03203110024333, -0.0628729835152626, 0.024402953684329987, -0.01690598763525486, -0.0278715118765831, 0.01357013639062643, -0.07568224519491196, 0.02146187610924244, -0.04762871563434601, 0.10137619823217392, -0.060217034071683884, 0.06766531616449356, -0.03678811341524124, -0.004964873194694519, 0.052448827773332596, -0.05422646924853325, -0.046866513788700104, 0.02916122041642666, -0.05284634977579117, 0.08215470612049103, 0.04003208503127098, 0.01685122214257717, 0.002455254551023245, -0.021733203902840614, 0.00839967280626297, 0.018716346472501755, -0.07366948574781418, 0.04362460970878601, -0.0029645219910889864, -0.02797096036374569, -0.06547680497169495, 0.011239207349717617, 0.006836201995611191, 0.002900240244343877, 0.012957564555108547, 0.04805292934179306, -0.00037034862907603383, -0.03034084104001522, -0.04300203174352646, -0.06168704107403755, 0.046092987060546875, -0.018191514536738396, 0.008521409705281258, -0.015868157148361206, -0.02061779424548149, 0.01803693361580372, -0.06579996645450592, 9.270561713492498e-05, -0.013838296756148338, 0.05010528117418289, 0.03329792991280556, 0.03324965015053749, 0.06675190478563309, -0.009153233841061592, 0.06947460025548935, -0.018475081771612167, 0.07846160978078842, 0.02612297050654888, 0.04615067318081856, -0.010737440548837185, 0.06172027811408043, -0.015591658651828766, 0.030290868133306503, 0.00792194064706564, 0.050257474184036255, 0.057434555143117905, 0.03969850391149521, 0.04442209377884865, -0.033281538635492325, 0.034614983946084976, 0.0329468734562397, 0.049796316772699356, 0.0050941891968250275, -0.06110170856118202, -0.027261460199952126, -0.01695871353149414, 0.02472671866416931, 0.06455627828836441, 0.021854478865861893, -0.2522314488887787, 0.008410614915192127, 0.03722163289785385, 0.024996241554617882, 0.02007334493100643, -0.051967840641736984, 0.05958671122789383, -0.04650414362549782, 0.040512893348932266, -0.04413382336497307, -0.034647535532712936, 0.020769787952303886, 0.0349036380648613, -0.005818990524858236, 0.005071064457297325, 0.01175207644701004, 0.13642165064811707, -0.006729801185429096, 0.010905597358942032, 0.01151672936975956, 0.005572462920099497, -0.022809576243162155, 0.18273232877254486, -0.027911461889743805, 0.008266470395028591, -0.005919459741562605, -0.013262631371617317, -0.05720693990588188, 0.025021348148584366, 0.019213538616895676, 0.03675244748592377, 0.043323323130607605, 0.05698711797595024, 0.0006744774291291833, 0.016627376899123192, 0.059105463325977325, -0.03830314800143242, 0.0457286462187767, 0.06343710422515869, 0.02415667101740837, 0.004096055869013071, -0.029928382486104965, -0.05882798507809639, -0.010402564890682697, -0.00836506113409996, -0.04228675737977028, -0.03322037309408188, -0.06513997167348862, -0.06824436783790588, 0.02687838301062584, 0.025741128250956535, 0.002419078256934881, -0.024058610200881958, -0.03713453188538551, 0.01781018078327179, 0.033654872328042984, -0.0037808953784406185, 0.017132198438048363, -0.014382599852979183, -0.012092558667063713, 0.03291432932019234, -0.07206816226243973, 0.04971688613295555, -0.023443659767508507, -0.04370768368244171], '04ccfe3c-9f63-4c80-afbd-de2a307aa69c': [-0.044322554022073746, 0.058770451694726944, -0.012655697762966156, -0.038318779319524765, -0.002936208387836814, -0.014561282470822334, -0.030684135854244232, 0.022584062069654465, 0.018007222563028336, 0.009248851798474789, 0.015899447724223137, -0.05613909661769867, 0.06029080972075462, -0.04808169603347778, -0.004456523805856705, -0.016174428164958954, 0.002330425661057234, -0.021981941536068916, -0.023272095248103142, -0.04552566260099411, 0.06465474516153336, -0.026874899864196777, -0.029369067400693893, -0.02094956301152706, 0.03989178314805031, 0.04994162544608116, 0.005931162741035223, 0.04947374016046524, -0.05676842853426933, -0.23935049772262573, 0.012446301057934761, -0.030999986454844475, 0.03948889672756195, 0.010772130452096462, -0.02955820970237255, 0.020108530297875404, 0.04220457747578621, -0.01799492910504341, -0.03947989642620087, 0.011914631351828575, 0.016794482246041298, -0.006450250744819641, -0.01976759172976017, -0.02179170586168766, 0.043351687490940094, -0.03441370278596878, 0.01706305518746376, -0.07275541871786118, -0.0577857680618763, -0.01933933235704899, 0.024529853835701942, -0.0063460823148489, -0.011226505041122437, -0.0011048120213672519, 0.025972120463848114, 0.004715560469776392, 0.027906931936740875, 0.041980843991041183, 0.024102218449115753, 0.02307373657822609, -0.02321903221309185, 0.021728094667196274, -0.18280678987503052, 0.06837376952171326, -0.020516688004136086, 0.05405014008283615, -0.033318862318992615, -0.01613570936024189, -0.01742224209010601, 0.019017469137907028, -0.01993378810584545, 0.020432045683264732, -0.027655774727463722, 0.045351292937994, 0.005258335266262293, -0.030610961839556694, 0.0062341163866221905, 0.033394891768693924, 0.023970911279320717, -0.020252512767910957, 0.03167663514614105, 0.0018229256384074688, -0.0080988435074687, -0.01877276599407196, -0.00999944843351841, 0.017241710796952248, 0.012432815507054329, -0.055780988186597824, 0.009964441880583763, -0.0393349751830101, -0.005937296897172928, -0.04589957743883133, -0.009773398749530315, 0.04694293066859245, -0.06920783221721649, -0.018458740785717964, -0.0014936734223738313, 0.021645601838827133, -0.023774534463882446, 0.3849713206291199, 0.0004239409463480115, 0.012418090365827084, -0.03134644776582718, -0.07497505843639374, 0.05855915695428848, -0.020714737474918365, -0.036435555666685104, 0.04127952456474304, 0.00090556510258466, 0.006459053140133619, -0.08950509130954742, -0.017956996336579323, -0.005185776390135288, -0.09915315359830856, 0.03360273316502571, -0.07978148013353348, 0.03598331660032272, -0.0010374293196946383, -0.03250743821263313, -0.010857271030545235, -0.020180661231279373, -0.018953638151288033, 0.02453238144516945, -0.0186918918043375, 0.03414517641067505, 0.0660209208726883, 0.04288998246192932, 0.06527195125818253, 0.06755822896957397, 0.019074931740760803, 0.055421728640794754, 0.03665420040488243, -0.033164411783218384, 0.02530233934521675, 0.01955799013376236, 0.00447752745822072, 0.020630158483982086, -0.008642773143947124, -0.02710038609802723, -0.0354154147207737, 0.006790770683437586, -0.015898510813713074, 0.014798905700445175, -0.024278724566102028, -0.08171852678060532, 0.09501302242279053, -0.008346406742930412, -0.058730196207761765, 0.019927019253373146, -0.0084405317902565, -0.04716720059514046, 0.07524199038743973, 0.028848038986325264, -0.035571787506341934, 0.02582322619855404, 0.044553957879543304, 0.042218804359436035, -0.05059104785323143, -0.02497483417391777, -0.07352587580680847, -0.013775434345006943, -0.03476014733314514, -0.020536163821816444, 0.06395407021045685, -0.003870517946779728, -0.05367644876241684, -0.032136231660842896, -0.016917936503887177, -0.05065333470702171, -0.043820735067129135, 0.03272432088851929, -0.008613724261522293, -0.036711763590574265, 0.013209777884185314, -0.022690391167998314, 0.0003783557622227818, 0.0017551081255078316, -0.06615833938121796, 0.01309965644031763, 0.05291549861431122, -0.02837534062564373, -3.206421752111055e-05, 0.030598822981119156, 0.08435475826263428, 0.004058271646499634, 0.002839252119883895, -0.042781271040439606, 0.0046178922057151794, 0.07595109939575195, -0.02352374605834484, -0.05870984494686127, 0.06228184700012207, 0.008347065187990665, -0.04680543392896652, 0.010303385555744171, 0.027994640171527863, -0.0013537773629650474, 0.0060697621665894985, -0.03921893984079361, 0.01718165911734104, 0.07265406847000122, 0.09217381477355957, 0.00792277418076992, -0.025457926094532013, -0.02824358455836773, -0.018974335864186287, 0.05789632350206375, -0.002502547111362219, 0.031051529571413994, -0.001402597757987678, -0.07612914592027664, -0.001371318707242608, 0.01992950774729252, 0.015654200688004494, -0.02687974087893963, 0.001583747216500342, 0.033058054745197296, -0.021930033341050148, -0.022475671023130417, 0.029744280502200127, -0.031839627772569656, 0.030042078346014023, -0.04254121333360672, -0.3338591754436493, -0.04471345245838165, 0.044868215918540955, -0.014159142039716244, 0.05823886767029762, -0.061418719589710236, 0.024754097685217857, 0.015033053234219551, 0.021577870473265648, 0.012750138528645039, 0.04557330161333084, -0.051268186420202255, -0.027181483805179596, -0.056033167988061905, 0.022674325853586197, 0.025674086064100266, 0.01703338883817196, -0.07938310503959656, -0.027286557480692863, 0.06336929649114609, 0.02823599800467491, 0.006928640883415937, 0.006801718845963478, -0.06138142570853233, 0.038966044783592224, 0.026117851957678795, 0.07865209132432938, 0.010009199380874634, 0.0704883560538292, 0.017980681732296944, 0.032309334725141525, 0.04572948068380356, -0.024845197796821594, -0.033050600439310074, 0.036927808076143265, -0.03686056286096573, 0.052232854068279266, 0.0121995834633708, -0.03403426334261894, 0.016231488436460495, -0.0031005111522972584, -0.01668817736208439, 0.029806504026055336, -0.0575784407556057, 0.003000743454322219, 0.020602194592356682, 0.014338399283587933, -0.04097629338502884, -0.018962521106004715, 0.02327515184879303, -0.026116611436009407, 0.05969031900167465, 0.060954369604587555, 0.059656497091054916, -0.049317993223667145, -0.0021427993196994066, -0.03512446582317352, -0.040932465344667435, -0.027609622105956078, -0.006491533946245909, -0.006687255576252937, -0.021435916423797607, 0.07769706845283508, -0.1020064502954483, -0.023020988330245018, 0.0027197895105928183, 0.0028357463888823986, -0.0023739070165902376, 0.03125988319516182, -0.008579299785196781, 0.003784807166084647, 0.1029183641076088, 0.014846486039459705, 0.012738360092043877, 0.013548514805734158, 0.06055750325322151, 0.01338078361004591, 0.018352894112467766, -0.02908179722726345, -0.018557405099272728, 0.0669480711221695, 0.01749543473124504, 0.06745237112045288, 0.05415117368102074, -0.004347901791334152, -0.03392715007066727, 0.06917313486337662, -0.02197767049074173, 2.0736859369208105e-05, 0.048932261765003204, -0.06333515048027039, 0.010769293643534184, 0.01139900553971529, 0.01506778970360756, 0.02457434870302677, -0.022593388333916664, -0.2737382650375366, 0.04672219231724739, 0.021104417741298676, 0.06486468017101288, 0.005902593955397606, -0.01825874112546444, -0.013608567416667938, -0.053662240505218506, -0.028181977570056915, -0.01062107551842928, 0.008922847919166088, 0.024559110403060913, 0.04108912870287895, -0.02015436440706253, -0.05083956569433212, 0.04410550370812416, 0.09277446568012238, 0.014829299412667751, -0.03570803254842758, -0.01886269822716713, 0.03250866383314133, -0.03254130482673645, 0.18113815784454346, 0.008458207361400127, -0.013869008980691433, 0.015925711020827293, -0.003014407819136977, -0.013631109148263931, 0.03394079953432083, 0.06470070034265518, 0.02728826180100441, 0.021910173818469048, 0.04754366725683212, 0.01154049951583147, 0.023519771173596382, -0.03805946931242943, -0.07882441580295563, -0.030574293807148933, 0.03845186159014702, 0.056395746767520905, -0.02149740420281887, 0.008730814792215824, -0.02242356725037098, -0.07101321965456009, 0.04529061168432236, -0.01891641691327095, -0.025313416495919228, -0.026210274547338486, -0.05179264396429062, 0.009549176320433617, -0.06670570373535156, -0.04428470879793167, -0.009855512529611588, -0.02558029629290104, 0.04319354519248009, 0.05971661955118179, 0.008942585438489914, 0.009074609726667404, 0.002130066743120551, 0.020496884360909462, -0.002783418633043766, -0.028503306210041046, 0.05665609613060951, 0.06271493434906006, 0.03583146259188652], '093521af-dd8f-4619-9022-e5eada65779a': [-0.00676315650343895, 0.001781080267392099, -0.042511288076639175, 0.029720282182097435, 0.07039754837751389, 0.0021920250728726387, -0.054475657641887665, -0.05735979229211807, -0.00014665348862763494, -0.001501391758210957, 0.01228210236877203, -0.058453064411878586, 0.044104427099227905, 0.03551606833934784, -0.04806378483772278, 0.03342483192682266, -0.052056197077035904, -0.021923445165157318, 0.0064056552946567535, -0.04368416592478752, 0.05734821781516075, -0.028190474957227707, 0.00033451325725764036, -0.09611819684505463, 0.04285425692796707, -0.017500223591923714, -0.014114590361714363, -0.028683191165328026, -0.03619374334812164, -0.25586146116256714, 0.04826059192419052, -0.022817865014076233, -0.002473151311278343, -0.04168403148651123, -0.022865239530801773, 0.04059123620390892, -0.022604292258620262, 0.03357259929180145, -0.05768953636288643, 0.06605350971221924, 0.02471330016851425, 0.03957774490118027, -0.05929528921842575, 0.013911758549511433, 0.05284217372536659, 0.014414789155125618, 0.0061628203839063644, -0.008683325722813606, 0.006951193790882826, 0.04332650452852249, -0.0018863839795812964, 0.006867764517664909, -0.03008704073727131, 0.017978643998503685, -0.011762631125748158, 0.025878781452775, 0.04083168879151344, 0.04789631813764572, -0.004139425698667765, -0.02013428881764412, 1.1184263712493703e-05, 0.0196157805621624, -0.1294374018907547, 0.045366737991571426, 0.05941133201122284, 0.01273584645241499, -0.0007464158115908504, -0.06741020083427429, 0.014364914037287235, 0.06934017688035965, 0.01886005513370037, 0.026903891935944557, 0.036763593554496765, 0.010547433979809284, -0.00964404921978712, -0.02224523015320301, -0.054014306515455246, -0.012175259180366993, 0.03740591183304787, 0.040874771773815155, -0.05189035087823868, -0.02487635426223278, -0.028697073459625244, 0.014363895170390606, 0.0320596769452095, 0.019436679780483246, 0.003201038809493184, 0.02247111313045025, 0.04782950505614281, -0.03317306190729141, -0.000772299652453512, -0.035046160221099854, -0.06143201142549515, 0.02592417597770691, 0.009508009068667889, 0.02171490713953972, 0.059638164937496185, -0.019844522699713707, -0.02987396903336048, 0.3437843918800354, 0.016876475885510445, -0.03716780245304108, -0.12122074514627457, 0.08586886525154114, -0.008111285977065563, -0.05603810027241707, -0.010023027658462524, 0.01232596393674612, -0.046590037643909454, 0.003380780341103673, 0.029729394242167473, -0.03141544386744499, 0.0501881018280983, -0.04362828657031059, 0.01070331409573555, -0.07011710852384567, -0.005649695638567209, 0.015736036002635956, 0.010503747500479221, 0.03127826750278473, -0.04630091413855553, 0.027456779032945633, 0.027390047907829285, -0.016137979924678802, 0.029589856043457985, 0.05095366761088371, 0.0032679494470357895, 0.06966521590948105, 0.0026467242278158665, 0.02443949319422245, 0.007715774234384298, 0.011040523648262024, -0.06480570882558823, 0.00720276590436697, 0.021134639158844948, 0.027337750419974327, 0.026827728375792503, 0.004515192937105894, -0.014050726778805256, -0.005357782356441021, 0.02096661366522312, 0.06596910953521729, 0.06385467201471329, -0.040785353630781174, -0.046784818172454834, 0.07859019935131073, -0.027989713475108147, 0.0886860266327858, 0.03632797673344612, -0.05638062581419945, 0.031345169991254807, 0.017336349934339523, -0.03705060854554176, -0.06534287333488464, 0.046945348381996155, 0.07642077654600143, 0.008131956681609154, -0.010249773040413857, -0.02144429460167885, 0.013375826179981232, -0.04130265861749649, -0.0446319542825222, 0.0040254597552120686, 0.04825093224644661, 0.03330925107002258, -0.04509696364402771, -0.01615511067211628, 0.00797587726265192, -0.02085592970252037, -0.05930045247077942, 0.007189666386693716, -0.019729774445295334, 0.006700602360069752, -0.0030721863731741905, -0.027201319113373756, -0.005948262754827738, -0.0777801051735878, -0.005656387656927109, -0.01717963069677353, 0.07499869167804718, 0.001784064108505845, -0.017505871132016182, 0.007986912503838539, 0.03671225905418396, -0.0616353340446949, -0.00762392720207572, -0.0238038320094347, 0.021811766549944878, -0.021475208923220634, 0.01679886132478714, -0.02854171395301819, -0.0033681239001452923, -0.020278211683034897, -0.005352358799427748, -0.031862515956163406, -0.07147146016359329, 0.029426420107483864, -0.026913253590464592, -0.0080207958817482, -0.008637664839625359, -0.04365455359220505, 0.041329726576805115, 0.040012773126363754, 0.030300291255116463, -0.04385031759738922, 0.022813202813267708, -0.021829718723893166, -0.056497182697057724, 0.010162143968045712, 0.036949221044778824, -0.062425848096609116, -0.04543834179639816, -0.04444802552461624, 0.04571240395307541, -0.07567637413740158, 0.008844750002026558, 0.010361592285335064, 0.033305443823337555, 0.012633231468498707, 0.03236878290772438, 0.04299040138721466, -0.023348230868577957, -0.018225248903036118, -0.35205787420272827, -0.04927288740873337, -0.03836004436016083, -0.008628961630165577, 0.05336374044418335, -0.047618407756090164, 0.03177884966135025, -0.024535542353987694, 0.0018156468868255615, -0.005553958937525749, 0.07780871540307999, 0.03490916267037392, 0.027607405558228493, -0.06183939799666405, 0.007031645160168409, 0.018983669579029083, 0.005893849302083254, -0.040458351373672485, -0.04117283225059509, 0.042589232325553894, 0.016060953959822655, -0.02183854952454567, 0.07707364112138748, -0.07448127865791321, 0.013480573892593384, -0.013559181243181229, 0.09030397236347198, -0.02429386042058468, 0.07807607203722, -0.025815794244408607, 0.03574828803539276, 0.019742846488952637, -0.040200743824243546, -0.0613902285695076, 0.0687842071056366, -0.003092055441811681, 0.009417515248060226, 0.06444407999515533, -0.008023041300475597, -0.0030839438550174236, 0.005801187362521887, 0.05022614449262619, 0.017278851941227913, -0.08199780434370041, -0.037681933492422104, -0.036381226032972336, -0.029665645211935043, 0.025624951347708702, -0.017274675890803337, 0.04721278324723244, -0.04934538155794144, -0.008666926063597202, 0.027145549654960632, 0.026486605405807495, 0.03484095260500908, -0.0060097211971879005, -0.07525072991847992, 0.051010508090257645, 0.005609360057860613, 0.013582096435129642, 0.0032244003377854824, -0.06180926784873009, 0.01171333622187376, -0.04378112778067589, 0.022655609995126724, -0.048450518399477005, 0.025190740823745728, -0.028876379132270813, 0.08740639686584473, 0.02311125583946705, 0.026438243687152863, 0.07788432389497757, -0.005464405752718449, 0.030859483405947685, 0.01238635927438736, 0.014948896132409573, -0.007223698776215315, -0.014841953292489052, -0.014337620697915554, 0.006892320699989796, 0.01832897774875164, 0.01486675813794136, 0.024209417402744293, 0.0689234659075737, 0.03309016302227974, -0.01190156303346157, 0.045288097113370895, 0.02799098938703537, 0.045953769236803055, 0.06473490595817566, -0.05447694659233093, 0.022020116448402405, -0.02152775041759014, 0.006613787729293108, -0.020137250423431396, 0.04707188904285431, -0.27398574352264404, -0.009384049102663994, -0.03688214346766472, 0.04614449664950371, 0.04385015740990639, -0.02809303067624569, 0.08197418600320816, -0.03192579373717308, -0.014943200163543224, -0.02162073366343975, -0.06646165251731873, 0.04065975174307823, 0.09710365533828735, -0.016934212297201157, 0.01810166798532009, 0.034610845148563385, 0.10005654394626617, -0.07218769192695618, -0.01585809327661991, -0.03151150420308113, 0.037199344485998154, 0.035895392298698425, 0.16039790213108063, 0.008054625242948532, -0.03551101312041283, -0.03688095137476921, 0.033655986189842224, -0.005720020271837711, 0.055772021412849426, 0.04309545457363129, -0.0018699619686231017, 0.0309873279184103, 0.07224605977535248, 0.006620530039072037, 0.04424148052930832, 0.07979792356491089, -0.03882918506860733, 0.005239525809884071, 0.03483173996210098, -0.01890169084072113, -0.051789216697216034, -0.0494999997317791, -0.024633802473545074, -0.058372415602207184, 0.01776881143450737, -0.03855353593826294, 0.0046886662021279335, -0.028673335909843445, -0.06887482851743698, 0.02813352271914482, -0.04146632179617882, 0.005114185158163309, -0.016990501433610916, -0.03719346970319748, 0.011101970449090004, -0.02862371690571308, 0.00045120579306967556, 0.003022669581696391, -0.051306478679180145, 0.02285875752568245, 0.051887448877096176, -0.01958475448191166, 0.04910128191113472, -0.00010812834807438776, -0.031688690185546875], 'e42b80bb-1d8a-4683-b0f2-cb990c8103d6': [0.002737388713285327, 0.03378571942448616, 0.0007543227402493358, -0.02903945930302143, 0.059797096997499466, 0.02665906585752964, -0.029274247586727142, -0.01989990659058094, -0.00999350193887949, -0.038933686912059784, -0.02538660354912281, -0.05846161022782326, 0.036833085119724274, 0.05721501633524895, -0.003231000853702426, -0.024028697982430458, 0.007862924598157406, -0.015000379644334316, -0.02209407091140747, 0.010992712341248989, 0.029810048639774323, -0.03504293039441109, 0.02232345938682556, -0.033162862062454224, 0.03439558669924736, 0.047633152455091476, -0.04414413496851921, -0.015389497391879559, -0.020985666662454605, -0.22879797220230103, 0.012906946241855621, -0.05130120366811752, 0.02135462872684002, 0.013305670581758022, -0.005128068849444389, 0.030611306428909302, 0.024549361318349838, 0.03287611901760101, 0.00011884872947121039, 0.000959987286478281, 0.004577431827783585, 0.013816284015774727, -0.04788939282298088, 0.04873596131801605, 0.04160960763692856, -0.004380682948976755, 0.003931878600269556, -0.022727370262145996, 0.008136292919516563, 0.0517578125, -0.059468746185302734, 0.04441683739423752, -0.02770463563501835, 0.025139380246400833, 0.011024074628949165, -0.010391798801720142, 0.04365977644920349, 0.04459666833281517, 0.02863171137869358, -0.003104314673691988, 0.015982240438461304, 0.029300576075911522, -0.1423463672399521, 0.080553337931633, -0.012609361670911312, 0.036232490092515945, -0.04109964147210121, 0.00841620471328497, -0.00824290793389082, 0.03548603877425194, -0.07617960125207901, 0.010924647562205791, 0.029212720692157745, 0.05164387449622154, -0.027479002252221107, 0.005660939961671829, 0.009231981821358204, 0.007984011434018612, 0.018421458080410957, 0.00858278013765812, 0.029222765937447548, -0.0030921888537704945, 0.02668054588139057, -0.014547018334269524, -0.0300699882209301, -0.05074577406048775, -0.02563522383570671, -0.016153672710061073, 0.0005736569873988628, 0.006256102118641138, 0.012009229511022568, 0.004600937012583017, -0.010039795190095901, 0.09254536777734756, -0.04868423193693161, -0.024403342977166176, 0.028016947209835052, 0.08524598181247711, 0.023799320682883263, 0.3418526351451874, -0.03311096876859665, -0.020025083795189857, -0.01841246522963047, 0.010140075348317623, -0.011743002571165562, -0.03897341340780258, 0.04617276042699814, 0.034389566630125046, -0.02797502465546131, 0.07014626264572144, -0.00045234718709252775, -0.05822601914405823, -0.005724577698856592, -0.08090436458587646, -0.005240216851234436, -0.02547636441886425, -0.04431726410984993, -0.002316053956747055, -0.05997234210371971, 0.05713129788637161, -0.0476410947740078, -0.014823567122220993, -0.05433330312371254, -0.001635946100577712, 0.02832622081041336, 0.062296319752931595, 0.04732133075594902, 0.04777614027261734, 0.06658235937356949, 0.014063308015465736, 0.06785646080970764, 0.013961254619061947, -0.1075356975197792, 0.01321859285235405, 0.03718021139502525, 0.012065847404301167, 0.07008331269025803, 0.02333017811179161, -0.0157788023352623, -0.04231581091880798, 0.00907667726278305, 0.037225641310214996, 0.030130954459309578, 0.03718792274594307, -0.050137147307395935, 0.1560867428779602, -0.02002072148025036, -0.021105526015162468, -0.06260489672422409, -0.04889974743127823, 0.026272904127836227, 0.04145914688706398, 0.024051936343312263, -0.07383253425359726, 0.0028334723319858313, 0.06011830270290375, 0.0615130253136158, -0.005986122880131006, -0.07818737626075745, -0.008465372025966644, -0.0264629777520895, -0.0015135880094021559, -0.007418097462505102, 0.043590668588876724, 0.05050445720553398, -0.012719955295324326, 0.013033820316195488, 0.011139252223074436, -0.005461202003061771, -0.09176479279994965, 0.041548386216163635, 0.03768759220838547, -0.01608465611934662, -0.0006824674201197922, 0.012813943438231945, 0.02460211142897606, -0.01775296777486801, -0.034913569688797, 0.011785103939473629, 0.05975615978240967, -0.006001410074532032, 0.027194824069738388, 0.004647783003747463, 0.0004023500077892095, -0.002665643347427249, 0.01541783008724451, -0.03603631630539894, 0.03583618998527527, 0.0031914690043777227, -0.0019142359960824251, -0.004419400822371244, 0.005681625101715326, -0.0038206269964575768, -0.029272213578224182, -0.016792358830571175, -0.05218440666794777, 0.02288305200636387, 0.04595068469643593, -0.056750062853097916, -0.022541945800185204, 0.027404574677348137, 0.020543787628412247, -0.029640423133969307, 0.03097120299935341, -0.04950172081589699, -0.01590755209326744, 0.046779148280620575, -0.002467289101332426, -0.016245033591985703, 0.0023991363123059273, -0.032607439905405045, -0.02261977083981037, -0.059289805591106415, 0.008295498788356781, -0.040903616696596146, -0.007849108427762985, 0.03902969881892204, -0.03460588678717613, -0.0461282841861248, 0.07358385622501373, -0.04335785657167435, -0.0852145105600357, -0.003221398452296853, -0.3816348910331726, -0.010346482507884502, 0.03324097394943237, 0.012910460121929646, 0.04309506714344025, -0.06519357860088348, -0.018834613263607025, 0.015217205509543419, -0.017854822799563408, 0.02688206173479557, 0.09536322951316833, 0.056754495948553085, -0.048104964196681976, -0.034098658710718155, 0.012614349834620953, -0.019726499915122986, 0.0030155363492667675, -0.014902481809258461, -0.04988282546401024, -0.03124069795012474, 0.022266795858740807, -0.05542026832699776, -0.03574742004275322, -0.05890662968158722, 0.06385231763124466, -0.02424638904631138, 0.09857127070426941, -0.0397438108921051, 0.06667960435152054, -0.03457368165254593, 0.039301156997680664, 0.021250011399388313, -0.021577609702944756, -0.053286727517843246, 0.06060798093676567, -0.04906522482633591, 0.032709959894418716, 0.08639814704656601, 0.01337878592312336, 0.011606696993112564, 0.021876193583011627, -0.04710029438138008, 0.019002340734004974, -0.07560892403125763, -0.0074814120307564735, 0.03650717809796333, 0.012844115495681763, -0.06917150318622589, 0.021769626066088676, 0.0136814434081316, -0.003863060148432851, 0.04669129475951195, 0.012146949768066406, -0.012322623282670975, 0.012570695020258427, -0.008883480913937092, -0.0543694831430912, 0.01146974228322506, -0.0044522974640131, 0.0017864195397123694, -0.013445134274661541, -0.002732600085437298, 0.045758944004774094, -0.056474022567272186, -0.005490351468324661, -0.036996886134147644, -0.007870220579206944, 0.011828151531517506, 0.014354358427226543, 0.013745123520493507, -0.0220048725605011, 0.03852672502398491, -0.0041898200288414955, 0.05910439416766167, -0.0007048401166684926, 0.016735989600419998, -0.05293171480298042, 0.0360226035118103, 0.012881811708211899, -0.026475878432393074, -0.005969199351966381, 0.05402762442827225, 0.031863320618867874, 0.026244577020406723, 0.015551554039120674, -0.012571745552122593, 0.044480983167886734, -0.0021576653234660625, 0.06300884485244751, 0.03477322310209274, -0.027906259521842003, -0.033112939447164536, -0.04101504385471344, 0.011698183603584766, 0.07419569045305252, -0.009533326141536236, -0.2691270411014557, -0.0006344555295072496, 0.0014930450124666095, 0.02506881020963192, 0.03564167767763138, -0.047582969069480896, 0.05082685500383377, -0.03846336901187897, 0.00968263205140829, -0.04143901169300079, -0.07760918140411377, 0.051229946315288544, 0.014656887389719486, -0.051475755870342255, -0.03655007481575012, 0.03819308802485466, 0.13647575676441193, -0.010773043148219585, 0.012929471209645271, 0.008936481550335884, 0.012909927405416965, -0.022008467465639114, 0.18204136192798615, -0.004383277613669634, 0.03338782489299774, -0.010480831377208233, -0.029141470789909363, -0.07726340740919113, 0.030934007838368416, -0.008537677116692066, 0.022425927221775055, 0.03576403111219406, 0.04297740384936333, -0.013363528065383434, 0.044357992708683014, 0.028191108256578445, -0.02407556027173996, 0.03979939594864845, 0.02652493119239807, 0.04270174354314804, -0.01673511601984501, 0.015325146727263927, -0.0770622044801712, 0.00984005257487297, 0.041959937661886215, -0.06074580177664757, -0.019030744209885597, -0.07766292989253998, -0.05360826477408409, -0.02587139420211315, 0.005205576773732901, -0.0019460002658888698, -0.06227698177099228, -0.061970967799425125, 0.031368765980005264, 0.057406358420848846, -0.005430424120277166, 0.021512901410460472, 0.03929663449525833, 0.010875985026359558, -0.01814810000360012, -0.042254235595464706, 0.009319611825048923, -0.013272522948682308, -0.0235441904515028], 'cf0809ed-8cec-4993-b359-5f6dc8e9c4c1': [-0.04014745354652405, 0.08048349618911743, -0.00915819127112627, 0.003993805963546038, -0.003086637705564499, 0.0026498117949813604, -0.06116099655628204, -0.01449536345899105, -0.059167779982089996, -0.02445797435939312, -0.041756924241781235, -0.07980404794216156, 0.030606549233198166, 0.04154608026146889, -0.004310624673962593, -0.0028037417214363813, -0.018053019419312477, -0.031485263258218765, -0.07915163040161133, -0.003599773393943906, 0.025112349539995193, -0.040821366012096405, 0.002148387022316456, -0.03475295007228851, 0.02841072715818882, 0.06377075612545013, -0.027304332703351974, -0.01784556545317173, -0.03007953055202961, -0.2222612202167511, 0.02447357028722763, -0.06621064245700836, -0.008703195489943027, -0.02872670255601406, -0.013317275792360306, 0.02922319434583187, 0.008779781870543957, 0.03096378780901432, -0.029800016433000565, -0.011577229015529156, 0.05252944678068161, -0.005015063565224409, -0.06627501547336578, -0.0073392619378864765, 0.01758800446987152, -0.04834294319152832, 0.02196556329727173, -0.013419131748378277, -0.010538049042224884, 0.054156072437763214, -0.06794983893632889, -0.032483283430337906, 0.007961694151163101, -0.042789723724126816, 0.015486685559153557, -0.013914475217461586, 0.03638932481408119, 0.06427225470542908, 0.06456483900547028, -0.0045493971556425095, -0.006733426358550787, 0.018909430131316185, -0.16411763429641724, 0.07067717611789703, -0.019653871655464172, 0.0500389002263546, -0.049788396805524826, -0.009338725358247757, 0.017673244699835777, 0.038726527243852615, -0.06463082134723663, -0.00032173070940189064, 0.0033078487031161785, 0.10525339841842651, -0.001579826814122498, -0.007892655208706856, -0.036140553653240204, 0.0012567671947181225, 0.050413887947797775, 0.02209164947271347, -0.02731012925505638, 0.002439198549836874, 0.018309295177459717, -0.010301783680915833, 0.005994617473334074, -0.0376167930662632, -0.01632501371204853, 0.04702379181981087, -0.012572888284921646, 0.017485810443758965, 0.027056114748120308, -0.016868168488144875, -0.024281684309244156, 0.06304876506328583, -0.0813332200050354, -0.06313571333885193, 0.017796967178583145, 0.03430359065532684, -0.0014838806819170713, 0.3524698317050934, -0.012538284063339233, -0.0011908183805644512, -0.01654766872525215, -0.007237086538225412, -0.0001784154592314735, -0.037694040685892105, 0.03336434066295624, 0.01760171912610531, -0.011209411546587944, 0.01018141582608223, -0.028881100937724113, -0.037017885595560074, 0.006684552878141403, -0.11815936118364334, -0.017578572034835815, -0.037345971912145615, -0.0019942373037338257, -0.0014959610998630524, -0.038799088448286057, 0.04510005936026573, 0.023424344137310982, -0.01668914407491684, -0.03787636011838913, -0.014636856503784657, 0.033178746700286865, 0.07753001153469086, 0.07559914886951447, 0.05323859304189682, 0.03713039681315422, 0.028156861662864685, 0.04779653251171112, 0.03754784166812897, -0.07252540439367294, 0.013107550330460072, -0.007559588644653559, 0.012173001654446125, 0.01913011632859707, 0.007104198448359966, -0.007536166347563267, -0.0015598313184455037, 0.036261364817619324, 0.016310634091496468, 0.041919562965631485, 0.01675352454185486, -0.040609508752822876, 0.09058278053998947, -0.02263544499874115, -0.03878939524292946, -0.03071308508515358, -0.05472433939576149, 0.02682516537606716, 0.04613102599978447, 0.018206575885415077, -0.04155328869819641, 0.029906518757343292, 0.07641520351171494, 0.027992570772767067, 0.007726323325186968, -0.01096956804394722, -0.01332598365843296, -0.012785691767930984, -0.03474269062280655, 0.002837383421137929, 0.06452368199825287, 0.02840123139321804, -0.0346078984439373, -0.024861376732587814, -0.01406728196889162, 0.0051691266708076, -0.05130860581994057, 0.05344854295253754, 0.013548577204346657, -0.0515085831284523, 0.037180397659540176, -0.006429045461118221, 0.00531371682882309, 0.006023110821843147, -0.00806056521832943, 0.02637859620153904, 0.08398613333702087, 0.005679994355887175, 0.02819691225886345, 0.04138989746570587, 0.05256201699376106, 0.00013171971659176052, 0.0026582516729831696, -0.03948872163891792, 0.0039541940204799175, 0.01854272000491619, 0.0213206447660923, -0.031132664531469345, 0.05590816214680672, -0.00840238481760025, -0.01808706857264042, 0.014735415577888489, 0.00283583696000278, 0.029202759265899658, -0.014309480786323547, -0.043211158365011215, -0.014955162070691586, 0.057278111577034, 0.035829078406095505, 0.0182925034314394, -0.004706352483481169, -0.01592375710606575, -0.02129434235394001, 0.017112895846366882, -0.024296607822179794, 0.051892366260290146, -0.03351989760994911, -0.049830321222543716, -0.0032840294297784567, 0.011808902025222778, 0.021166356280446053, -0.03908652067184448, 0.00037123984657227993, 0.01726342737674713, -0.006657408084720373, -0.01901979185640812, 0.06068390980362892, -0.02240218222141266, -0.05288746580481529, -0.040836066007614136, -0.3852454721927643, -0.051412638276815414, 0.051103316247463226, 0.012248807586729527, 0.04192465916275978, -0.06838443875312805, -0.0033284961245954037, 0.038552798330783844, 0.0009854476666077971, 0.04366470128297806, 0.08577408641576767, 0.019250037148594856, -0.01010145340114832, -0.06442868709564209, 0.018796304240822792, -0.012693340890109539, -0.00536844739690423, -0.04262716695666313, 0.0006887494819238782, 0.03434055298566818, 0.032468099147081375, -0.06618223339319229, 0.03246733546257019, -0.09180326014757156, 0.03348909318447113, -0.013242207467556, 0.10879836231470108, -0.037573955953121185, 0.051966629922389984, -0.06694191694259644, 0.0621153861284256, 0.0336819663643837, -0.03328854590654373, -0.033989399671554565, 0.04436790570616722, -0.032714612782001495, 0.013635520823299885, 0.10353473573923111, 0.007045551668852568, 0.0008655435522086918, 0.018423117697238922, -0.008416340686380863, -0.012100533582270145, -0.09782861173152924, 0.02825624868273735, 0.004265946801751852, -0.003772371681407094, -0.03280515596270561, 0.041694872081279755, -0.02024517022073269, -0.014916518703103065, 0.03451654314994812, 0.065476194024086, 0.025400357320904732, -0.003220780985429883, -0.026858672499656677, -0.08897591382265091, 0.008157539181411266, 0.006750568747520447, -0.02276773937046528, 0.012170755304396152, 0.03437669575214386, 0.061327431350946426, -0.04129648953676224, 0.01868623122572899, -0.007657689042389393, 0.004254700616002083, 0.012322369031608105, 0.04067522659897804, 0.03218567743897438, -0.01644025556743145, 0.02421719580888748, 0.008612580597400665, 0.045244038105010986, 0.013279964216053486, 0.06375902891159058, -0.026187414303421974, 0.013717922382056713, -0.012099487707018852, 0.013705674558877945, 0.0056821973994374275, 0.05613727867603302, 0.03367123007774353, 0.035650432109832764, -0.011385907419025898, 0.0295270849019289, 0.04353386536240578, 0.006242230534553528, 0.07448688894510269, 0.02787720039486885, -0.055682141333818436, -0.03263460099697113, -0.012711734510958195, 0.0632094219326973, 0.026478776708245277, 0.032290019094944, -0.2817035913467407, -0.00867270678281784, 0.010935058817267418, 0.06134132668375969, 0.0171387679874897, -0.055497605353593826, 0.017431126907467842, -0.04946829751133919, -0.020136142149567604, -0.04481697827577591, -0.040735624730587006, 0.03648022562265396, 0.047510623931884766, -0.047828879207372665, -0.04135257750749588, 0.029840735718607903, 0.10126780718564987, 0.003766007721424103, -0.023365480825304985, -0.006544363219290972, 0.01559794694185257, -0.0320572704076767, 0.17674985527992249, -0.0004616635851562023, -0.037880100309848785, 0.01957240141928196, 0.013179806061089039, -0.04932597652077675, 0.05964047089219093, 0.043322835117578506, 0.02659478224813938, 0.026808638125658035, 0.03138555586338043, -0.0053172935731709, 0.0424230620265007, 0.041549019515514374, -0.05269768834114075, -0.04225675016641617, 0.03512827679514885, 0.004568245727568865, -0.049143508076667786, 0.021344218403100967, -0.025771424174308777, -0.035237062722444534, 0.01519887987524271, -0.024187037721276283, -0.014294460415840149, -0.04360171779990196, -0.04394938424229622, -0.013426833786070347, -0.036510907113552094, 0.004350035451352596, -0.05260476469993591, -0.02001846767961979, 0.032255157828330994, 0.03155379742383957, 0.046040818095207214, 0.009718749672174454, -0.0022135130129754543, -0.012609892524778843, -0.03790925443172455, -0.07762842625379562, 0.021639078855514526, -0.03058173507452011, -0.02291872352361679], 'a210186a-4ca8-49b8-87e2-273595024777': [-0.023328525945544243, 0.06551314145326614, -0.021467771381139755, 0.01792910508811474, -0.04609546810388565, -0.06440593302249908, -0.017453595995903015, 0.03302735090255737, 0.04427129030227661, -0.008851611986756325, -0.02626403607428074, -0.0861775130033493, 0.05510074645280838, 0.00031313198269344866, 0.011776874773204327, -0.03776449337601662, 0.012796326540410519, 0.013153641484677792, -0.07733428478240967, -0.028891082853078842, 0.022645827382802963, 0.013623694889247417, 0.019654830917716026, -0.01579095795750618, 0.06017167493700981, 0.011450067162513733, -0.024741293862462044, -0.0009874803945422173, -0.008371171541512012, -0.22577810287475586, 0.027777977287769318, -0.04392683506011963, 0.009124664589762688, 0.02364908531308174, -0.012002554722130299, 0.03429396077990532, 0.007931465283036232, 0.024249279871582985, -0.03363613411784172, 0.012559588998556137, 0.035451970994472504, 0.017558280378580093, -0.040341347455978394, -0.012820935808122158, 0.05868988856673241, -0.046274855732917786, -0.03799249976873398, -0.01638638973236084, -0.08050717413425446, 0.05065739154815674, -0.03380471467971802, -0.01817498914897442, -0.013282017782330513, -0.0017069531604647636, 0.03702295571565628, 0.0033769283909350634, 0.05077000707387924, 0.07720188051462173, 0.013562146574258804, 0.04594343155622482, -0.023523643612861633, -0.0030634617432951927, -0.15265442430973053, 0.06808258593082428, -0.04113820195198059, 0.038266222923994064, -0.06442559510469437, -0.010926413349807262, -0.06882299482822418, 0.0972561314702034, -0.008860819041728973, -0.006703597027808428, -0.004255305975675583, 0.0926641896367073, 0.015365960076451302, -0.00317144556902349, 0.016909250989556313, 0.009850878268480301, 0.05374763533473015, -0.02357584796845913, 0.043853599578142166, 0.0071132611483335495, 0.01741328462958336, -0.00422882242128253, 0.01438536960631609, -0.038041286170482635, -0.015111302025616169, -0.04271405562758446, -0.02086307667195797, -0.04351252317428589, 0.002415152732282877, -0.0415547713637352, -0.0031650823075324297, 0.03738003596663475, -0.07829109579324722, -0.04721163585782051, 0.012372004799544811, 0.043041616678237915, -0.028379013761878014, 0.3382265269756317, -0.015390663407742977, 0.01537693664431572, -0.020021887496113777, -0.07524964958429337, 0.03168493136763573, -0.06919943541288376, -0.012801439501345158, 0.017110561951994896, 0.0019239040557295084, -0.00984970759600401, -0.08041876554489136, 0.003526590997353196, -0.016015518456697464, -0.10521592944860458, 0.016570569947361946, -0.02321643941104412, 0.041721414774656296, 0.004534066654741764, -0.017425337806344032, -0.0021829158067703247, 0.025385215878486633, -0.015432356856763363, -0.0404900461435318, 0.0010052196448668838, 0.04232681542634964, 0.054959580302238464, 0.034915026277303696, 0.057040393352508545, 0.04123123362660408, 0.06014912202954292, 0.03509566932916641, -0.019399963319301605, -0.051302503794431686, 0.006223179399967194, 0.03021864779293537, -0.00895918719470501, -0.02708250842988491, -0.013404796831309795, 0.0034140569623559713, -0.013794247061014175, -0.030855927616357803, -0.012517757713794708, 0.022373652085661888, 0.020802557468414307, -0.050743468105793, 0.09885930269956589, -0.0688762441277504, -0.0557757243514061, 0.004535665735602379, -0.017777374014258385, 0.018068993464112282, 0.06293629854917526, 0.03055417351424694, -0.058122001588344574, 0.05906329303979874, 0.03274911642074585, 0.03933516889810562, -0.035692889243364334, -0.015676436945796013, -0.02353866957128048, -0.011394916102290154, -0.029431629925966263, -0.030981386080384254, 0.08278702199459076, 0.00852559506893158, -0.018300088122487068, -0.06167217344045639, 0.019917858764529228, -0.006937876809388399, -0.06998435407876968, 0.06330185383558273, 0.0035477099008858204, -0.044439997524023056, 0.07311881333589554, 0.005251661874353886, -0.0004495475150179118, -0.040922291576862335, -0.005464422516524792, 0.015438416972756386, 0.023439504206180573, 0.01813530921936035, -0.04680139571428299, -0.010772151872515678, 0.03772728890180588, 0.02324751950800419, 0.018069926649332047, -0.049459151923656464, 0.03226405009627342, 0.07355888187885284, -0.014498156495392323, -0.02143263816833496, 0.04294779896736145, -0.01310410350561142, -0.010727441869676113, -0.01405832264572382, 0.016922159120440483, -0.014213073067367077, -0.004253819584846497, -0.03308703377842903, 0.04677168279886246, 0.08297780156135559, 0.10146203637123108, 0.023347903043031693, -0.023682937026023865, 0.007643376477062702, -0.012285006232559681, 0.08762430399656296, -0.07270552963018417, 0.04391469061374664, -0.018633149564266205, -0.08847817033529282, -0.014083515852689743, 0.00298095541074872, 0.015450643375515938, -0.015286915004253387, 0.013300683349370956, 0.04123922437429428, 0.007078372873365879, -0.05030176416039467, -0.012103530578315258, -0.02037530206143856, -0.009781005792319775, -0.05116599053144455, -0.3644830584526062, -0.03447785601019859, 0.03582886606454849, -0.022442635148763657, 0.044956788420677185, -0.07893615961074829, -0.029835907742381096, 0.01349895540624857, -0.001843127072788775, 0.03368071839213371, -0.0015884267631918192, -0.05774882435798645, -0.03849424049258232, 0.0008327224641107023, 0.03598051890730858, 0.016583211719989777, 0.00936378724873066, -0.06173465773463249, 0.0036523202434182167, 0.01951294206082821, 0.024676000699400902, -0.029760092496871948, 0.032299723476171494, -0.062067046761512756, 0.03421719744801521, 0.02736695110797882, 0.10436933487653732, -0.02514982782304287, 0.06870552897453308, -0.024158410727977753, 0.014262332580983639, 0.03251975029706955, -0.014631216414272785, -0.0015633710427209735, 0.02973676472902298, -0.033019136637449265, 0.03552810475230217, 0.0324256457388401, -0.019846847280859947, -0.021937936544418335, -0.005497862119227648, 0.014896601438522339, 0.018711555749177933, -0.0958094596862793, 0.013487315736711025, 0.012490504421293736, 0.02396250329911709, -0.0502278208732605, -0.011418942362070084, 0.02696344628930092, -0.009621906094253063, 0.07368817925453186, 0.02887004427611828, 0.035180676728487015, -0.007259956561028957, -0.00912204198539257, -0.058582331985235214, -0.03137914091348648, -0.0005243563209660351, -0.02844691090285778, -0.005607368890196085, -0.02006271295249462, 0.07748867571353912, -0.05893288925290108, -0.018648458644747734, -0.01631699688732624, -0.0032072202302515507, -0.004256578162312508, 0.007382548879832029, 0.028917115181684494, -0.03608965128660202, 0.058991286903619766, 0.0017889203736558557, -0.0050911735743284225, 0.0568060576915741, 0.06732445955276489, -0.04119173064827919, 0.02953648380935192, -0.06863152980804443, 0.007983250543475151, 0.04691058397293091, 0.02384856715798378, 0.05152842029929161, -0.0039667910896241665, 0.010382536798715591, 0.016537226736545563, 0.08459220826625824, -0.017016088590025902, 0.029220100492239, 0.01197057869285345, -0.061387527734041214, -0.006062959786504507, -0.020980600267648697, 0.07006506621837616, 0.01274352241307497, -0.023148484528064728, -0.2805001437664032, 0.025182366371154785, 0.07177869230508804, 0.0356961190700531, 0.056772489100694656, 0.052139412611722946, 0.023366160690784454, -0.03471701592206955, -0.03412352502346039, -0.03848569095134735, -0.05629817396402359, 0.033874593675136566, 0.04607885330915451, -0.04758061468601227, -0.056735046207904816, 0.04704932123422623, 0.0677071213722229, -0.011174771934747696, -0.027078986167907715, -0.0022626144345849752, 0.03117988631129265, -0.015851091593503952, 0.18943622708320618, -0.035760484635829926, -0.028551286086440086, 0.01782648265361786, 0.01831706613302231, -0.005918645765632391, 0.042727380990982056, 0.047543324530124664, -0.02768041007220745, 0.052064813673496246, 0.08193784952163696, 0.029953809455037117, 0.019796984270215034, -0.011412185616791248, -0.04362919554114342, -0.06825365871191025, 0.0518454983830452, 0.012880291789770126, -0.03279142826795578, 0.018021387979388237, -0.025913264602422714, -0.0443011149764061, 0.012559047900140285, 0.015544533729553223, 0.019065996631979942, -0.004049354232847691, -0.033721357583999634, 0.03651553392410278, -0.026842761784791946, 0.007343161851167679, -0.01061892881989479, 0.0064512281678617, 0.04998694732785225, 0.007757952436804771, 0.030488580465316772, 0.001987408148124814, -0.002528809243813157, -0.015687953680753708, -0.0500977598130703, -0.017115483060479164, -0.009573563933372498, 0.03896135464310646, 0.019217992201447487], '3d199ae9-9787-41d4-bde5-efd220aee357': [-0.025731632485985756, 0.009284882806241512, 0.004620988387614489, -0.0015465994365513325, 0.019841186702251434, -0.06060067191720009, -0.0094826715067029, 0.014078126288950443, 0.054487444460392, -0.007910710759460926, -0.014191096648573875, -0.07688116282224655, 0.007541815750300884, 0.05339881777763367, -0.016915496438741684, -0.007941178046166897, -0.05378637835383415, -0.00438585365191102, -0.07541122287511826, 0.016769565641880035, 0.07154306024312973, 0.02940572239458561, 0.02900482527911663, -0.036908965557813644, 0.04455319046974182, 0.05379381775856018, -0.010808942839503288, -0.010453295893967152, 0.03520257771015167, -0.225922092795372, 0.03373518958687782, -0.024823512881994247, 0.03917607292532921, 0.010189470835030079, -0.02325277216732502, 0.014186372980475426, -0.01182158850133419, -0.02522573247551918, 0.00040462755714543164, 0.03510313108563423, -0.007827991619706154, 0.003368041478097439, 0.019432807341217995, -0.03126092627644539, 0.03583214059472084, -0.04168575257062912, -0.0485166572034359, -0.006389233283698559, -0.046183161437511444, 0.05774611979722977, 0.0170455165207386, -0.005314796231687069, -0.015620042569935322, 0.048517242074012756, 0.01275137159973383, 0.010217354632914066, 0.03409435600042343, 0.08359019458293915, -0.021669702604413033, -0.00956005323678255, 0.011602682061493397, 0.0206711757928133, -0.18183009326457977, 0.07378867268562317, -0.05618166923522949, 0.016091646626591682, 0.015164205804467201, -0.0006135958828963339, -0.014655298553407192, 0.06793604046106339, -0.034300919622182846, -0.027813078835606575, -0.010691325180232525, 0.08789782971143723, 0.03573041781783104, 0.00597723014652729, 0.04988968372344971, 0.005544140003621578, 0.011602343991398811, 0.025572016835212708, 0.032886799424886703, -0.014069583266973495, 0.05024336650967598, -0.046749792993068695, -0.0028567977715283632, 0.01601574383676052, -0.03679507225751877, -0.04248780757188797, -0.007537811994552612, -0.012398568913340569, -0.01786728762090206, -0.01369213405996561, -0.011866822838783264, 0.08805355429649353, -0.07132235169410706, -0.03159213438630104, 0.03285088762640953, 0.04010860249400139, -0.05365975573658943, 0.32909828424453735, -0.014160280115902424, 0.0029087623115628958, -0.050856735557317734, -0.06356456130743027, 0.010750294663012028, -0.02837049961090088, -0.005872540641576052, 0.04130595922470093, -0.013517089188098907, 0.06630799174308777, -0.08202582597732544, 0.053255438804626465, -0.01883004792034626, -0.056927118450403214, -0.011851103976368904, -0.058043304830789566, 0.026801351457834244, 0.04814178869128227, 0.018247775733470917, 0.0505196675658226, -0.006998281925916672, 0.0227755568921566, -0.04439462721347809, -0.019505655393004417, 0.016736214980483055, 0.060346122831106186, 0.03751150518655777, 0.024918923154473305, 0.02862349897623062, 0.02230406366288662, 0.03820047900080681, -0.010999207384884357, -0.10100556910037994, 0.008633275516331196, -0.009723225608468056, 0.004692975897341967, 0.02323298342525959, -0.000233551487326622, -0.03767681121826172, -0.020370613783597946, 0.02809831313788891, 0.025742288678884506, 0.018495438620448112, 0.03034660592675209, -0.023397352546453476, 0.12401670217514038, -0.05427395552396774, -0.042311858385801315, -0.046787720173597336, -0.00835846085101366, 0.002995899412781, 0.07171667367219925, 0.017284035682678223, -0.04319782555103302, 0.05429462715983391, 0.059235863387584686, 0.057875581085681915, -0.02709396369755268, -0.09249391406774521, -0.04597547650337219, -0.01883559487760067, -0.029207000508904457, -0.03843902051448822, 0.06604170799255371, 0.05985866114497185, -0.02846720442175865, -0.004352340009063482, -0.005928492173552513, 0.039094146341085434, -0.08457572013139725, 0.03363289684057236, -0.038807906210422516, -0.06680342555046082, 0.05257285013794899, -0.030841201543807983, -0.00358227058313787, -0.03339405357837677, 0.009420405142009258, -0.018014557659626007, 0.05212094262242317, 0.005022270604968071, -0.017632901668548584, -0.009370940737426281, 0.04866259917616844, 0.020197924226522446, 0.008023444563150406, -0.025598496198654175, 0.02537723071873188, 0.05937986075878143, -0.030729688704013824, 0.05958157405257225, 0.0584443099796772, -0.04191472753882408, -0.011378531344234943, 0.003020582953467965, -0.007897661067545414, 0.0010356439743191004, 0.010872025974094868, -0.0024587761145085096, -0.005797814577817917, 0.08206638693809509, 0.06999843567609787, 0.019158903509378433, -0.03700336813926697, -0.008716864511370659, -0.02381034381687641, 0.028693746775388718, -0.02932761237025261, 3.984525756095536e-05, -0.01704968512058258, -0.1030561551451683, 0.03049737960100174, -0.022918257862329483, -0.0005300665507093072, -0.02875128760933876, 0.03175553306937218, 0.018789779394865036, 0.02015567384660244, -0.038447387516498566, -0.01989126019179821, -0.011409061960875988, 0.015346068888902664, -0.030619341880083084, -0.3692702353000641, -0.013103789649903774, -0.007179416250437498, 0.011928850784897804, 0.03489861637353897, -0.06380804628133774, -0.01097321230918169, 0.0295716505497694, -0.005448445212095976, 0.011840770952403545, 0.028147634118795395, -0.05299634113907814, -0.06263739615678787, -0.0309633519500494, -0.00518204178661108, 0.0315992496907711, -0.043377701193094254, -0.05501921847462654, 0.024365827441215515, 0.03529941663146019, 0.0022156378254294395, 0.044526055455207825, 0.01757814548909664, -0.07004329562187195, 0.0072232456877827644, -0.02595113031566143, 0.07284166663885117, -0.013137474656105042, 0.06356155872344971, -0.0609164722263813, 0.013749540783464909, 0.02147313393652439, 0.03358307108283043, -0.016838788986206055, 0.07565930485725403, -0.045056700706481934, 0.011089847423136234, 0.028218626976013184, 0.0392984114587307, -0.008074462413787842, -0.03645377978682518, 0.020101184025406837, -0.020153136923909187, -0.055480532348155975, 0.011414178647100925, -0.035305097699165344, -2.5602139430702664e-05, -0.09733761847019196, 0.06932753324508667, 0.041066575795412064, -0.03309814631938934, 0.06999468803405762, 0.01639539748430252, 0.009496279060840607, 0.016114238649606705, -0.027029292657971382, -0.07018055766820908, -0.02385365031659603, 0.017711611464619637, -0.03993498906493187, 0.029013080522418022, -0.013315586373209953, 0.04254107549786568, -0.06286849826574326, -0.011924357153475285, -0.04302603378891945, 0.007213542237877846, -0.015596642158925533, 0.03640908747911453, -0.012938824482262135, -0.011150690726935863, 0.09747321903705597, -0.01283253263682127, 0.002704421989619732, 0.03581085801124573, 0.011125695891678333, -0.024360554292798042, 0.015489538200199604, -0.05684299021959305, 0.011012631468474865, 0.01492998469620943, -0.028319906443357468, 0.06647714972496033, 0.00218873075209558, 0.03697439283132553, 0.034901391714811325, 0.09326207637786865, 0.049649015069007874, 0.026063228026032448, 0.03909607604146004, -0.0634705200791359, -0.03785707801580429, -0.012819261290133, 0.054028261452913284, 0.038006819784641266, -0.024933720007538795, -0.28113964200019836, -0.009555185213685036, 0.01707528345286846, 0.007573469076305628, 0.05132874846458435, 0.03156546503305435, -0.036101434379816055, -0.04319663345813751, -0.024457015097141266, 0.017176631838083267, -0.0635569840669632, 0.06413830071687698, 0.04735924303531647, -0.05481802672147751, -0.06686186045408249, 0.040585536509752274, 0.12200777977705002, -0.020901570096611977, 0.0038081249222159386, -0.01860807277262211, 0.010486898012459278, -0.0664052814245224, 0.15502741932868958, -0.007924508303403854, 0.0018291679443791509, -0.015739306807518005, -0.0421469584107399, -0.008283177390694618, 0.06829223036766052, -0.007160852197557688, 0.027975255623459816, 0.02644435502588749, 0.04964751377701759, 0.013535231351852417, 0.014573482796549797, 0.0107624726369977, -0.014095407910645008, -0.005078431684523821, 0.02791927382349968, 0.03997315093874931, 0.023738117888569832, -0.004964583553373814, -0.010280822403728962, -0.019629038870334625, 0.028219351544976234, -0.002740992698818445, 0.015614138916134834, -0.03952871263027191, -0.007017083000391722, -0.012697634287178516, -0.0032122244592756033, -0.03328961133956909, -0.07005424052476883, -0.013857558369636536, 0.05451422557234764, 0.044151268899440765, -0.0027389407623559237, -0.003424862865358591, -0.015689343214035034, 0.0015357468510046601, -0.03562719747424126, -0.04617967829108238, -0.016949990764260292, 0.05558754503726959, 0.0020335656590759754], '3048529c-f4aa-4266-bd70-ef21f4f9bc47': [-0.059751246124506, 0.021524393931031227, 0.009598799981176853, 0.01406334899365902, -0.012158934958279133, -0.0458417646586895, 0.0060812425799667835, 0.03592324256896973, 0.02677980065345764, -0.01694384403526783, 0.01798848621547222, -0.06501425057649612, 0.03575978800654411, 0.023205362260341644, 0.005736729130148888, -0.0027104844339191914, -0.055722564458847046, -0.022335702553391457, -0.07656867057085037, -0.006292370148003101, 0.07181500643491745, 0.025101695209741592, -0.008606573566794395, -0.004065097309648991, -0.005226736888289452, 0.07367047667503357, 0.01586880162358284, -0.053018949925899506, 0.07617375999689102, -0.21005402505397797, 0.032773226499557495, -0.04132021963596344, 0.050407856702804565, 0.030971013009548187, -0.005247322376817465, 0.024001145735383034, -0.03518577665090561, 0.052820440381765366, -0.018528902903199196, 0.04168367013335228, -0.011125112883746624, -0.01293649710714817, -0.009897226467728615, 0.02213902957737446, 0.017760569229722023, -0.079958975315094, -0.08744588494300842, 0.003251377260312438, 0.02006564848124981, 0.03134568780660629, -0.0724891722202301, -0.06650544703006744, -0.03214495629072189, 0.006525253877043724, 0.013425475917756557, 0.0022792392410337925, 0.017844034358859062, 0.012469853274524212, -0.00744443666189909, 0.030024005100131035, 0.03759812191128731, 0.029250280931591988, -0.15982447564601898, 0.08223775029182434, -0.03745964914560318, 0.04945579171180725, -0.04809689521789551, 0.01932588592171669, -0.009002454578876495, 0.05813585966825485, -0.038527801632881165, -0.006335420999675989, 0.07423018664121628, 0.10983344167470932, 0.03837626427412033, 0.010371758602559566, 0.019964629784226418, -0.0068841115571558475, 0.006154269445687532, 0.032759055495262146, -0.00674465810880065, -0.0012048111530020833, 0.046531662344932556, -0.0486101433634758, 0.03029628098011017, -0.03358151763677597, -0.00047187969903461635, 0.003129007760435343, -0.010140709578990936, -0.018797285854816437, 0.0008750961278565228, -0.04870322719216347, 0.04779394716024399, 0.09344901144504547, -0.04177317023277283, -0.05316538363695145, 0.003993757534772158, 0.0005438849329948425, 0.0024299726355820894, 0.37181732058525085, -7.112669118214399e-05, 0.027419712394475937, -0.03688826039433479, -0.03656310960650444, 0.03419199585914612, -0.020246142521500587, 0.031056402251124382, -0.03163352236151695, -0.009424585849046707, 0.039142657071352005, -0.0241725854575634, 0.013765603303909302, 0.01805485412478447, -0.0910191535949707, -0.016211306676268578, -0.005904859397560358, 0.016663849353790283, 0.00022877582523506135, 0.054445989429950714, 0.04163867235183716, -0.01898588053882122, -0.02765573561191559, -0.06055355817079544, -0.01306439284235239, 0.017986435443162918, 0.03075537458062172, 0.008007138967514038, 0.0065267812460660934, -0.011829054914414883, 0.038588330149650574, 0.024311810731887817, 0.012383372522890568, -0.03492623567581177, -0.02769622392952442, 0.01512920018285513, 0.01708500273525715, -0.0202669445425272, -0.003049884457141161, 0.04225919023156166, -0.008111556060612202, 0.030787285417318344, 0.005192196927964687, 0.01930852048099041, -0.0038398897740989923, -0.015560571104288101, 0.13564437627792358, -0.03050764836370945, -0.03401953727006912, -0.06844020634889603, 0.009922089986503124, 0.007121420465409756, 0.04758339747786522, 0.020100554451346397, -0.06658408045768738, 0.02829703316092491, 0.06326615810394287, 0.07206558436155319, -0.0016768666682764888, 0.006769733037799597, -0.04828675091266632, -0.0077056861482560635, -0.002707391045987606, -0.05403393879532814, 0.07007055729627609, 0.04784640297293663, -0.012199862860143185, -0.013718144036829472, 0.04626954719424248, 0.005569797474890947, -0.08655756711959839, 0.03306485339999199, 0.022309178486466408, -0.06264735013246536, 0.11629091948270798, 0.026676971465349197, 0.06291890144348145, -0.05362602695822716, 0.023932138457894325, 0.03894730284810066, 0.028730783611536026, 0.00892569124698639, -0.05374647304415703, -0.06180941313505173, 0.017138123512268066, -0.021751176565885544, 0.0022210010793060064, -0.046821776777505875, -0.03437543660402298, 0.009987856261432171, -0.02726006880402565, -0.0022443935740739107, 0.07670130580663681, -0.049885958433151245, 0.028357388451695442, -0.04235922545194626, 0.007556162308901548, 0.011732205748558044, -0.042458031326532364, -0.018830278888344765, -0.04962018504738808, 0.05673808977007866, 0.03815535828471184, 0.019485440105199814, 0.0462399460375309, 0.027043668553233147, -0.07691211998462677, 0.013326691463589668, -0.03573586419224739, 0.0737919956445694, -0.0395585261285305, -0.08552005887031555, -0.020464662462472916, -0.029089994728565216, -0.023748157545924187, -0.03904126212000847, -0.040970947593450546, -0.025405190885066986, 0.03909294307231903, 0.00416433485224843, 0.0300774946808815, -0.007900695316493511, -0.04451495409011841, -0.03983823210000992, -0.3326154947280884, -0.030725451186299324, 0.015100662596523762, 0.022985361516475677, 0.022755015641450882, -0.07505027949810028, -0.015636304393410683, 0.015391766093671322, -0.022569715976715088, 0.006162580568343401, 0.013300991617143154, -0.03385274112224579, -0.00902195367962122, -0.04486071690917015, 0.004373741801828146, 0.02966228313744068, 0.006988275330513716, -0.06101204827427864, 0.030660714954137802, 0.02917773462831974, 0.02681066282093525, -0.0159052275121212, 0.01582927256822586, -0.057161372154951096, -0.006367128808051348, -0.02132883109152317, 0.0988319143652916, -0.009611313231289387, 0.01785936765372753, -0.026769012212753296, 0.08573303371667862, 0.013524103909730911, 0.01374204084277153, -0.08107797801494598, 0.04395300894975662, -0.033519040793180466, -0.022854464128613472, 0.06301752477884293, 0.004327083937823772, 0.0010274684755131602, -0.009542872197926044, 0.030270913615822792, -0.008023755624890327, -0.026796668767929077, -0.0198805071413517, 0.017757197842001915, -0.010536346584558487, -0.034823618829250336, 0.06449706852436066, 0.003421967616304755, -0.0011418202193453908, 0.07574645429849625, 0.005736121907830238, -0.023680420592427254, -0.0014106682501733303, -0.04788951575756073, -0.008948312141001225, -0.03790130093693733, -0.04657657444477081, -0.04921725019812584, 0.021380482241511345, 0.0009335239883512259, 0.020306136459112167, -0.020269587635993958, 0.009181058034300804, 0.008780933916568756, 0.042513858526945114, -0.006921618711203337, 0.004668448120355606, -0.0013151817256584764, -0.05499088764190674, 0.057694219052791595, 0.0012437652330845594, -0.007555235177278519, 0.051128488034009933, 0.048508089035749435, -0.030252793803811073, 0.01106539461761713, -0.01434237975627184, 0.026255503296852112, 0.020446252077817917, -0.04495641589164734, 0.047954805195331573, 0.01891123130917549, 0.01154305599629879, 0.053393613547086716, 0.03164602443575859, 0.04513859748840332, 0.026995118707418442, 0.019923139363527298, -0.007009698078036308, 0.011835962533950806, -0.01447533443570137, 0.08314523100852966, 0.02016492933034897, 0.0003118453605566174, -0.29386720061302185, 0.010326603427529335, -0.005313510075211525, -0.0248752199113369, 0.06188163906335831, 0.03686671704053879, 0.012149832211434841, -0.0536886528134346, 0.010665896348655224, -0.012546573765575886, -0.03639283403754234, -0.02048337832093239, -0.014460615813732147, -0.08239965885877609, -0.06711667031049728, -0.0025066055823117495, 0.12862956523895264, -0.01594761572778225, 0.0013049145927652717, -0.02290959469974041, 0.007302913349121809, -0.022752271965146065, 0.1844533234834671, 0.04493742436170578, -0.022565854713320732, -0.05514397472143173, -0.001444028690457344, -0.012716026045382023, 0.051125556230545044, 0.006149887107312679, 0.03062519244849682, -0.00595735153183341, 0.10271788388490677, 0.033520523458719254, 0.0314146988093853, -0.020160788670182228, 0.012158192694187164, -0.02663455344736576, 0.028152810409665108, 0.012940539978444576, -0.001616532332263887, 0.00196063588373363, -0.06350956857204437, 0.012464256025850773, 0.04378943145275116, 0.0008451769826933742, 0.019135847687721252, -0.06721144914627075, -0.018194863572716713, 0.022084007039666176, -0.028916846960783005, -0.053678177297115326, -0.05698064714670181, 0.006182512268424034, 0.031235508620738983, -0.035319216549396515, 0.0024833930656313896, -0.008920358493924141, 0.01561872661113739, -0.007199374958872795, -0.04149649664759636, -0.018709614872932434, 0.03562410548329353, -0.006549417041242123, 0.02550830878317356], '92c049e4-0b98-4564-baf9-c63d186125b3': [-0.05079682171344757, 0.023534726351499557, -0.0012112421682104468, -0.02191145531833172, -0.03290930762887001, 0.035950105637311935, -0.04110611975193024, 0.007327334024012089, 0.03653588145971298, 0.00747495424002409, -0.007469390984624624, -0.04644009470939636, 0.028910616412758827, 0.0723317489027977, -0.0026102596893906593, -0.00040168798295781016, -0.053061455488204956, 0.05424955487251282, -0.03377543389797211, -0.04456588998436928, 0.08504143357276917, -0.01489599235355854, 0.021968087181448936, -0.06696891784667969, 0.003502599196508527, 0.03403688967227936, -0.01862667128443718, -0.018086211755871773, 0.020533405244350433, -0.23853111267089844, 0.006265819538384676, 0.0072525879368186, 0.04391016438603401, -0.0021571069955825806, -0.08643840253353119, 0.005967403762042522, -0.09227381646633148, -0.008895708248019218, -0.002957245334982872, 0.04533267021179199, -0.008504217490553856, 0.03711536154150963, -0.01676972210407257, -0.03188030421733856, 0.05467340350151062, -0.048684053122997284, -0.033788248896598816, -0.02161535434424877, -0.049908194690942764, 0.030826333910226822, -0.003292857203632593, 0.0029866902623325586, -0.03118620067834854, 0.08851378411054611, 0.012151858769357204, -0.0007382725016213953, 0.03782820701599121, 0.027565615251660347, -0.0068995836190879345, -0.022471856325864792, 0.03707994148135185, 0.027093159034848213, -0.12921608984470367, 0.07112035900354385, -0.027587013319134712, 0.034927740693092346, -0.024339789524674416, 0.012614871375262737, -0.0014545581070706248, 0.06035606563091278, -0.0009049844811670482, -0.01156329084187746, 0.011866048909723759, 0.06919442862272263, 0.05036905035376549, 0.031634338200092316, 0.056446924805641174, 0.007045180536806583, 0.020224133506417274, -0.004397075157612562, 0.013100082986056805, -0.03560945764183998, 0.047779180109500885, -0.06251048296689987, 0.015225882641971111, -0.02403944917023182, -0.02756364643573761, -0.023348813876509666, -0.04042181000113487, -0.006662832107394934, 0.0002778805501293391, -0.016694003716111183, -0.023797573521733284, 0.06248657405376434, -0.046660199761390686, -0.06304575502872467, 0.028127707540988922, 0.055961865931749344, -0.037394121289253235, 0.3435196280479431, 0.021107913926243782, -0.010716846212744713, -0.05669858306646347, -0.025701899081468582, 0.01712917350232601, -0.013511501252651215, -0.006056938320398331, 0.022666243836283684, -0.06512480974197388, 0.021880237385630608, -0.07345189899206161, 0.05084773153066635, -0.03972867876291275, -0.047005247324705124, 0.019485829398036003, -0.03410576283931732, 0.042337898164987564, 0.017023753374814987, -0.03899506852030754, 0.03195839747786522, -0.05397108942270279, 0.042194727808237076, -0.0594172365963459, 0.013524762354791164, 0.006506253965198994, 0.04105430096387863, 0.06570183485746384, 0.0598679855465889, 0.04674606770277023, 0.06824400275945663, 0.03741667792201042, 0.01514498796314001, -0.09193471074104309, 0.01809976063668728, -0.008638652041554451, 0.04035491868853569, 0.0065907868556678295, -0.02740791067481041, -0.005696344655007124, -0.012525944039225578, -0.012832123786211014, 0.018622534349560738, 0.04967646673321724, 0.022255083546042442, -0.0424499548971653, 0.1267087757587433, -0.07094630599021912, -0.028858067467808723, -0.08008856326341629, 0.02155524492263794, -0.01145895104855299, 0.07853832095861435, -0.0038130516186356544, -0.05389412119984627, 0.04538082331418991, 0.069005087018013, 0.044312734156847, -0.039682500064373016, -0.05666620656847954, -0.02657422237098217, -0.02520705945789814, -0.0022966566029936075, 0.009019697085022926, 0.07664057612419128, 0.08184413611888885, -0.059470757842063904, -0.00506915058940649, -0.004105217754840851, 0.021720899268984795, -0.050029341131448746, 0.04915735498070717, -0.025014396756887436, -0.02601616457104683, 0.062316302210092545, -0.0424191877245903, 0.03937806561589241, -0.05987048149108887, -0.013240490108728409, 0.01939784176647663, 0.05454440042376518, 0.01695803925395012, -0.03967221453785896, 0.00907296221703291, 0.030289502814412117, -0.011652783490717411, -0.02090863324701786, -0.010487271472811699, -0.003463117405772209, 0.016297118738293648, -0.056109968572854996, 0.014055157080292702, 0.0293622724711895, -0.030804267153143883, 0.006227532401680946, -0.017561670392751694, -0.017082257196307182, 0.02838507480919361, 0.010360253974795341, -0.042164403945207596, -0.011231656186282635, 0.039348941296339035, 0.04968353733420372, -0.015188763849437237, -0.02865133248269558, 0.006567134987562895, -0.037686072289943695, 0.050279296934604645, -0.003976665902882814, 0.01830388233065605, -0.009638235904276371, -0.08834277093410492, -0.007175695616751909, 0.0001433819270459935, -0.027035431936383247, -0.030252085998654366, 0.004670080728828907, -0.011922221630811691, 0.053470488637685776, 0.016068415716290474, 0.009219287894666195, -0.030398409813642502, -0.012982781045138836, 0.0006457588751800358, -0.37553486227989197, -0.004076170269399881, 0.02071443386375904, -0.006352350115776062, 0.026508210226893425, -0.05877000093460083, -0.010121429339051247, 0.03194509074091911, -0.006122078746557236, 0.006522193551063538, 0.03707168251276016, -0.04277243837714195, -0.022839443758130074, -0.07548762857913971, -0.008098926395177841, 0.04156643524765968, 0.006817168090492487, -0.03595412150025368, -0.029018612578511238, 0.04727398604154587, 0.022002961486577988, 0.013579343445599079, 0.040972497314214706, -0.060056012123823166, 0.028957447037100792, -0.04763681814074516, 0.09558966755867004, -0.03445349633693695, 0.07097044587135315, -0.033453524112701416, 0.01868058368563652, -0.0025019445456564426, 0.0032807171810418367, 0.005189974792301655, 0.07922540605068207, -0.060587912797927856, -0.005528717301785946, 0.028854265809059143, 0.030549034476280212, -0.002062486717477441, -0.029496358707547188, -0.018635988235473633, 0.023250769823789597, -0.04358673840761185, 0.0009241302032023668, -0.020316386595368385, -0.059258971363306046, -0.06771350651979446, 0.030639562755823135, 0.029987595975399017, 0.023713048547506332, 0.023253751918673515, 0.04831419512629509, -0.004778214264661074, -0.03052171692252159, -0.0375681109726429, -0.0336771123111248, -0.023987118154764175, -0.028463009744882584, -0.0569714680314064, 0.003342284355312586, -0.029228907078504562, -0.0019535478204488754, -0.031392570585012436, -0.014228571206331253, -0.0034379998687654734, 0.04087725281715393, 0.017498185858130455, 0.01818268932402134, 0.041604530066251755, -0.027034202590584755, 0.0968354120850563, 0.01106325164437294, 0.016154732555150986, 0.06505493819713593, 0.02136554941534996, -0.0049649630673229694, 0.020820999518036842, -0.03297557681798935, 0.005934804677963257, 0.018815090879797935, -0.013926123268902302, 0.0718347504734993, 0.02022162266075611, 0.06106741353869438, 0.010377006605267525, 0.08307833969593048, 0.03174665942788124, 0.01176986750215292, 0.061014000326395035, -0.0398157574236393, 0.021354667842388153, -0.014128771610558033, 0.03021002560853958, -0.002729126950725913, -0.012504798360168934, -0.26387953758239746, 0.04089874401688576, 0.039533693343400955, 0.040687572211027145, 0.010517892427742481, -0.00036869372706860304, 0.02448921836912632, -0.034860942512750626, -0.014603108167648315, 0.015148553997278214, -0.08588830381631851, 0.07065007835626602, 0.04736447334289551, -0.06907521188259125, -0.053667668253183365, 0.03247852995991707, 0.10726384073495865, -0.027770228683948517, 0.000318121281452477, -0.02299496904015541, -0.005969851277768612, -0.00430486211553216, 0.1834668666124344, -0.04379173368215561, -0.00366289378143847, -0.08659610897302628, -0.04057734087109566, -0.04241827875375748, 0.021535562351346016, -0.021367870271205902, 0.04862139746546745, 0.020079446956515312, 0.05657977983355522, 0.04308682307600975, -0.004472910426557064, 0.03686050698161125, 0.025631897151470184, 0.006317933555692434, 0.059443097561597824, 0.0379653126001358, 0.052399326115846634, -0.036004841327667236, -0.03611808642745018, -0.04046878591179848, 0.04313436895608902, 0.014583305455744267, 0.010749666020274162, -0.023760512471199036, -0.02259722724556923, 0.0074780285358428955, -0.03595973923802376, -0.01150189246982336, -0.04641134664416313, -0.01161168236285448, 0.021684378385543823, 0.006094041280448437, -0.009773765690624714, 0.006878141779452562, -0.016346825286746025, -0.00823062751442194, -0.004351416137069464, -0.08077475428581238, 0.010750283487141132, 0.02529258280992508, -0.0064345174469053745], '8476e1b3-b9cc-427f-bd26-dae9013263d4': [-0.09171140193939209, 0.054060451686382294, 0.02740282192826271, -0.04533250629901886, -0.014440811239182949, -0.008002369664609432, -0.006967952474951744, -0.025773296132683754, 0.02599671296775341, 0.003737302729859948, 0.01196594350039959, -0.10594160854816437, -0.016444586217403412, 0.0014764385996386409, -0.022072970867156982, -0.030522309243679047, -0.0909702330827713, 0.03644503280520439, -0.04865144193172455, -0.016099803149700165, 0.07218645513057709, -0.022614972665905952, 0.03757288306951523, -0.025230079889297485, 0.03200887143611908, 0.03050900250673294, -0.02467155084013939, 0.015324479900300503, 0.011112285777926445, -0.26661333441734314, 0.016632793471217155, 0.03733672946691513, 0.008805617690086365, -0.04283982887864113, -0.05372628569602966, 0.012060320004820824, -0.040459658950567245, 0.006077143829315901, 0.012419170700013638, 0.05154735967516899, 0.02095726877450943, 0.022046759724617004, -0.02129107527434826, -0.030955322086811066, 0.029333151876926422, -0.011616750620305538, -0.002084790263324976, -0.0009226110414601862, -0.0024014597292989492, 0.00545821338891983, 0.0052871098741889, 0.042501311749219894, -0.01974458061158657, 0.02223220467567444, 0.02325538359582424, 0.01479380764067173, 0.05609454587101936, 0.02327856421470642, 0.013542795553803444, 0.008077086880803108, 0.012853574939072132, -0.0025544294621795416, -0.15105098485946655, 0.06404907256364822, 0.04027768597006798, 0.006329911760985851, -0.036106716841459274, -0.07088979333639145, 0.008896068669855595, 0.009043876081705093, 0.0038157973904162645, -0.010875615291297436, -0.00149192800745368, 0.02110997959971428, 0.0636654943227768, -0.00864789355546236, -0.0050974683836102486, 0.009393460117280483, -0.014569347724318504, -0.023867404088377953, -0.04262056201696396, -0.0026830434799194336, -0.01694994978606701, -0.024445023387670517, 0.03644649684429169, 0.003943298477679491, 0.01834864355623722, 0.008321461267769337, -0.006270549725741148, -0.019674278795719147, -0.03499063104391098, -0.02329394407570362, -0.07491091638803482, 0.030410876497626305, -0.0030028026085346937, -0.02805258519947529, 0.04923829808831215, 0.04182468354701996, -0.037185944616794586, 0.3938031494617462, -0.02518937736749649, -0.0023463484831154346, -0.028278758749365807, 0.02669050358235836, 0.018229106441140175, -0.03641156852245331, -0.019005734473466873, -0.0023714108392596245, -0.048528268933296204, -0.016981493681669235, -0.004394847434014082, 0.0395205095410347, 0.0015803653514012694, -0.083781898021698, -0.06444051116704941, -0.04950755462050438, -0.001320136827416718, 0.010147921741008759, 0.03509483113884926, 0.027063073590397835, -0.01059224084019661, 0.02878686599433422, -0.009867534041404724, 0.03360293433070183, 0.0014870987506583333, 0.03220361843705177, 0.00450939079746604, 0.07898174226284027, -0.004647871945053339, 0.06309580057859421, 0.04571469500660896, -0.035345301032066345, -0.04705037921667099, -7.631140033481643e-05, 0.01075104158371687, 0.04285833612084389, 0.021232156082987785, -0.001970874145627022, 0.02108633890748024, 0.002841512206941843, -0.050223417580127716, 0.022684186697006226, 0.034129831939935684, -0.02254503220319748, 0.018711837008595467, 0.1466599851846695, -0.07696975767612457, -0.02088109590113163, -0.030658813193440437, -0.036736585199832916, -0.0006872718222439289, 0.062423042953014374, -0.0193238016217947, -0.019348308444023132, -0.008234982378780842, 0.05592756345868111, -0.017473600804805756, -0.0027289448771625757, -0.015931500121951103, -0.027227746322751045, -0.054650112986564636, -0.015666157007217407, 0.04130113497376442, 0.09545080363750458, 0.0080522196367383, -0.036320701241493225, -0.05527801439166069, 0.017816927284002304, -0.010723241604864597, -0.034406550228595734, 0.02243281714618206, -0.031303733587265015, -0.04393483325839043, -0.0014666691422462463, 0.0538506917655468, 0.027999598532915115, -0.02163221500813961, -0.010123874992132187, 0.038859691470861435, 0.041058167815208435, 0.04373851791024208, -0.02613106556236744, 0.05027969926595688, 0.02642778679728508, -0.05008114129304886, 0.020870568230748177, -0.04193594679236412, -0.025008773431181908, -0.01020662859082222, -0.01640264131128788, 0.0066399653442204, 0.004381923470646143, -0.047306451946496964, 0.015465755946934223, -0.048464659601449966, -0.021280063316226006, 0.024785874411463737, 0.016894783824682236, -0.01085648126900196, -0.016410639509558678, 0.05388377234339714, 0.05322825536131859, -0.04443293437361717, 0.01910642720758915, -0.01720569282770157, 0.004131312947720289, 0.025412410497665405, -0.02933642640709877, 0.01992953009903431, -0.015197779051959515, -0.029521947726607323, 0.00497664138674736, 0.0003128174284938723, -0.017219850793480873, -0.06038989871740341, -0.04741412773728371, 0.021390819922089577, 0.009974143467843533, 0.0012580447364598513, -0.00030893628718331456, 0.003192698583006859, -0.06291462481021881, 0.012835348956286907, -0.358169287443161, 0.030904455110430717, -0.01755792647600174, -0.009080935269594193, 0.03663473203778267, -0.04425142705440521, 0.04039322957396507, 0.013314344920217991, 0.02725912071764469, 0.006163176614791155, 0.05155282840132713, 0.031672488898038864, -0.04141814261674881, -0.040271662175655365, -0.060516566038131714, 0.03721782937645912, 0.0393962562084198, -0.026345811784267426, -0.03315991163253784, 0.037531863898038864, -0.0007723264279775321, 0.0013115268666297197, -0.03520950302481651, -0.034164704382419586, 0.06329904496669769, -0.009642904624342918, 0.09724359214305878, -0.03324870392680168, 0.07306888699531555, -0.08622676879167557, -0.026034710928797722, 0.02233550138771534, 0.0030355362687259912, 0.0350789837539196, 0.04415806382894516, -0.06570329517126083, 0.00043059559538960457, 0.06114630028605461, 0.02850249595940113, -0.0050407350063323975, -0.021001385524868965, -0.0020960657857358456, 0.046143539249897, -0.0449439100921154, -0.05156957730650902, 0.01091341394931078, -0.025001104921102524, -0.025682950392365456, 0.01629663072526455, 0.01429048553109169, 0.04081229865550995, -0.019102755934000015, 0.01301146112382412, -0.07019935548305511, 0.0010595055064186454, -0.05612797662615776, -0.04661126062273979, 0.004386703949421644, 0.0002818297070916742, -0.02307664044201374, 0.019674891605973244, -0.0504116453230381, 0.0011152139632031322, -0.03501858562231064, -0.03156409412622452, 0.009156705811619759, 0.005016151815652847, -0.023799054324626923, 0.10100001841783524, 0.034730829298496246, 0.04243675619363785, 0.08375445008277893, 0.03516237437725067, 0.02863232046365738, 0.0406055748462677, -0.003825689200311899, -0.039625637233257294, 0.039697203785181046, 0.0228427704423666, -0.027584999799728394, 0.028836125507950783, 0.04037478566169739, 0.06317048519849777, 0.04031847044825554, -0.0001226711319759488, 0.014982686378061771, 0.0643700510263443, 0.003370109014213085, 0.061840400099754333, 0.017761368304491043, -0.05319587141275406, 0.006568519864231348, -0.01587490923702717, -0.0014232359826564789, 0.0063818939961493015, 0.027243075892329216, -0.29934924840927124, 0.02898944541811943, 0.026301667094230652, 0.05151043459773064, -0.007715069223195314, -0.018731718882918358, -0.037239693105220795, -0.047558777034282684, -0.01485504675656557, -0.0033874958753585815, -0.09618963301181793, 0.0237890612334013, 0.009794053621590137, -0.04477722942829132, -0.009188174270093441, 0.025911634787917137, 0.06364979594945908, -0.04287939891219139, 0.031102614477276802, -0.04496590420603752, 0.0188395157456398, 0.01735427789390087, 0.18481680750846863, 0.006747405044734478, -0.038198746740818024, -0.06565167009830475, -0.025224506855010986, -0.0323803573846817, -0.004915602505207062, 0.05995183065533638, 0.056851018220186234, 0.008390123024582863, 0.0482313446700573, 0.04421008378267288, -0.007137763779610395, 0.0722149908542633, -0.011317344382405281, -0.002228262135758996, 0.05235568434000015, 0.009236562065780163, 0.02604520693421364, 0.006754121743142605, -0.030271491035819054, -0.02561311610043049, 0.04487169533967972, -0.003945686388760805, 0.03821336105465889, 0.038486599922180176, 0.024573801085352898, -0.039266593754291534, 0.01818719506263733, 0.003826270578429103, -0.0005024852580390871, 0.005005777347832918, 0.01384768821299076, 0.049034155905246735, -0.040949445217847824, 0.023673854768276215, 0.005009422544389963, -0.03629317134618759, 0.02249259501695633, -0.030363598838448524, 0.06228075921535492, -0.03096030093729496, 0.04608907178044319], 'd844248f-f515-4da4-94e1-26e939335820': [-0.06953108310699463, 0.04782966151833534, -0.0073973448015749454, -0.008663623593747616, -0.017154071480035782, 0.026965467259287834, -0.05188915506005287, -0.011153503321111202, -0.008955176919698715, 0.00604480504989624, 0.006915105041116476, -0.08955003321170807, -0.027343101799488068, 0.036788519471883774, 0.0006027449853718281, 0.023855021223425865, -0.06294875591993332, 0.047280773520469666, -0.011578529141843319, -0.019984599202871323, 0.0719684585928917, -0.06068273261189461, 0.022829515859484673, -0.052453409880399704, -0.001060623093508184, 0.032403528690338135, -0.033053670078516006, 0.001766264671459794, -0.006751229986548424, -0.23018302023410797, -0.0006523094489239156, -0.007379135582596064, 0.04224192351102829, -0.00028842699248343706, -0.09210139513015747, -0.04108208790421486, -0.05544765666127205, -0.01171688549220562, -0.011501174420118332, 0.0664043053984642, 0.031044350937008858, 0.01879034750163555, -0.03842480853199959, -0.007567139808088541, 0.03378709778189659, -0.042855750769376755, 0.021177517250180244, -0.02502613328397274, -0.07683901488780975, -0.00640422198921442, 0.012007607147097588, -0.009352819994091988, -0.03219595178961754, 0.028814690187573433, 0.023114625364542007, 0.013276508077979088, 0.03763587772846222, 0.020280208438634872, 0.01478287111967802, 0.0009997235611081123, 0.002094368217512965, 0.025441603735089302, -0.10688841342926025, 0.06619927287101746, 0.008443799801170826, 0.05480019003152847, -0.0502120740711689, -0.016012996435165405, 0.00983385182917118, 0.029403716325759888, 0.0036265237722545862, -0.021076625213027, -0.004989080596715212, 0.034661922603845596, 0.004482892341911793, 0.041607361286878586, 0.050802815705537796, 0.03530145809054375, 0.056717827916145325, -0.031711772084236145, -0.02418000064790249, 0.01008900348097086, 0.045173171907663345, -0.03788162022829056, 0.03998062014579773, -0.005837524775415659, 0.061019670218229294, 0.019830061122775078, -0.0030661611817777157, 0.009554769843816757, -0.005347140599042177, -0.04129663109779358, -0.06403350085020065, 0.02464914321899414, -0.024070540443062782, -0.05964991822838783, 0.020131470635533333, 0.037481654435396194, -0.05701309069991112, 0.35979434847831726, -0.011514401063323021, -0.008182370103895664, -0.03045869991183281, -0.007140299770981073, 0.005753831937909126, -0.05011546611785889, -0.0019536835607141256, 0.0004849377728533, -0.08165257424116135, 0.02226930670440197, -0.03809419274330139, 0.033165834844112396, -0.005078216083347797, -0.06256712228059769, -0.009796380996704102, -0.03937442600727081, 0.025114212185144424, 0.033913835883140564, 0.0003263290273025632, 0.0483781062066555, -0.02546234056353569, 0.04516762122511864, -0.046613793820142746, 0.020182142034173012, 0.01428974885493517, 0.05079565569758415, 0.05678892508149147, 0.10115623474121094, 0.027099771425127983, 0.08771947026252747, 0.026138607412576675, 0.04063737392425537, -0.06272799521684647, 0.021582521498203278, -0.028187856078147888, 0.06387892365455627, -0.002813786966726184, 0.012463952414691448, 0.0015505454502999783, -0.021669190376996994, -0.01102700736373663, 0.04966383054852486, 0.03367433696985245, -0.010235777124762535, -0.034732598811388016, 0.09644517302513123, -0.06404080986976624, -0.03760473057627678, -0.06510523706674576, 0.005913143046200275, -0.015919189900159836, 0.05277343839406967, -0.026097653433680534, -0.04549168422818184, 0.03306472674012184, 0.05855868011713028, -0.01351256389170885, -0.0515347421169281, -0.06848365813493729, -0.002791993087157607, -0.03069555014371872, -0.019869336858391762, 0.04107236489653587, 0.06800340116024017, 0.02746925689280033, -0.08024381846189499, -0.03808198124170303, 0.007231818046420813, 0.02323283441364765, -0.044401369988918304, 0.05881807580590248, -0.007259260397404432, -0.024194007739424706, 0.03184659779071808, 0.004260750953108072, 0.06026299670338631, -0.01899605616927147, 0.010042408481240273, 0.02954963967204094, 0.05067995563149452, 0.04249560460448265, -0.052485283464193344, 0.04370255768299103, 0.018753640353679657, -0.056361932307481766, -0.016119064763188362, -0.007861536927521229, -0.024615922942757607, -0.0191360916942358, 0.00942148081958294, -0.024431688711047173, 0.022474154829978943, -0.010558070614933968, -0.01891763135790825, -0.007588179316371679, -0.013145264238119125, 0.01878003217279911, -0.004220323171466589, -0.06441013514995575, -0.014130506664514542, 0.052873872220516205, 0.08237728476524353, -0.05134941637516022, 0.029749153181910515, -0.05299483612179756, -0.01142298337072134, 0.0693257600069046, -0.030880535021424294, 0.04181883856654167, -0.0011453834595158696, -0.08526823669672012, -0.01036213617771864, 0.01055336743593216, -0.0423397421836853, 0.003627217374742031, -0.016776682808995247, 0.013146255165338516, 0.03684305399656296, 0.008630579337477684, 0.006695895455777645, -0.05183444917201996, -0.0751769095659256, -0.003628550795838237, -0.3545035123825073, -0.004016803111881018, 0.02561759762465954, -0.04449055343866348, 0.0246674045920372, -0.06396368891000748, 0.024385640397667885, 0.031025726348161697, 0.03814034163951874, 0.0067304037511348724, 0.09487242251634598, -0.009620043449103832, 0.0008789213607087731, -0.09519266337156296, -0.04123552888631821, 0.02889176458120346, 0.018919363617897034, -0.002686241175979376, -0.01920243538916111, 0.08630218356847763, 0.039056196808815, -0.013421132229268551, 0.032195497304201126, -0.03604043275117874, 0.03002859279513359, -0.03790535777807236, 0.10953667759895325, -0.03312009572982788, 0.06561239063739777, -0.00758174154907465, 0.020665228366851807, 0.03491697832942009, -0.0503208264708519, -0.015799373388290405, 0.0520225428044796, -0.08722390234470367, -0.015320011414587498, 0.05839413404464722, 0.023530803620815277, 0.015297326259315014, -0.05147484317421913, -0.030629603192210197, 0.032350026071071625, -0.05772174149751663, 0.00259746634401381, -0.005766490940004587, -0.047179121524095535, -0.022052325308322906, 0.01715519279241562, 0.022679239511489868, 0.060751773416996, 0.0006417184486053884, 0.06660173833370209, -0.012945866212248802, -0.05497558042407036, -0.0692446231842041, -0.028134075924754143, -0.030422162264585495, -0.03679224103689194, -0.026699017733335495, -0.007465085946023464, -0.022777540609240532, -0.003002460580319166, -0.06601901352405548, 0.00353674846701324, 0.039232026785612106, 0.020335927605628967, 0.023090539500117302, 0.017808757722377777, 0.021747542545199394, -0.0040515693835914135, 0.07336018234491348, 0.01770440861582756, 0.02044890820980072, 0.044443026185035706, 0.03795680031180382, 0.01915363408625126, 0.030427798628807068, -0.007548733614385128, 0.026998618617653847, -0.005055716726928949, 0.007519549690186977, 0.09216868132352829, 0.01709369570016861, 0.04408683627843857, 0.0020349009428173304, 0.04034901782870293, 0.0030083060264587402, 0.009207160212099552, 0.05471702665090561, -0.11615358293056488, 0.014063315466046333, -0.026118235662579536, 0.016350017860531807, -0.016919082030653954, -0.028906842693686485, -0.2670581638813019, 0.007499008905142546, 0.059929441660642624, 0.07425779104232788, -0.014864595606923103, -0.024268535897135735, -0.0007003009086474776, -0.05592114478349686, -0.011207479052245617, -0.016906868666410446, -0.07970719784498215, 0.0093071972951293, 0.057666562497615814, -0.017996596172451973, -0.04068661481142044, 0.008709288202226162, 0.09226285666227341, -0.04512810334563255, -0.023788584396243095, 0.018955418840050697, -0.005299925338476896, -0.006116020958870649, 0.15894724428653717, 0.0028377827256917953, -0.014936182647943497, -0.060462214052677155, -0.056163813918828964, -0.02894224226474762, 0.004942562896758318, 0.03271966055035591, 0.052434612065553665, 0.02752726338803768, 0.05921012535691261, 0.03482098504900932, -0.0114195691421628, 0.027018332853913307, 0.027898190543055534, -0.010114858858287334, 0.07854575663805008, 0.026881981641054153, 0.04970897361636162, -0.012248505838215351, -0.017543751746416092, -0.0581769198179245, 0.05661255493760109, 0.040495678782463074, -0.004037752747535706, 0.011683156713843346, -0.04844968393445015, -0.014294699765741825, 0.02370784990489483, 0.013963870704174042, -0.01821989007294178, -0.014596857130527496, 0.00711903627961874, 0.014034301973879337, -0.01299004815518856, 0.03471403196454048, -0.025209994986653328, -0.01258294191211462, 0.030245985835790634, -0.05570075288414955, 0.06165701150894165, -0.032528799027204514, 0.023297132924199104], '1558bd5a-19c5-4ce9-8a51-a391588ddfcd': [-0.06543762981891632, 0.03434209153056145, -0.03702062740921974, 0.010470370762050152, -0.02269701659679413, 0.045939378440380096, -0.030450161546468735, 0.0057352823205292225, 0.04791204631328583, 0.015440705232322216, 0.043193474411964417, -0.04165167361497879, 0.01906362920999527, 0.040902696549892426, 9.187234536511824e-05, -0.004804947879165411, -0.04407881200313568, 0.017960378900170326, -0.01813252829015255, -0.059825122356414795, 0.0878453478217125, -0.06063130125403404, 0.03538277745246887, -0.0704071894288063, 0.005305740050971508, 0.05672796815633774, -0.025462457910180092, -0.010867132805287838, -0.016342921182513237, -0.25277331471443176, 0.008680258877575397, -0.03350825980305672, 0.07130937278270721, 0.025532135739922523, -0.04572790488600731, 0.013972516171634197, -0.04078855738043785, 0.023927344009280205, 0.00926328357309103, 0.024417679756879807, 0.024221239611506462, 0.042950764298439026, -0.00623750127851963, -0.008107759989798069, 0.018966011703014374, -0.03657415136694908, 0.0027550458908081055, -0.034484583884477615, -0.055966511368751526, -0.01750921830534935, -0.015764597803354263, -0.027411071583628654, -0.012327766045928001, 0.08657312393188477, 0.032641731202602386, -0.02129465341567993, 0.06457553803920746, 0.009783812798559666, 0.0035237683914601803, 0.02873123064637184, 0.023569930344820023, 0.019866811111569405, -0.12995180487632751, 0.05705616995692253, 0.03511727601289749, 0.020736290141940117, -0.05252164602279663, -0.00703436229377985, -0.032555703073740005, 0.05364471301436424, 0.027838652953505516, -0.024667205289006233, 0.011683166027069092, 0.009144395589828491, 0.062064673751592636, 0.03059983439743519, 0.05209366977214813, 0.02788582444190979, 0.03295915946364403, -0.05282251164317131, -0.007644216995686293, 0.01801668293774128, 0.03991200402379036, -0.030533980578184128, -0.005479301325976849, -0.05098000541329384, 0.015242249704897404, -0.006771694868803024, -0.05943484231829643, -0.003702423069626093, -0.012211739085614681, -0.02292744815349579, -0.027307696640491486, 0.02695060335099697, -0.027928408235311508, -0.07095427066087723, -0.009052656590938568, 0.06233389303088188, 0.003973526880145073, 0.3508872985839844, -0.003463121596723795, 0.022119054570794106, -0.015153996646404266, -0.024550484493374825, 0.00981348380446434, -0.054828353226184845, -0.008178048767149448, -0.006031153257936239, -0.04487394168972969, 0.04196657985448837, -0.05330543592572212, 0.009644067846238613, -0.011359576135873795, -0.04876640811562538, -0.000677913601975888, -0.026095427572727203, 0.031071577221155167, 0.023456815630197525, 0.02461841143667698, 0.018784090876579285, -0.07312628626823425, 0.04436160624027252, -0.04446465149521828, 0.01846468634903431, 0.036886002868413925, 0.03536687046289444, 0.049913354218006134, 0.08655989915132523, 0.06394314020872116, 0.03593343123793602, 0.050371456891298294, 0.033933136612176895, -0.05341155081987381, 0.03539757430553436, -0.018650397658348083, 0.042552489787340164, -0.012976805679500103, -0.004934394732117653, 0.012447947636246681, -0.044466566294431686, -0.0026315751019865274, 0.0006948653026483953, 0.004328714683651924, 0.02343618869781494, -0.06036340445280075, 0.15346188843250275, -0.052987467497587204, -0.03454103693366051, -0.01986544393002987, 0.01368808001279831, -0.000918768288102001, 0.07005800306797028, 0.00020978663815185428, -0.061123818159103394, -0.020939698442816734, 0.052005212754011154, -0.0006770955515094101, -0.07506491243839264, -0.08364564925432205, -0.008579478599131107, -0.032641518861055374, 0.0013468348188325763, -0.014134788885712624, 0.11963227391242981, 0.03360358253121376, -0.06330705434083939, -0.0008871820755302906, -0.0038134895730763674, 0.033070553094148636, -0.02763650007545948, 0.07656601071357727, -0.019609494134783745, -0.03344828262925148, 0.042132873088121414, -0.0035002140793949366, 0.05622934550046921, -0.021960321813821793, -0.00634467788040638, -0.004175442736595869, 0.03177965432405472, 0.04238823056221008, -0.022494584321975708, 0.025041555985808372, 0.043622370809316635, -0.0267273411154747, 0.004033719189465046, -0.04933531954884529, -0.008934651501476765, 0.015021912753582, 0.019071945920586586, 0.01439167931675911, -0.0014018126530572772, -0.02204909548163414, -0.015289222821593285, -0.0033453507348895073, -0.041402801871299744, 0.012401786632835865, 0.021635403856635094, -0.06553084403276443, -0.035809919238090515, 0.030034305527806282, 0.054276954382658005, -0.01992342807352543, 0.020624030381441116, -0.03841456025838852, -0.07726924866437912, 0.06367004662752151, -0.0019715772941708565, 0.041547030210494995, 0.023883428424596786, -0.0718877986073494, -0.04185912758111954, -0.01739189587533474, -0.03915807977318764, 0.004670014139264822, -0.03149663656949997, 0.00547287380322814, 0.020770294591784477, 0.0008076734957285225, -0.005946068558841944, -0.06451897323131561, -0.06267684698104858, -0.01823660545051098, -0.34082525968551636, -0.0358780138194561, 0.039686962962150574, -0.01767633855342865, 0.021800871938467026, -0.06700671464204788, 0.009182814508676529, 0.052301641553640366, 0.09110183268785477, 0.024280637502670288, 0.06797823309898376, -0.0385880321264267, -0.03417772054672241, -0.06742290407419205, -0.009413867257535458, 0.02181215211749077, 0.040209684520959854, -6.226301775313914e-05, -0.014536743983626366, 0.021877039223909378, 0.038364823907613754, 0.02269596792757511, 0.0061507439240813255, -0.02564343251287937, 0.05324891209602356, -0.02229544334113598, 0.1188080906867981, -0.021252121776342392, 0.06738749146461487, 0.012238415889441967, -0.001046518562361598, 0.021439744159579277, -0.013392245396971703, -0.02089528739452362, 0.049745239317417145, -0.03473658487200737, -0.012253726832568645, 0.012735831551253796, -0.0013380286982282996, -0.00764061976224184, -0.048988815397024155, -0.011325026862323284, 0.05733615159988403, -0.0327959805727005, -0.00927500519901514, -0.0023007639683783054, -0.049443189054727554, -0.03867132589221001, -0.01798482984304428, 0.04945168271660805, 0.03487364947795868, -0.02739873342216015, 0.001103579648770392, -0.009059020318090916, -0.04771490767598152, -0.023052679374814034, 0.008222440257668495, -0.052155591547489166, -0.04399418458342552, -0.044110897928476334, -0.019034719094634056, -0.048792339861392975, 0.002442040015012026, -0.025423675775527954, -0.03670115023851395, 0.013712821528315544, 0.053490329533815384, 0.04926226660609245, 0.02021690085530281, 0.023493465036153793, -0.03853046894073486, 0.09697224944829941, 0.019240621477365494, 0.003369815181940794, 0.05938970670104027, 0.009450285695493221, -0.008459849283099174, -0.005362862255424261, -0.016839822754263878, -0.007969462312757969, 0.026544492691755295, 0.0017756624147295952, 0.06426753848791122, -0.009754404425621033, 0.07846114784479141, -0.016091886907815933, 0.05863691866397858, -0.01720719411969185, -0.0037340621929615736, 0.06941886991262436, -0.005419670604169369, 0.012146963737905025, 0.0026872106827795506, -0.012281809002161026, 0.010227524675428867, -0.01379783358424902, -0.2772103250026703, 0.021705903112888336, 0.015027200803160667, 0.07579757273197174, 0.016864432021975517, -0.017885467037558556, -0.01621716096997261, -0.041312769055366516, -0.01983836106956005, 0.03266710415482521, -0.08068040758371353, 0.05030103400349617, 0.06399576365947723, -0.07522961497306824, -0.051689375191926956, -0.008195515722036362, 0.11774048954248428, -0.07014117389917374, 0.009620093740522861, 0.005321443546563387, -0.00887878704816103, 0.023538870736956596, 0.1805621087551117, -0.02282417193055153, -0.0062719909474253654, -0.08676973730325699, -0.022393669933080673, -0.0508943647146225, -0.011339436285197735, 0.032486844807863235, 0.03718194738030434, 0.029610659927129745, 0.04893462359905243, 0.04846630245447159, -0.022726083174347878, 0.009269238449633121, 0.015488698147237301, 0.008691253140568733, 0.02685653045773506, 0.029277978464961052, 0.039117682725191116, -0.017791783437132835, -0.051861416548490524, -0.027382662519812584, 0.06648603081703186, 0.043133314698934555, 0.031556859612464905, -0.02392818219959736, -0.03109903447329998, -0.005411006975919008, 0.0013615593779832125, 0.010853643529117107, 0.013210713863372803, -0.014880658127367496, 0.012946340255439281, 0.009183715097606182, -0.04598080739378929, -0.007713248487561941, -0.029179980978369713, -0.030886787921190262, 0.00011596891999943182, -0.061607494950294495, 0.034047506749629974, -0.014661724679172039, 0.016980959102511406], 'fc731157-a527-4712-be13-e352c3567a31': [-0.03687834367156029, 0.07034264504909515, -0.023987019434571266, 0.001242161844857037, -0.03438267484307289, 0.05850844085216522, -0.0532880499958992, -0.015547363087534904, 0.011047293432056904, 0.0022730582859367132, -0.011858797632157803, -0.09442345798015594, 0.03182820603251457, 0.037401385605335236, 0.04445236921310425, -0.010803263634443283, -0.049886591732501984, 0.03671089932322502, -0.0010633390629664063, -0.005704534240067005, 0.10389537364244461, -0.03311228007078171, -0.00016762138693593442, -0.07673441618680954, 0.010241471230983734, 0.03336659073829651, -0.02213183417916298, -0.03614062815904617, -0.02774799056351185, -0.2332889884710312, 0.032003872096538544, -0.032999373972415924, 0.05756061524152756, 0.00624779611825943, -0.05456520617008209, 0.033489350229501724, -0.09654543548822403, 0.036170363426208496, -0.031967081129550934, 0.02822895348072052, -0.00556393014267087, 0.03736267611384392, -0.006127043627202511, -0.017767928540706635, 0.013532649725675583, -0.027344390749931335, 0.0007651633350178599, 0.0008648100192658603, -0.028814135119318962, -0.0011188461212441325, -0.03373728692531586, 0.02009872905910015, 0.020297229290008545, 0.03751876577734947, -0.00607934920117259, -0.06145448982715607, 0.037096742540597916, 0.04563893750309944, 0.010823407210409641, 0.03653331845998764, 0.00032768669188953936, 0.03913842514157295, -0.13828794658184052, 0.07825460284948349, -0.009629771113395691, 2.151031185348984e-05, -0.01681342162191868, -0.008855685591697693, -0.015608991496264935, 0.048322681337594986, 0.0003840280987787992, 0.023970747366547585, 0.048962511122226715, 0.06914828717708588, 0.05209344998002052, 0.01683676801621914, 0.040759481489658356, 0.04126723110675812, -0.015749778598546982, -0.06960336863994598, -0.04587043076753616, -0.0066801272332668304, 0.03459818661212921, -0.031001338735222816, -0.043570466339588165, -0.04020226001739502, 0.012054597958922386, -0.02126062661409378, -0.021937528625130653, 0.012969626113772392, 0.015294492244720459, 0.014133461751043797, -0.0019072110299021006, -0.002978283679112792, -0.05825194716453552, -0.06679296493530273, -0.0442219115793705, 0.0548459067940712, -0.02642439678311348, 0.3813122808933258, -0.04060685634613037, 0.010711751878261566, -0.01950090378522873, 0.01765023171901703, -0.004851511679589748, -0.05300401151180267, 0.00073711370350793, 0.03249841183423996, -0.027996066957712173, -0.0023576179519295692, -0.03381604328751564, 0.05101453512907028, 0.009865585714578629, -0.056027624756097794, -0.01973443478345871, -0.047054268419742584, 0.05028212442994118, 0.01022760383784771, -0.009161670692265034, 0.014890443533658981, -0.07090530544519424, 0.021328477188944817, -0.024992844089865685, 0.03398730605840683, 0.035493843257427216, -0.0038231676444411278, 0.047264471650123596, 0.03921090066432953, 0.05135383829474449, 0.024120241403579712, 0.050838395953178406, 0.024013668298721313, -0.05816706642508507, -0.016955163329839706, -0.00023173251247499138, 0.02550993300974369, -0.0024067882914096117, -0.035362135618925095, -0.014396478421986103, -0.05643340200185776, -0.0027452572248876095, -0.029314585030078888, 0.008762804791331291, -0.012533925473690033, -0.04027503356337547, 0.07209666073322296, -0.02629152685403824, 0.009544494561851025, -0.011400056071579456, -0.049288541078567505, -0.012500832788646221, 0.004335536155849695, -0.0213081743568182, 0.004646526649594307, 0.03815966472029686, 0.04250428080558777, 0.0002924577856902033, -0.033512361347675323, -0.05872231721878052, 0.0006854113307781518, -0.03820747137069702, -0.06739915162324905, 0.0025958421174436808, 0.10520555078983307, 0.02198846824467182, -0.08927518129348755, -0.05640973523259163, -0.0012659493368119001, -0.011583304032683372, -0.016529284417629242, 0.07959397882223129, 0.009306959807872772, -0.04097561910748482, 0.0349247083067894, -0.03570026531815529, -0.0038466136902570724, -0.03462975472211838, 5.950689228484407e-05, 0.005190012976527214, 0.08384395390748978, 0.01820295676589012, -0.017844021320343018, -0.008088047616183758, 0.036657001823186874, 0.01721457578241825, -0.04261922091245651, -0.04910741001367569, 0.023777751252055168, 0.03300050273537636, -0.02108892798423767, 0.011582905426621437, 0.005529334768652916, -0.022042280063033104, -0.019637759774923325, 0.03835160285234451, -0.059178419411182404, 0.004759533330798149, 0.020581243559718132, -0.02894665114581585, -0.04430396109819412, 0.04641091451048851, 0.07651415467262268, -0.05419095605611801, 0.022227613255381584, -0.004833185579627752, -0.061415426433086395, 0.029931405559182167, -0.04421217367053032, 0.03170233964920044, -0.005451866425573826, -0.04465983062982559, -0.02240622043609619, 0.022506460547447205, 0.010467153042554855, -0.030437931418418884, -0.003183460794389248, -0.011282021179795265, 0.0789579525589943, 0.053900472819805145, 0.005590889137238264, -0.05577322468161583, -0.06591435521841049, -0.014009295031428337, -0.31399455666542053, -0.013787947595119476, 0.034793488681316376, -0.016318975016474724, 0.022424891591072083, -0.06095060333609581, -0.0076047396287322044, -0.003130716970190406, 0.1311093270778656, -0.0037261084653437138, 0.11081574112176895, 0.00645092036575079, -0.01916944794356823, -0.052641455084085464, -0.015367223881185055, 0.05433894693851471, 0.002719153417274356, 0.024215156212449074, 0.02036789059638977, 0.042198460549116135, 0.04615870118141174, -0.0008876463398337364, -0.00503590377047658, -0.016841035336256027, 0.07843393832445145, 0.02737310342490673, 0.09245473146438599, 0.021665148437023163, 0.07792689651250839, -0.020426670089364052, 0.0461689829826355, 0.0787518173456192, -0.034705132246017456, -0.05003052577376366, 0.00894085131585598, 0.03091580793261528, -0.02797810174524784, 0.028523311018943787, 0.0020241981837898493, -0.007413346320390701, 0.01273714005947113, 0.018147818744182587, 0.012697543948888779, -0.07213051617145538, 0.014206133782863617, -0.027546962723135948, -0.03645199537277222, -0.016120290383696556, 0.020163094624876976, 0.019120432436466217, -0.007012077607214451, -0.030283255502581596, -0.0004399870231281966, 0.009123670868575573, -0.06992226094007492, -0.028926720842719078, -0.017772726714611053, -0.015859734266996384, -0.024416718631982803, -0.057384926825761795, -0.001934703323058784, -0.06863749027252197, 0.0387125201523304, 0.0015761272516101599, -0.06251052021980286, 0.015475249849259853, 0.04421689733862877, 0.07376955449581146, 0.0396936871111393, 0.09235154837369919, -0.06950684636831284, 0.08002088218927383, 0.02744012139737606, 0.021418269723653793, 0.08167857676744461, 0.009358441457152367, 0.010635770857334137, -0.02564757876098156, 0.033065665513277054, 0.008814713917672634, 0.04939909651875496, 0.03025566227734089, 0.07555849850177765, 0.0359368696808815, 0.01835467666387558, 0.02828008309006691, 0.039516594260931015, 0.008617130108177662, 0.027839696034789085, 0.042179107666015625, -0.04503233730792999, 0.009903768077492714, 0.008209479972720146, 0.0063553801737725735, 0.006297179963439703, -0.012884723022580147, -0.2900448143482208, 0.0381896086037159, -0.025065358728170395, 0.041155800223350525, -0.00019634202180895954, -0.05819104611873627, -0.04896721616387367, -0.06666446477174759, -0.03979164734482765, 0.04738525673747063, -0.08842165023088455, 0.043454401195049286, 0.04497044160962105, -0.0555214025080204, 0.0011041599791496992, -0.008840952068567276, 0.05632247030735016, -0.011647208593785763, -0.004866264294832945, 0.004096075892448425, -0.05156054347753525, -0.029877251014113426, 0.16355691850185394, -0.010441293008625507, -0.002556560793891549, -0.05268659442663193, -0.02099943533539772, -0.07492828369140625, 0.033276159316301346, 0.014635150320827961, 0.0102971401065588, 0.01279783807694912, 0.09124388545751572, 0.0573032945394516, -0.012036619707942009, 0.026830140501260757, -0.0008266505319625139, 0.013967928476631641, 0.0020789066329598427, 0.033868324011564255, 0.017397109419107437, 0.004995808936655521, -0.04188840091228485, -0.02202487364411354, 0.03250648081302643, 0.04217761382460594, 0.004982842598110437, -0.006598461885005236, -0.04586222395300865, 0.015449251979589462, -0.01186222955584526, -0.008049970492720604, -0.014034458436071873, 0.00418043090030551, 0.017324848100543022, 0.024742938578128815, -0.025192203000187874, -0.013459878973662853, -0.06573169678449631, 0.00655964994803071, 0.013633711263537407, -0.03433333337306976, 0.04104363173246384, -0.020373471081256866, 0.026769880205392838], 'aed5196b-e68a-47f4-b9a8-f59785ccce55': [-0.0554281622171402, 0.043942224234342575, -0.005303358193486929, 0.019136391580104828, 0.01659844070672989, 0.04252343997359276, 0.0008896220824681222, -0.004760072100907564, 0.036938637495040894, -0.01331003662198782, 0.03494497761130333, -0.062218133360147476, 0.07470082491636276, 0.019336571916937828, 0.0669557973742485, 0.013680408708751202, 0.013119112700223923, -0.022109147161245346, -0.02003619633615017, -0.0011052727932110429, 0.03312837332487106, -0.03228317201137543, 0.014414476230740547, -0.02419755980372429, 0.05601400136947632, 0.03262461721897125, -0.009841343387961388, -0.04358277469873428, 0.013471226207911968, -0.2552429735660553, 0.0169120654463768, 0.016774894669651985, 0.07797075062990189, 0.0006819747504778206, -0.07709310948848724, -0.013952674344182014, -0.05956770479679108, -0.01945636235177517, -0.003133264137431979, 0.006526294630020857, 0.04847658425569534, 0.024485701695084572, -0.00631117494776845, -0.023591531440615654, 0.0020573223009705544, -0.010929695330560207, -0.054220426827669144, -0.009911270812153816, -0.022141527384519577, 0.013115478679537773, -0.019983243197202682, -0.04559510946273804, 0.004499767441302538, -0.0003976404550485313, 0.06630976498126984, -0.01251424290239811, 0.04984669014811516, -0.008626061491668224, 0.03374809771776199, 0.033071015030145645, -0.014959066174924374, 0.028161050751805305, -0.14458508789539337, 0.010919381864368916, 0.030998844653367996, 0.02511581778526306, -0.040143221616744995, -0.03144517168402672, -0.03279570862650871, 0.03563424572348595, 0.0015521671157330275, -0.03822929039597511, 0.0478973463177681, 0.010889937169849873, 0.05009884014725685, -0.007324591279029846, -0.0032057769130915403, 0.011877316050231457, 0.040447819977998734, -0.009028931148350239, 0.0030664787627756596, 0.05414731800556183, 0.00798739492893219, -0.037186264991760254, 0.0208264272660017, 0.009420590475201607, -0.0013074263697490096, -0.019223622977733612, -0.0362456813454628, -0.03680189326405525, 0.005028202664107084, -0.013851628638803959, -0.04393012821674347, -0.0369957871735096, -0.04784666746854782, -0.08031433075666428, 0.02599269710481167, 0.03192092478275299, -0.012680518440902233, 0.339413046836853, 0.016436250880360603, -0.028868619352579117, -0.0361892394721508, 0.005235304124653339, -0.04128856211900711, -0.034676261246204376, -0.03742903843522072, -0.013559116050601006, -0.0054338895715773106, -0.038139503449201584, -0.005132786929607391, 0.004952935501933098, -0.000474531581858173, -0.04064207524061203, -0.01826418936252594, -0.05976077541708946, 0.037285663187503815, 0.036131277680397034, 0.002914131386205554, -0.0074755228124558926, -0.01793755404651165, 0.028013022616505623, 0.0012091629905626178, -0.04194854944944382, 0.07199026644229889, 0.01709802821278572, -0.004112411756068468, 0.09518631547689438, 0.05080285668373108, 0.02987215481698513, 0.029108216986060143, 0.0024234671145677567, -0.05421683192253113, 0.007462522480636835, -0.003834720002487302, -0.03806975111365318, 0.042295463383197784, -0.039818864315748215, -0.032891348004341125, -0.010311535559594631, -0.037768736481666565, 0.060773059725761414, 0.02387600764632225, 0.006983011960983276, -0.09144953638315201, 0.12999165058135986, -0.03217431157827377, -0.04136674478650093, -0.00934799574315548, -0.025985486805438995, 0.018812362104654312, 0.06404717266559601, -0.024548396468162537, 0.006620632950216532, 0.05330290272831917, 0.052121784538030624, -0.021429935470223427, -0.0007925179088488221, -0.08834686130285263, -0.012798747979104519, -0.03909628465771675, -0.04980476200580597, 0.03380206599831581, 0.10575609654188156, 0.040480755269527435, -0.02325502596795559, 0.003802596591413021, 0.032326411455869675, -0.02299772948026657, -0.03662987798452377, 0.05541600286960602, -0.01017704512923956, -0.08094289898872375, 0.05357479676604271, -0.019859418272972107, -0.014760530553758144, -0.04083004221320152, 0.013788819313049316, 0.044341444969177246, 0.02102489210665226, 0.026340670883655548, -0.01614559069275856, -0.018978148698806763, -0.014653295278549194, -0.0037574891466647387, -0.03591378778219223, -0.026036106050014496, -0.008723342791199684, -0.0067020803689956665, -0.021225156262516975, -0.05329526215791702, -0.012247749604284763, -0.027568459510803223, 0.01997644081711769, -0.013144563883543015, -0.04952682927250862, 0.008668295107781887, -0.013257937505841255, -0.018809814006090164, -0.01415237970650196, 0.019582906737923622, 0.06047076731920242, -0.04820690676569939, -0.012721535749733448, -0.027891911566257477, 0.058291271328926086, 0.012577347457408905, -0.013528348878026009, 0.023529846221208572, 0.0278929453343153, -0.05497189611196518, -0.0345907062292099, -0.03901530057191849, -0.0294977854937315, -0.01685892604291439, 0.004046670161187649, 0.007946502417325974, 0.04014807567000389, -0.04476066306233406, 0.007831324823200703, 0.003170367795974016, -0.07793258130550385, -0.059991076588630676, -0.34868401288986206, -0.02046695165336132, 0.012927797622978687, -0.04248209297657013, 0.016630247235298157, -0.05809023976325989, 0.015858221799135208, 0.023592201992869377, 0.033615026623010635, 0.03460218757390976, 0.092474065721035, 0.04618658870458603, -0.011364912614226341, -0.07988622784614563, -0.028924012556672096, -0.00869087316095829, 0.006883848924189806, 0.033347271382808685, -0.03973296284675598, -0.002379058627411723, 0.008641093969345093, 0.03148708865046501, 0.03689585253596306, -0.025691373273730278, -0.003971767611801624, -0.02309267781674862, 0.14208190143108368, -0.007501699961721897, 0.06099396198987961, -0.026077454909682274, 0.028783563524484634, 0.06951775401830673, -0.046793606132268906, -0.017415190115571022, 0.06446502357721329, -0.05370765179395676, 0.005359862465411425, 0.07109546661376953, -0.03405899181962013, -0.015814315527677536, -0.026482515037059784, 0.012115338817238808, 0.011523214168846607, -0.07026790082454681, 0.008617095649242401, 0.009637678973376751, -0.03682338073849678, -0.03934308886528015, -0.04263732209801674, 0.018698398023843765, -0.009581764228641987, -0.014349590055644512, 0.0437125563621521, -0.003668497782200575, -0.04899907857179642, -0.0477045439183712, -0.09136763960123062, -0.03929158300161362, -0.07285930216312408, -0.006907605100423098, -0.013857130892574787, -0.035758063197135925, -0.0007123652612790465, -0.08135348558425903, -0.02431916445493698, -0.02648344822227955, 0.025732239708304405, 0.054837703704833984, 0.008226018399000168, 0.007327023893594742, -0.039032209664583206, 0.03599230572581291, 0.031007295474410057, 0.043072689324617386, 0.052061136811971664, -0.01884492114186287, 0.01677650399506092, 0.021800413727760315, 0.010193238966166973, 0.10514041036367416, 0.06108536571264267, 0.008421462960541248, 0.05553179606795311, 0.018331877887248993, 0.05895162746310234, 0.00847857166081667, 0.037628911435604095, 0.015347832813858986, 0.04108784347772598, 0.028028065338730812, -0.07331855595111847, -0.056766994297504425, 0.03348525986075401, 0.007837191224098206, 0.03180211782455444, 0.0010874957079067826, -0.27803662419319153, 0.03602009639143944, -0.008779388852417469, 0.07765556126832962, 0.002778377616778016, -0.044912248849868774, 0.02592710219323635, -0.03490842878818512, 0.01403619535267353, 0.014790371060371399, -0.028424536809325218, 0.09754837304353714, 0.041064273566007614, -0.06765805929899216, 0.02613644488155842, -0.02060997672379017, 0.0860491544008255, -0.020795755088329315, 0.051002904772758484, 0.08944467455148697, -0.04039756581187248, 0.01410880871117115, 0.15004846453666687, -0.02371399477124214, -0.018679877743124962, -0.06986980140209198, -0.005271383561193943, -0.03564808517694473, 0.03691597282886505, 0.05393148213624954, 0.0491936132311821, 0.051051873713731766, 0.12521404027938843, 0.03778191655874252, 0.008890774101018906, 0.06493919342756271, -0.0087420754134655, 0.01555210817605257, 0.023513000458478928, 0.051068924367427826, 0.01982753723859787, -0.0033102454617619514, -0.03013365902006626, 0.02394811250269413, 0.06013740599155426, -0.012306027114391327, 0.022132715210318565, -0.01888298988342285, -0.056072842329740524, -0.00523601146414876, 0.01153501495718956, -0.013686229474842548, 0.022620180621743202, 0.00827797967940569, 0.041871748864650726, 0.04396720975637436, -0.005977233871817589, 0.015881823375821114, -0.004496503621339798, -0.03145503252744675, 0.004424497950822115, -0.04350869357585907, 0.045524973422288895, -0.021213551983237267, -0.0014453993644565344], 'e6887d47-75c4-4050-8d98-53fe3e232c13': [-0.06910423934459686, 0.022253572940826416, -0.02029503509402275, -0.0037359357811510563, -0.020320849493145943, 0.02723405510187149, -0.012270829640328884, -0.005483567249029875, -0.0172199048101902, 0.03717343881726265, 0.02980363555252552, -0.10645553469657898, 0.044024400413036346, 0.02030532993376255, 0.08495059609413147, 0.024970045313239098, -0.05721229314804077, -0.03656565397977829, -0.025332709774374962, -0.05220317840576172, 0.045777417719364166, -0.012495680712163448, -0.014310806058347225, -0.01042902935296297, 0.05911003798246384, 0.018547527492046356, -0.02503356710076332, -0.10780437290668488, -0.006021367385983467, -0.25000232458114624, 0.026710567995905876, 0.019640373066067696, 0.019364476203918457, 0.05333644896745682, -0.04578457400202751, 0.030587514862418175, -0.0403260700404644, 0.03300880268216133, -0.016523391008377075, -0.00383013766258955, 0.042498499155044556, 0.0137424161657691, -0.02978854440152645, -0.03153694421052933, -0.002055270131677389, -0.021066002547740936, -0.0702122151851654, -0.0033102890010923147, -0.004225034732371569, 0.0035927093122154474, -0.00406721793115139, -0.04496118426322937, 0.02573101408779621, 0.011479263193905354, 0.04203939065337181, -0.036131974309682846, 0.05095411464571953, 0.0387115404009819, 0.04841360077261925, 0.035937823355197906, 0.004488261416554451, 0.03877824544906616, -0.1446007639169693, 0.028642117977142334, 0.019892966374754906, 0.015573559328913689, -0.025853270664811134, -0.061330605298280716, -0.04188285395503044, 0.06429644674062729, 0.006924521643668413, -0.029895730316638947, 0.025377236306667328, 0.009025320410728455, 0.037620898336172104, -0.03470885381102562, -0.0339510403573513, 0.04776473715901375, 0.012754053808748722, 0.012194620445370674, 0.008346602320671082, 0.04246295243501663, -0.01544096041470766, -0.014745564199984074, -0.003549661487340927, 0.04999401420354843, -0.03001187928020954, -0.03640194237232208, -0.005981224589049816, -0.03744761273264885, -0.001926903729327023, -0.01664462313055992, -0.000511228630784899, -0.026269512251019478, -0.020817315205931664, 0.0016761462902650237, -0.013251393102109432, 0.015426953323185444, 0.017247077077627182, 0.3357912003993988, -0.011595666408538818, -0.034729402512311935, -0.048119280487298965, -0.022212335839867592, -0.04000426456332207, -0.053179074078798294, -0.04638873040676117, 0.026013201102614403, -0.021098177880048752, -0.00825269240885973, -0.0029696079436689615, -0.029241429641842842, 0.01412357110530138, -0.033799853175878525, -0.034571435302495956, -0.03391338884830475, 0.01523427851498127, 0.054955001920461655, 0.016576282680034637, -0.041060179471969604, 0.035466354340314865, 0.003112395526841283, 0.01787780225276947, -0.006550387013703585, 0.061969220638275146, -0.015958210453391075, 0.0311071015894413, 0.06515683233737946, 0.0548601895570755, 0.010222935117781162, 0.024946842342615128, 0.018613530322909355, -0.05647509917616844, -0.029222900047898293, -0.014238097704946995, -0.02938443049788475, 0.015866855159401894, -0.053090546280145645, -0.019520016387104988, -0.018051177263259888, -0.001793708186596632, 0.04037003964185715, 0.030841048806905746, -0.027956489473581314, -0.044739339500665665, 0.14798805117607117, -0.021786285564303398, -0.03833446279168129, -0.025395706295967102, -0.05091388151049614, -0.010548215359449387, 0.042811907827854156, -0.0020351321436464787, -0.02063722535967827, 0.01777227222919464, 0.027250297367572784, -0.028825506567955017, -0.004297764506191015, -0.0617956668138504, 0.018586212769150734, -0.06322295218706131, -0.015841396525502205, 0.0193085465580225, 0.09898621588945389, 0.011483313515782356, -0.05262212082743645, 0.006026735994964838, 0.023743797093629837, 0.009725363925099373, -0.0006976319709792733, 0.04550880193710327, -0.004840274807065725, -0.04712613672018051, 0.0174331646412611, 0.013823351822793484, -0.004690294153988361, -0.08147206902503967, 0.05397382006049156, 0.010234721004962921, 0.014699784107506275, 0.06351906806230545, -0.007757252082228661, -0.03003864921629429, -0.017630204558372498, -0.027597609907388687, -0.053555071353912354, -0.0011154954554513097, 0.008221186697483063, -0.010610117577016354, 0.004263423848897219, 0.015293550677597523, -0.013515927828848362, -0.048758022487163544, 0.03246280550956726, 0.00025353184901177883, -0.05972055345773697, -0.0016680414555594325, 0.027982646599411964, 0.02497718669474125, -0.07808051258325577, 0.014012807980179787, 0.05521630495786667, -0.05222056806087494, 0.003929143771529198, -0.004123815335333347, 0.0322507806122303, 0.000696810835506767, 0.01740582101047039, 0.04161277413368225, 0.044542208313941956, -0.005644833203405142, -0.015499934554100037, -0.004954718519002199, -0.018904490396380424, -0.0360308475792408, -0.016701219603419304, 0.019476745277643204, 0.07245653867721558, -0.02346607856452465, -0.005832173395901918, 0.02229323424398899, -0.0815601646900177, -0.0567716583609581, -0.347828209400177, -0.026019616052508354, 0.03881940618157387, -0.00024180016771424562, 0.009139825589954853, -0.06352708488702774, 0.01378170121461153, 0.002860193606466055, 0.0799698531627655, -0.015010109171271324, 0.12838223576545715, 0.03547307103872299, -0.027681611478328705, -0.027001360431313515, -0.028562534600496292, 0.04249745234847069, -0.005928310565650463, 0.036840517073869705, -0.01432756707072258, -0.00502829160541296, 0.03768620267510414, 0.033638425171375275, 0.07996314018964767, -0.06077420338988304, 0.013967219740152359, 0.011748848482966423, 0.133658766746521, -0.02092629298567772, 0.052227068692445755, 0.004002735018730164, -0.004240053705871105, 0.04902450367808342, -0.023021165281534195, -0.016164343804121017, 0.04312140867114067, -0.023178990930318832, 0.012367810122668743, 0.01295288186520338, 0.006044972222298384, 0.025212127715349197, -0.017959434539079666, -0.0011546493042260408, -0.023664746433496475, -0.101716049015522, 0.010466914623975754, 0.005481570493429899, -0.04527418315410614, 0.0036545302718877792, -0.01010827161371708, 0.026744943112134933, -0.008970661088824272, -0.016068927943706512, 0.03426985815167427, 0.04022591933608055, 0.0034757135435938835, -0.05146940425038338, -0.05244128778576851, -0.013663048855960369, -0.014600331895053387, -0.004753299057483673, 0.017538463696837425, -0.022419117391109467, 0.027476536110043526, -0.024914724752306938, -0.024258321151137352, -0.05394390597939491, 0.027706805616617203, 0.072604238986969, 0.027935704216361046, 0.0037484155036509037, -0.026181818917393684, 0.03936878219246864, 0.022130101919174194, 0.03208613023161888, 0.05758082494139671, -0.0016288274200633168, 0.035158395767211914, -0.013030202127993107, -0.037217456847429276, 0.055596787482500076, 0.011345352977514267, 0.009289884939789772, 0.04714668169617653, 0.015251819975674152, 0.027678538113832474, -0.004573593381792307, 0.04286608099937439, -0.008166186511516571, 0.022769158706068993, -0.00814791675657034, -0.051005687564611435, -0.0264319758862257, 0.0662427619099617, -0.007768059615045786, 0.03720264509320259, 0.013105062767863274, -0.2909330427646637, 0.007757239509373903, -0.05494006350636482, 0.07090529799461365, 0.024336226284503937, -0.012049148790538311, 0.009375804103910923, -0.03846181929111481, 0.01433994248509407, 0.054203134030103683, -0.07593943178653717, 0.06301101297140121, 0.043591953814029694, -0.03299327567219734, 0.03339695930480957, -0.004949233494699001, 0.05712684988975525, -0.012646866030991077, 0.05567735433578491, 0.020290935412049294, -0.0725068524479866, -0.013766060583293438, 0.17949864268302917, -0.021097250282764435, -0.01911018416285515, -0.07776056230068207, -0.02812141366302967, -0.057013221085071564, 0.055611513555049896, 0.017734067514538765, 0.028275756165385246, 0.046695079654455185, 0.13482876121997833, 0.007017146795988083, -0.02788134664297104, 0.05500862002372742, -0.06208260357379913, 0.0065346891060471535, 0.006238588597625494, 0.05383513495326042, 0.02146260067820549, 0.02257578633725643, -0.049323670566082, -0.02645217441022396, 0.06931529194116592, 0.03619970753788948, -0.019967779517173767, -0.05780438706278801, -0.08056360483169556, -0.014555885456502438, -0.00428267614915967, 0.032906897366046906, -0.012201034463942051, 0.012583417817950249, 0.10146620124578476, 0.05371014401316643, 0.002256648149341345, 0.02095336839556694, -0.06913403421640396, 0.012367447838187218, 0.030026163905858994, -0.028038285672664642, -0.004527919925749302, 0.01745704934000969, 0.007754357531666756], '7a58867c-9dfd-4b7b-ac50-14bc9b1fdabc': [-0.028944481164216995, 0.023548491299152374, -0.050656337291002274, 0.06289304792881012, -0.025006258860230446, 0.009353508241474628, -0.023433227092027664, 0.019789351150393486, 0.01411451492458582, 0.03938005864620209, -0.014719557017087936, -0.09072302281856537, 0.05951545387506485, 0.030713863670825958, 0.06523659080266953, 0.006791404914110899, -0.023740384727716446, 0.011408638209104538, -0.005925765726715326, -0.04726843908429146, 0.060609158128499985, -0.025148726999759674, 0.035614416003227234, -0.03935950621962547, 0.04514441266655922, 0.0444844625890255, -0.05060458928346634, -0.05069086700677872, -0.011739990673959255, -0.22235479950904846, 0.004757723771035671, -0.05460485443472862, 0.052946943789720535, 0.02336839586496353, -0.01845407858490944, 0.048908960074186325, -0.04982800409197807, 0.009011835791170597, -0.03358995541930199, 0.07430034875869751, 0.00048137904377654195, 0.01582438312470913, -0.04815521091222763, 0.010637612082064152, 0.021038589999079704, -0.017400143668055534, -0.017734060063958168, -0.044323455542325974, -0.045451197773218155, 0.019971439614892006, -0.027385879307985306, -0.03496004641056061, 0.059125419706106186, 0.02000054344534874, 0.03468656167387962, 0.010520508512854576, 0.05604558810591698, 0.048266105353832245, 0.029075291007757187, 0.036233704537153244, -0.030500207096338272, 0.02648104727268219, -0.16823139786720276, 0.04685638099908829, 0.025363992899656296, -0.03069767728447914, -0.07321520149707794, -0.010012561455368996, -0.010165603831410408, 0.0880943089723587, 0.018460005521774292, 0.0005142432055436075, 0.0258630458265543, 0.0743153840303421, 0.016011282801628113, 0.02518225647509098, 0.05011767894029617, 0.05028540641069412, 0.044508449733257294, -0.05361340194940567, -0.04762272164225578, 0.043768756091594696, -0.01968875713646412, -0.03588826581835747, -0.023365112021565437, 0.006670861970633268, 0.01078786514699459, 0.0042454893700778484, -0.0035839343909174204, 0.005236695986241102, -0.011540197767317295, -0.015835817903280258, -0.02646785043179989, 0.016392379999160767, -0.049475256353616714, -0.11009914427995682, 0.020379669964313507, 0.049397263675928116, 0.001611029845662415, 0.3546740710735321, -0.002791697159409523, 0.018594998866319656, -0.001780797028914094, 0.0011161473812535405, -0.026042791083455086, -0.06536687910556793, 0.024437138810753822, 0.0007519781938754022, -0.03812505677342415, -0.019016237929463387, -0.024599643424153328, -0.01356763020157814, 0.03298221156001091, -0.03844504803419113, 0.02592882327735424, -0.032765891402959824, 0.058057352900505066, 0.03315039724111557, 0.0037336573004722595, 0.005673161242157221, -0.061176057904958725, -0.00319445738568902, -0.014361988753080368, 0.011406449601054192, 0.0013511034194380045, 0.03591611608862877, 0.02339458279311657, 0.0371820405125618, 0.04893800616264343, 0.040895719081163406, 0.05792082101106644, 0.005173950456082821, -0.05418437346816063, 0.01874740608036518, 0.016270911321043968, 0.037668269127607346, 0.005897698923945427, 0.007369406521320343, -0.008476713672280312, -0.015611774288117886, -0.03856468200683594, 0.028396716341376305, 0.020807769149541855, 0.02348989062011242, -0.06012969836592674, 0.0983985960483551, -0.040963899344205856, -0.04300951957702637, -0.008804460056126118, -0.0026711057871580124, -0.0016208209563046694, 0.039476796984672546, -0.03836505115032196, -0.0175465177744627, 0.017416678369045258, 0.06309717148542404, 0.0032360719051212072, -0.023895233869552612, -0.07186024636030197, 0.013596048578619957, -0.01187695749104023, -0.05044683441519737, -0.018097953870892525, 0.04544834420084953, 0.04395833984017372, -0.04320552200078964, -0.06094658374786377, 0.0012687480775639415, -0.030157774686813354, -0.06898022443056107, 0.09027079492807388, 0.0005105478339828551, -0.049686312675476074, 0.07406336069107056, -0.0547976978123188, -0.020112548023462296, -0.05271059274673462, 0.02200448140501976, 0.04460790008306503, 0.005334180314093828, 0.0274724792689085, -0.025521233677864075, -0.03274226188659668, 0.03586465120315552, -0.02883063070476055, -0.014067189767956734, -0.03966016322374344, -0.004617016762495041, 0.010234221816062927, -0.0624137781560421, 0.01601974479854107, 0.010458401404321194, -0.049230292439460754, -0.014901593327522278, -0.04361078888177872, -0.050339072942733765, 0.011958434246480465, -0.0035103526897728443, -0.03738756105303764, -0.04643082991242409, 0.029595980420708656, 0.04255402833223343, -0.04813772067427635, -0.002976413117721677, -0.034860074520111084, -0.03564152866601944, 0.03556118905544281, 0.03341686725616455, 0.031646981835365295, -0.01121953409165144, -0.07525302469730377, -0.05857902392745018, -0.047751057893037796, -0.0020089223980903625, -0.009730668738484383, -0.023739837110042572, -0.030859246850013733, 0.03326879441738129, 0.02051795832812786, 0.03504494950175285, -0.03970756381750107, -0.0901559516787529, -0.04211793094873428, -0.35626497864723206, -0.05143202468752861, -0.0015446868492290378, -0.021395644173026085, 0.012254239991307259, -0.0759357362985611, 0.020745664834976196, 0.019513098523020744, 0.06022302433848381, 0.030288036912679672, 0.08898710459470749, 0.010875209234654903, 0.015158148482441902, -0.08973836898803711, -0.0268741212785244, 0.020572908222675323, 0.019395459443330765, 0.014850256964564323, 0.0064328876323997974, 0.041754696518182755, 0.05171702057123184, 0.009549589827656746, 0.0025920835323631763, -0.017553899437189102, 0.024664048105478287, -0.05321567878127098, 0.18444256484508514, 0.05335330590605736, 0.06033613905310631, -0.04350874945521355, 0.0535268671810627, 0.03573494777083397, -0.0524691678583622, -0.057303156703710556, 0.030511459335684776, 0.01565057411789894, -0.001554350950755179, 0.07748331129550934, -0.022190555930137634, 0.004120629280805588, 0.003603345947340131, 0.024702860042452812, 0.019642194733023643, -0.044629670679569244, 0.04456685110926628, -0.01610313542187214, -0.02998850680887699, -0.03248988837003708, -0.02444969303905964, 0.04774540662765503, 0.01733982190489769, 0.006717145908623934, 0.00011175950930919498, 0.018620040267705917, -0.03368936479091644, 0.01397822517901659, -0.03438996523618698, 0.02180863358080387, -0.03876041620969772, -0.03963186591863632, -0.003427746705710888, -0.03744906559586525, 0.016790350899100304, -0.07447590678930283, -0.016951464116573334, -0.014092009514570236, 0.040609847754240036, 0.015261752530932426, 0.011198874562978745, 0.07075746357440948, -0.054266881197690964, 0.09613844752311707, 0.016192933544516563, 0.010682684369385242, 0.028954658657312393, -0.0020399915520101786, 0.017289945855736732, 0.03533245623111725, 0.036122340708971024, 0.03554293140769005, 0.02659277804195881, 0.013731238432228565, 0.06672341376543045, 0.01016633678227663, 0.057730209082365036, 0.00950161088258028, 0.011677221395075321, -0.01972557231783867, 0.051131196320056915, 0.03106379508972168, -0.02695421874523163, -0.030158959329128265, -0.0003632446750998497, 0.03849412500858307, 0.012658409774303436, -0.017080320045351982, -0.26223450899124146, 0.03243262693285942, 0.05521192401647568, 0.05553172156214714, -0.006268851459026337, -0.05538082495331764, -0.035887837409973145, -0.07252614200115204, -0.025236137211322784, -0.0005453773774206638, -0.05449238792061806, 0.035098783671855927, 0.05056529864668846, -0.026724793016910553, -0.0256812646985054, 0.002636442892253399, 0.09298782795667648, -0.038251567631959915, 0.001987731084227562, 0.009322340600192547, 0.01938547007739544, -0.04070618376135826, 0.14045828580856323, -0.033602505922317505, -0.025790847837924957, -0.08173094689846039, 0.0036501623690128326, -0.03958684951066971, 0.03204656019806862, 0.03535899892449379, -3.0634342692792416e-05, 0.014995414763689041, 0.0907084047794342, 0.05994720384478569, 0.0005539949634112418, 0.013268735259771347, 0.007710265461355448, -0.006122448015958071, 0.07215651869773865, 0.007402976509183645, 0.044309161603450775, 0.03059971146285534, -0.05405508726835251, -0.02640383318066597, 0.009388947859406471, 0.02458813041448593, 0.05709191411733627, -0.031369391828775406, -0.024817271158099174, -0.0039051149506121874, 0.02481880411505699, 0.005452246870845556, -0.002173688029870391, -0.028000418096780777, 0.031582023948431015, -0.004603312350809574, 0.005007339175790548, -0.0002789490681607276, -0.027123602107167244, -0.009195582941174507, -0.03349039703607559, -0.04260503128170967, 0.05456379055976868, -0.008640358224511147, 0.023089135065674782], '25439d0e-a06a-4b07-83e2-944bdca8690e': [-0.018965572118759155, 0.04749952629208565, -0.008679057471454144, 0.02623634971678257, 0.03243260085582733, 0.02592187561094761, 0.015702472999691963, -0.0031100036576390266, 0.027738915756344795, 0.0109627116471529, 0.04546629637479782, -0.06331029534339905, 0.038445331156253815, 0.035422779619693756, 0.045392218977212906, 0.03328724205493927, 0.024178791791200638, -0.02296598069369793, -0.05997578427195549, -0.03667677566409111, 0.07209806889295578, -0.053844302892684937, 0.028378233313560486, -0.05341685563325882, 0.07721661776304245, 0.011168715544044971, -0.04006307199597359, -0.0775630846619606, 0.004556331317871809, -0.24756528437137604, -0.015258047729730606, 0.02834659442305565, 0.034671273082494736, -0.004273348022252321, -0.0303229708224535, 0.03383186087012291, -0.05696362629532814, -0.014284024015069008, -0.014229384250938892, 0.006391096860170364, 0.017616761848330498, 0.02040046453475952, -0.014413447119295597, 0.018695078790187836, 0.0038492127787321806, -0.01624356396496296, -0.03923723101615906, -0.04670880362391472, -0.021853573620319366, 0.017428217455744743, -0.059180065989494324, -0.03342191129922867, 0.02449870854616165, -0.0034219902008771896, 0.05057840421795845, -0.011258424259722233, 0.05312191694974899, 0.009697439149022102, 0.04922762140631676, 0.025031110271811485, -0.0016061986098065972, 0.03911830112338066, -0.2007083296775818, 0.03814035654067993, 0.07752055674791336, -0.010593428276479244, -0.05314936488866806, -0.04419989883899689, -0.0326431542634964, 0.04328037425875664, 0.009990829974412918, -0.011104447767138481, 0.054485172033309937, 0.05255035683512688, 0.03632412105798721, -0.010120294988155365, 0.009925009682774544, 0.006098507903516293, -0.009376454167068005, -0.0161876417696476, -0.017171822488307953, 0.03429172933101654, -0.03391970694065094, -0.01544722355902195, 0.026977218687534332, 0.010747157037258148, 0.017522117123007774, -0.004990553017705679, 0.010825049132108688, -0.038265299052000046, -0.008754380978643894, -0.0235586017370224, -0.0067678214982151985, 0.012282871641218662, -0.03957042843103409, -0.07850050181150436, -0.0016462743515148759, 0.031110838055610657, 0.01800205186009407, 0.3614216148853302, -0.019285479560494423, -0.013667390681803226, -0.015108673833310604, -0.008290654048323631, 0.009575177915394306, -0.0527125783264637, -0.0026999458204954863, 3.1627798307454214e-05, -0.010270551778376102, -0.02517794631421566, -0.012394534423947334, -0.043652668595314026, 0.017843855544924736, -0.04879148676991463, -0.00687911082059145, -0.017432698979973793, 0.055860236287117004, 0.030955936759710312, 0.03086087852716446, -0.006887803785502911, -0.0046062464825809, 0.012264407239854336, 0.014951247721910477, -0.03347339481115341, 0.03489823266863823, -0.0007505703833885491, 0.006340834312140942, 0.0587298683822155, 0.027287451550364494, 0.007794445380568504, 0.05629907548427582, 0.0164441280066967, -0.056848157197237015, -0.021494051441550255, 0.0022879685275256634, 0.011122334748506546, 0.03524048253893852, -0.01446300745010376, -0.015032211318612099, 0.028012840077280998, -0.014309371821582317, 0.013414141722023487, 0.04058824107050896, -0.025028932839632034, -0.08696308732032776, 0.12553419172763824, -0.03150118514895439, -0.036402683705091476, -0.031483400613069534, -0.011354971677064896, 0.028939589858055115, 0.03221413120627403, -0.012679423205554485, 0.013179176487028599, 0.050575755536556244, 0.030954034999012947, 0.0037703830748796463, -0.0067667788825929165, -0.06120850518345833, 0.008512541651725769, -0.0405869334936142, -0.0715608298778534, -0.0015119758900254965, 0.09174633771181107, 0.031689923256635666, -0.02461344189941883, 0.009987940080463886, 0.021408967673778534, -0.03565597906708717, -0.021436333656311035, 0.058458149433135986, -0.015412305481731892, -0.03381277620792389, 0.043973423540592194, 0.00040274308412335813, 0.00030078922281973064, -0.0014394716126844287, 0.055419690907001495, 0.03206245228648186, 0.0259220190346241, 0.012423894368112087, -0.0019777703564614058, 0.0018823896534740925, -0.021545732393860817, -0.010664066299796104, -0.030102359130978584, -0.025121591985225677, -0.009336653165519238, 0.0015712330350652337, -0.011221040040254593, -0.0367654524743557, 0.0277607049793005, -0.03689830005168915, 0.01324531715363264, -0.00900235865265131, -0.05105557665228844, 0.02293756976723671, -0.022684302181005478, -0.034177325665950775, -0.059608373790979385, 0.04883440211415291, 0.018647976219654083, -0.05214462801814079, -0.044388219714164734, 0.015178131870925426, 0.03128126263618469, 0.012439937330782413, 0.024707160890102386, 0.02946469746530056, -0.008053048513829708, -0.014098276384174824, -0.06113864853978157, -0.03049079142510891, 0.008490866050124168, -0.024979393929243088, -0.05088271573185921, 0.005899960175156593, 0.06797780841588974, 0.00037313217762857676, 0.024314790964126587, 0.0016356618143618107, -0.0752863809466362, -0.08180809020996094, -0.37135452032089233, -0.015186644159257412, 0.004376821219921112, -0.036402687430381775, 0.05045028030872345, -0.013038534671068192, 0.01497411448508501, 0.007797595113515854, 0.04241883009672165, 0.04308298975229263, 0.09844017028808594, 0.046222783625125885, 0.010751325637102127, -0.061643533408641815, -0.021256862208247185, -0.0067628053948283195, -0.0043060677126049995, 0.0024710753932595253, -0.044695526361465454, 0.01909014768898487, 0.04535093531012535, 0.04448436200618744, 0.05984142795205116, -0.021465782076120377, 0.001961258240044117, -0.005022488068789244, 0.15262112021446228, -0.02216135896742344, 0.053261131048202515, -0.026451580226421356, 0.023984892293810844, 0.024190114811062813, -0.034962981939315796, -0.07497979700565338, 0.016158949583768845, -0.012043976224958897, 0.05378199741244316, 0.027563245967030525, -0.013288665562868118, -0.0009153842693194747, -0.010906313546001911, -0.004585265181958675, -0.007052853237837553, -0.07095701992511749, 0.015736451372504234, -0.020873308181762695, -0.02797282487154007, -0.050934601575136185, -0.010235273279249668, 0.01777239516377449, -0.02021375484764576, -0.009925727732479572, 0.019128188490867615, 0.018665149807929993, -0.024524549022316933, -0.046379055827856064, -0.0918065533041954, -0.0006794634973630309, -0.044112611562013626, -0.05537613108754158, 0.005625180900096893, -0.02920859307050705, 0.02458827570080757, -0.0639340952038765, -0.022390216588974, -0.0329434759914875, 0.04983687028288841, 0.06264715641736984, 0.005820982623845339, 0.05172821134328842, -0.0361715666949749, 0.001139449537731707, 0.027387455105781555, 0.02447480335831642, 0.029991989955306053, 0.006334686651825905, 0.014791755937039852, 0.04697097837924957, 0.02312893606722355, 0.038438741117715836, 0.044473350048065186, 0.0409412644803524, 0.06123433634638786, -0.007495776750147343, 0.02458292245864868, 0.007372857071459293, 0.02734009176492691, -0.0351194366812706, 0.039689626544713974, 0.023462479934096336, -0.005403475370258093, -0.030014922842383385, 0.037913478910923004, 0.003939752466976643, 0.03178485855460167, 0.022574307397007942, -0.30800020694732666, 0.01569480262696743, 0.00567388441413641, 0.009451491758227348, -0.009748159907758236, -0.011745598167181015, 0.007461643312126398, -0.05523814633488655, -0.01680227555334568, 0.029132066294550896, -0.04593414440751076, 0.08306093513965607, 0.05265692248940468, -0.04904327169060707, -0.015246757306158543, -0.03260938450694084, 0.054566044360399246, -0.007944120094180107, 0.016138844192028046, 0.03733881190419197, -0.025056563317775726, -0.0013693056534975767, 0.1862090826034546, -0.06041068583726883, -0.02221008762717247, -0.06140114739537239, 0.0126437833532691, -0.029029490426182747, 0.024018265306949615, 0.015298104844987392, 0.024424681439995766, 0.06114770099520683, 0.08802524209022522, 0.06491570174694061, 0.008087982423603535, 0.059662822633981705, -0.017210805788636208, 0.005735036451369524, 0.034714922308921814, 0.0235813707113266, -0.017107568681240082, 0.03239073231816292, -0.06271190196275711, -0.022732149809598923, 0.06967069953680038, -0.024081185460090637, -0.04124738648533821, -0.06074494495987892, -0.05512050911784172, -0.013090768828988075, -0.02987539954483509, 0.013149742037057877, 0.00157858373131603, 0.009256819263100624, 0.04604274034500122, 0.010507839731872082, 0.0290900357067585, 0.0238269604742527, -0.034784894436597824, -0.023439744487404823, -0.03114895150065422, -0.003756606951355934, 0.05538284033536911, 0.005013538524508476, 0.02864023484289646], '13e9062c-84eb-4aba-bde6-87032e8411c3': [-0.010877032764256, 0.024120673537254333, -0.0008963303407654166, -0.06657910346984863, 0.022335631772875786, 0.022740544751286507, 0.024764999747276306, 0.019929513335227966, 0.04706846922636032, -0.06618642807006836, -0.005246693268418312, -0.08006531000137329, 0.019617704674601555, 0.019093668088316917, 0.03319929167628288, -0.003303197678178549, -0.02522984705865383, -0.004303279332816601, -0.0015085608465597034, -0.049632661044597626, 0.05987919121980667, -0.028102945536375046, -0.006340821273624897, -0.006437542848289013, 0.04358280822634697, -0.010851321741938591, 0.04725860059261322, -0.04561678320169449, -0.04300227388739586, -0.23688846826553345, 0.012634583748877048, -0.04374977573752403, 0.059485048055648804, 0.015255973674356937, -0.0964244157075882, -0.008622994646430016, -0.04096193611621857, -0.02981412224471569, 0.009670657105743885, -0.021685708314180374, 0.011666460894048214, 0.017328400164842606, -0.03428594768047333, -0.038479242473840714, 0.005556759424507618, 0.012812976725399494, 0.015453179366886616, -0.03853199630975723, -0.03907611966133118, -0.04761109873652458, 0.05879747495055199, -0.05591047182679176, 0.019452735781669617, 0.016926953569054604, 0.048779066652059555, 0.021962644532322884, 0.041016899049282074, -0.0014870950253680348, 0.07978283613920212, 0.02072121389210224, 0.018487395718693733, 0.039518434554338455, -0.1393527388572693, 0.05913301184773445, 0.01785971410572529, 0.02435278706252575, -0.04015189781785011, -0.08065276592969894, 0.0018492977833375335, 0.04482819139957428, 0.010778529569506645, -0.04755726084113121, 0.0020590531639754772, -0.0173494815826416, 0.03211985155940056, 0.02122272178530693, 0.04565645754337311, 0.03855238854885101, 0.04429471865296364, -0.027992282062768936, 0.04860738292336464, 0.047010716050863266, 0.0022274199873209, -0.038259562104940414, 0.03571278229355812, 0.024744069203734398, -0.021857164800167084, -0.025395382195711136, -0.05665864050388336, -0.02872595191001892, -0.034755904227495193, -0.026614006608724594, 0.0001797616423573345, 0.0009741935064084828, -0.031660281121730804, -0.04870119318366051, 0.03441757708787918, 0.030849561095237732, -0.018221387639641762, 0.33676978945732117, -0.0026509081944823265, -0.0022459784522652626, 0.007491529453545809, 0.02876887284219265, 0.0058634160086512566, -0.03978986293077469, 0.0010453859576955438, -0.0018552789697423577, -0.00976228155195713, 0.027233337983489037, -0.04716453701257706, -0.01189928874373436, -0.03947099298238754, -0.06182599812746048, -0.0404607355594635, -0.020152000710368156, 0.009021982550621033, 0.03438390791416168, -0.0008152251248247921, 0.002979978919029236, 0.028818512335419655, 0.002754298271611333, -0.00788953062146902, 0.0026522167026996613, 0.0025888800155371428, 0.007651413790881634, 0.02426866441965103, 0.08706387877464294, 0.04371625930070877, 0.05444881692528725, 0.04036909341812134, 0.0045270114205777645, -0.04694303497672081, -0.015571141615509987, 0.03178888186812401, 0.02980750985443592, 0.0035531362518668175, -0.04577384144067764, -0.016993876546621323, -0.004634079523384571, -0.023736225441098213, 0.026667112484574318, 0.054019004106521606, 0.013487248681485653, -0.07074187695980072, 0.11976440995931625, -0.024225523695349693, -0.02809661254286766, -0.02270050346851349, 0.013218927197158337, -0.03665237873792648, 0.05451638996601105, -0.0026178581174463034, 0.02266779914498329, 0.03586616739630699, 0.053266871720552444, -0.001106213079765439, -0.0569516196846962, -0.057713866233825684, -0.02508070133626461, -0.07792225480079651, -0.03499087318778038, -0.018090220168232918, 0.06712755560874939, 0.022344699129462242, -0.05617687851190567, -0.04843154549598694, 0.006631562486290932, -0.023611821234226227, -0.03881430625915527, 0.02269531972706318, 0.008450012654066086, -0.007228925824165344, -0.012892288155853748, 0.010278195142745972, 0.05715898796916008, -0.012425145134329796, -0.04093537852168083, 0.012190372683107853, 0.020248493179678917, 0.042269233614206314, -0.043851789087057114, 0.015546697191894054, -0.008923801593482494, -0.024810926988720894, 0.0023097973316907883, 0.0013641060795634985, -0.006292419042438269, -0.06957529485225677, 0.022783508524298668, -0.07901223748922348, -0.016890116035938263, -0.03914855793118477, 0.0023190139327198267, 0.006273861508816481, -0.0340084545314312, 0.036949124187231064, 0.0406564325094223, -0.02180071361362934, 0.0018009351333603263, -0.0030606810469180346, 0.04277057573199272, 0.0026206260081380606, -0.012560080736875534, -0.0015157628804445267, 0.03927018493413925, 0.03638710454106331, -0.00012309856538195163, -0.014682131819427013, 0.0034134015440940857, -0.07179348170757294, -0.009501174092292786, 0.006179660093039274, -0.034070443361997604, -0.026241915300488472, -0.05250066891312599, -0.04066240042448044, 0.07589389383792877, -0.019543487578630447, 0.009796530939638615, 0.033383917063474655, -0.037239186465740204, -0.021421076729893684, -0.3583906292915344, -0.043701134622097015, 0.0511438325047493, -0.03472525626420975, 0.012774661183357239, -0.07691063731908798, 0.004805872216820717, 0.0382736511528492, 0.05108843743801117, 0.023430952802300453, 0.09377042204141617, 0.029425689950585365, -0.04970875009894371, -0.049752384424209595, 0.02879783697426319, 0.0400947630405426, 0.011273008771240711, -0.00692970072850585, -0.05845203995704651, -0.03588051348924637, 0.04415643587708473, 0.03847728669643402, 0.05946649983525276, -0.029469018802046776, 0.035189371556043625, 0.03054743818938732, 0.06284531950950623, -0.06310328096151352, 0.0928497314453125, 0.01973959617316723, 0.007200498133897781, 0.044072944670915604, -0.02052454464137554, 0.05045520141720772, 0.04829687997698784, -0.05968201532959938, 0.08374541252851486, 0.02534591220319271, -0.008546901866793633, -0.060868922621011734, -0.028569558635354042, -0.013134470209479332, 0.03588811308145523, -0.0682457834482193, -0.03958842530846596, 0.02574373222887516, -0.05794331803917885, -0.01580827496945858, -0.022039996460080147, 0.036248765885829926, 0.007179994601756334, -0.026241978630423546, -0.016310036182403564, 0.06885433942079544, 0.0009768528398126364, -0.049860186874866486, -0.028740985319018364, -0.014723531901836395, -0.04964998736977577, -0.02249237149953842, -0.01636517234146595, -0.0546080619096756, -0.01002451404929161, -0.04219856113195419, 0.012095964513719082, 0.02260454371571541, 0.002728326478973031, 0.04986891523003578, 0.018419234082102776, 0.030674943700432777, -0.012802384793758392, 0.10047128051519394, 0.06160200387239456, 0.06596497446298599, 0.0464077927172184, -0.016553346067667007, 0.0017193115781992674, 0.04322570934891701, -0.012015648186206818, 0.044904470443725586, 0.059458792209625244, 1.822817102947738e-05, 0.033779021352529526, 0.03232767432928085, 0.07379884272813797, -0.0436541810631752, 0.04706689715385437, -0.020111434161663055, 0.014092457480728626, 0.039387915283441544, -0.08149833232164383, 0.017209161072969437, -0.028910301625728607, -0.018606340512633324, -0.001781051279976964, 0.0048600779846310616, -0.2650008499622345, 0.023781871423125267, 0.04898173362016678, 0.11078514903783798, -0.0031468020752072334, -0.010821533389389515, 0.0390322282910347, -0.027588199824094772, 0.0063830348663032055, -0.03419055789709091, -0.11449802666902542, 0.06853917241096497, 0.05883759632706642, 0.016732824966311455, -0.04555456340312958, 0.021189866587519646, 0.07650592923164368, -0.04337837174534798, 0.0008850705926306546, -0.032271090894937515, -0.025996815413236618, 0.031176771968603134, 0.14914868772029877, -0.024330971762537956, 0.014943340793251991, -0.060734644532203674, -0.0530579499900341, -0.09627825766801834, 0.049236834049224854, 0.02034892328083515, 0.061466146260499954, -0.0027831317856907845, 0.06184331327676773, -0.0025332907680422068, 0.011619776487350464, 0.045379966497421265, -0.017778664827346802, 0.03165034204721451, 0.009996640495955944, 0.012379431165754795, 0.0169597826898098, 0.02788694016635418, -0.04258199408650398, -0.04248644411563873, 0.116067074239254, 0.0025070151314139366, -0.0006160902557894588, -0.03605492040514946, -0.058394044637680054, -0.014266230165958405, 0.025248296558856964, 0.004640505183488131, 0.04088232293725014, 0.00022386072669178247, 0.03676134720444679, 0.018701734021306038, -0.035936139523983, 0.03253741189837456, -0.04611394926905632, -0.0010811244137585163, 0.06618150323629379, -0.07179403305053711, 0.06640789657831192, 0.015914278104901314, -0.012208610773086548], 'c43d09d4-188a-436f-ac94-8d6ddef65372': [-0.04255688562989235, 0.03160058706998825, -0.02222640998661518, -0.034581705927848816, -0.00817042775452137, 0.005701468791812658, 0.006426219828426838, 0.0036162491887807846, 0.025674330070614815, -0.04052196815609932, -0.03542553260922432, -0.06396261602640152, 0.05038702115416527, 0.04955409839749336, 0.04467982426285744, 0.016968807205557823, -0.03443927690386772, -0.0037987781688570976, -0.03097076155245304, -0.04666994512081146, 0.03293751925230026, -0.04703262448310852, 0.025115104392170906, -0.036693911999464035, 0.03334273025393486, 0.01182227861136198, -0.030771460384130478, -0.06931967288255692, 0.006739868316799402, -0.24000729620456696, 0.05155216157436371, -0.03984621539711952, 0.014471260830760002, 0.023536868393421173, -0.07508209347724915, -0.029555825516581535, -0.02526746317744255, 0.005641540512442589, 0.014717461541295052, 0.012627734802663326, 0.026276981458067894, 0.0060424101538956165, -0.05838213115930557, -0.05676963925361633, 0.008469625376164913, -0.009811952710151672, -0.012201829813420773, -0.05872436612844467, -0.05106114596128464, 0.007880812510848045, 0.026352351531386375, -0.07985988259315491, 0.002664793049916625, 0.05161503702402115, 0.03489958494901657, 0.005303105339407921, 0.025717439129948616, 0.0431724488735199, 0.04737008363008499, 0.03809196129441261, -0.001031016348861158, 0.03906117007136345, -0.1146790087223053, 0.050766393542289734, 0.022543806582689285, 0.00305696832947433, -0.05826498195528984, -0.03925888612866402, -0.010994416661560535, 0.04132664576172829, 0.029580065980553627, -0.05531356856226921, -0.02761092223227024, 0.01106937788426876, 0.06825334578752518, 0.01817941479384899, 0.06216445192694664, 0.033908870071172714, 0.004014461301267147, 0.020460903644561768, 0.026286857202649117, 0.012664142064750195, 0.039052918553352356, -0.008834756910800934, 0.053769271820783615, 0.027106471359729767, 0.012856701388955116, -0.02765641361474991, -0.03737123683094978, -0.053654298186302185, -0.04038282483816147, -0.03426128253340721, 0.00031060120090842247, 0.04998476058244705, -0.012851196341216564, -0.021748501807451248, 0.04090365022420883, 0.02230515144765377, -0.014363200403749943, 0.3598489463329315, -0.013479349203407764, -0.019262084737420082, -0.011598902754485607, -0.0052824304439127445, 0.04885239154100418, -0.06482209265232086, 0.017053095623850822, -0.010373145341873169, -0.03768858313560486, 0.04261656478047371, -0.0318039134144783, -0.0026669336948543787, -0.019937800243496895, -0.04468454048037529, -0.046127527952194214, -0.031237192451953888, 0.02424948662519455, 0.04982369393110275, 0.020984258502721786, -0.005475042853504419, 0.05415765568614006, -0.006862446200102568, -0.048769403249025345, -0.012630595825612545, 0.028651569038629532, 0.013788438402116299, 0.06297402828931808, 0.09089324623346329, 0.06382909417152405, 0.03480537608265877, 0.04445607587695122, 0.024609316140413284, -0.065837562084198, -0.029498621821403503, 0.036565057933330536, 0.007984600961208344, 0.0031501769553869963, -0.0368850901722908, -0.02297186851501465, -0.03333205357193947, 0.008533096872270107, 0.02318873256444931, 0.03952213376760483, 0.00575572345405817, -0.05134330689907074, 0.15180684626102448, -0.049481965601444244, -0.039704330265522, -0.029892852529883385, -0.007771987468004227, -0.021441807970404625, 0.035337354987859726, -0.010381245985627174, 0.029581885784864426, 0.045079007744789124, 0.05078936740756035, 0.025321030989289284, -0.022436846047639847, -0.06358654797077179, -0.044572748243808746, -0.04807266220450401, -0.04204145818948746, -0.023143859580159187, 0.07488773763179779, 0.01959729939699173, -0.051342982798814774, -0.014735914766788483, -0.004924066364765167, 0.017623137682676315, -0.05570453777909279, 0.02975880168378353, -0.03361773118376732, 0.012970592826604843, 0.02438434027135372, -0.008180147968232632, 0.05292678624391556, -0.05208157002925873, -0.032476481050252914, 0.025465302169322968, 0.030052630230784416, 0.03551296144723892, -0.07161281257867813, 0.008297636173665524, -0.01147498656064272, -0.027698395773768425, 0.010996298864483833, 0.009653732180595398, 0.028030352666974068, -0.043515946716070175, -0.01696212962269783, -0.03303631395101547, 0.006959051359444857, -0.043421465903520584, -0.017281994223594666, 0.008118272759020329, -0.02418847754597664, 0.029088668525218964, 0.029412023723125458, -0.03525019809603691, 0.0003319380630273372, 0.04520849511027336, 0.054568786174058914, 0.015424953773617744, -0.007229167968034744, -0.010108387097716331, 0.029739079996943474, 0.030823806300759315, -0.006571955978870392, 0.03821563348174095, -0.016065271571278572, -0.08270114660263062, 0.0035007919650524855, 0.004607397131621838, -0.024067077785730362, 0.002717912197113037, -0.010088151320815086, 0.0002970009227283299, 0.08401408791542053, -0.01522069051861763, -0.017363980412483215, 0.01755707524716854, -0.010625646449625492, -0.04374312609434128, -0.35365059971809387, -0.0371934249997139, 0.05575287714600563, 0.017161181196570396, 0.005491578485816717, -0.05985936149954796, -0.014387411065399647, 0.0276461411267519, 0.024105839431285858, 0.02920900657773018, 0.06863844394683838, 0.004743819124996662, -0.06611998379230499, -0.03452698141336441, -0.006020164117217064, 0.03342372551560402, 0.030851801857352257, -0.00916366558521986, -0.014484184794127941, 0.03838818147778511, 0.007229597773402929, 0.03256599232554436, 0.034260448068380356, -0.08929047733545303, 0.038997769355773926, 0.020541541278362274, 0.09241308271884918, -0.044354166835546494, 0.0781465545296669, 0.0023861301597207785, -0.023905618116259575, 0.07995569705963135, -0.014231827110052109, 0.026845861226320267, 0.04020396247506142, -0.05999881774187088, 0.026406608521938324, 0.0017597702099010348, 0.025465890765190125, -0.04004191979765892, -0.061914220452308655, -0.01993405818939209, 0.060582056641578674, -0.09694834053516388, -0.012532196938991547, 0.0018246930558234453, -0.054097771644592285, -0.021039912477135658, 0.006955157034099102, -0.024440912529826164, 0.007989604026079178, -0.04582533612847328, 0.0125142065808177, 0.034834861755371094, 0.01998819224536419, -0.04374537616968155, -0.033142998814582825, -0.03679719939827919, -0.020308196544647217, -0.015140919014811516, 0.010677117854356766, -0.04078398272395134, 0.005915519315749407, -0.020717041566967964, 0.021159734576940536, 0.041718490421772, 0.009557285346090794, 0.018893618136644363, 0.028332596644759178, 0.012927558273077011, -0.035840440541505814, 0.08110073953866959, 0.049925290048122406, 0.01941261813044548, 0.04473350569605827, 0.02068883739411831, 0.004276272375136614, 0.0397416427731514, -0.02320992946624756, 0.04656725004315376, 0.038833022117614746, 0.02344386838376522, 0.04755758121609688, -0.009154826402664185, 0.05683625489473343, 0.005567003507167101, 0.050403397530317307, 0.0061712791211903095, 0.049123283475637436, 0.03433265537023544, -0.07989087700843811, 0.03694301098585129, -0.02763395383954048, 0.0011628498323261738, -0.007281038910150528, -0.01818900555372238, -0.2892919182777405, -0.004303248133510351, 0.059458956122398376, 0.03983655944466591, 0.028315428644418716, 0.033454529941082, 0.02215505763888359, -0.025190509855747223, -0.0159895159304142, -0.024413881823420525, -0.14911174774169922, 0.039736174046993256, 0.05299736186861992, -0.03701106086373329, -0.07225870341062546, 0.025390800088644028, 0.07539746165275574, -0.037832021713256836, -0.019641170278191566, -0.006947619840502739, -0.02440279722213745, -0.007555367425084114, 0.17793652415275574, -0.012358315289020538, -0.004010660108178854, -0.049458619207143784, -0.05272705852985382, -0.038272567093372345, 0.0476762056350708, 0.024090975522994995, 0.05773874744772911, 0.0342949703335762, 0.0810624361038208, 0.014432589523494244, 0.002711406908929348, 0.01099264994263649, 0.006458672694861889, 0.0188697949051857, 0.025039076805114746, 0.021903736516833305, 0.02548462338745594, -0.006129341199994087, -0.01794297993183136, -0.1085754856467247, 0.09027082473039627, 0.013181936927139759, -0.03327668830752373, -0.00485357828438282, -0.04498875141143799, 0.011195390485227108, 0.014745041728019714, -0.0022127674892544746, -0.009530466981232166, -0.007491500582545996, 0.0490456186234951, 0.02814507484436035, -0.04526514559984207, 0.017071081325411797, -0.0033500557765364647, -0.004991211928427219, 0.025863807648420334, -0.05875340849161148, 0.037620630115270615, -0.028133517131209373, -0.012262430042028427], 'cc8f10f8-93c8-45b1-8e96-909ea9271f51': [0.0033342728856951, 0.055417969822883606, -0.03443167358636856, 0.01279893796890974, 0.03997853398323059, 0.0031115517485886812, -0.009164320304989815, -0.03235333785414696, 0.08895935863256454, -0.035254962742328644, -0.005407810676842928, -0.03242241218686104, 0.041773613542318344, 0.06611340492963791, 0.03428378328680992, 0.03284740447998047, -0.015415610745549202, -0.017469551414251328, -0.035680919885635376, -0.04854428023099899, 0.007972056977450848, -0.0578644834458828, 0.020697107538580894, -0.06254664808511734, 0.05502171069383621, -0.014317409135401249, -0.03767794370651245, -0.08194576948881149, -0.025588931515812874, -0.22360314428806305, 0.0698823630809784, -0.008561413735151291, 0.04428242892026901, 0.02030063234269619, -0.03509265184402466, 0.009767120704054832, -0.03551199287176132, -0.020033948123455048, -0.015208031050860882, 0.018951278179883957, 0.019814668223261833, 0.017724260687828064, -0.06155345216393471, -0.06304773688316345, -0.008169145323336124, 0.034774016588926315, -0.07081815600395203, -0.07147678732872009, -0.027071461081504822, -0.02695479243993759, 0.01199666503816843, -0.08301170915365219, -0.023097088560461998, 0.03343912214040756, 0.036463506519794464, 0.0013531249715015292, 0.05132715031504631, 0.004600476007908583, 0.027773156762123108, 0.05824713408946991, 0.0030973171815276146, 0.045746490359306335, -0.10241729021072388, 0.04691091924905777, 0.058305952697992325, 0.010687734931707382, -0.04804621636867523, -0.02135884203016758, 0.009520967490971088, 0.03478102385997772, 0.0015612835995852947, -0.0258675217628479, -0.011819809675216675, 0.031044648960232735, 0.07777559757232666, 0.019519789144396782, 0.06134350597858429, -0.006596445571631193, 0.04041974991559982, 0.028586674481630325, 0.033841248601675034, -0.011640772223472595, 0.021088317036628723, 0.011405367404222488, 0.03976230323314667, 0.0026073360349982977, 0.010274205356836319, -0.04959854483604431, -0.0074369171634316444, -0.041974037885665894, -0.028176452964544296, 0.006321608554571867, -0.021637748926877975, 0.025449398905038834, -0.011937247589230537, -0.0238974466919899, 0.05004594847559929, -0.023588767275214195, -0.017336660996079445, 0.35407164692878723, -0.04929199069738388, 0.012613928876817226, 0.047891709953546524, 0.010730182752013206, 0.01848250813782215, -0.057999830693006516, 0.0019974992610514164, -0.0039053529035300016, -0.03961348906159401, 0.03721345588564873, -0.005999603308737278, -0.02137775719165802, 0.019283955916762352, 0.0001408109674230218, -0.03673751652240753, -0.0296471007168293, -0.001758685102686286, 0.06669888645410538, -0.009358770214021206, 0.0070151654072105885, 0.02416864223778248, -0.03384238854050636, -0.02519170381128788, 0.017823992297053337, 0.04231470450758934, -0.007913206703960896, 0.02304431051015854, 0.1013389453291893, 0.057861413806676865, 0.0067676217295229435, 0.06298954039812088, -0.040682971477508545, -0.08956137299537659, -0.03922590613365173, 0.03877392038702965, -0.008020480163395405, 0.02851312793791294, 0.005966685246676207, -0.036753781139850616, -0.017415659502148628, 0.019711043685674667, 0.03707133233547211, 0.05157715827226639, -0.006692407187074423, -0.043774835765361786, 0.1496090590953827, -0.031347889453172684, -0.023170247673988342, -0.004947683308273554, -0.08141878992319107, 0.01399175077676773, -0.00038911704905331135, -0.036664072424173355, 0.021314769983291626, 0.06600932776927948, 0.047876566648483276, 0.0016856876900419593, -0.022803356871008873, -0.09122799336910248, 0.0016558502102270722, -0.08530952036380768, -0.03793293237686157, -0.013547046110033989, 0.04165322333574295, -0.012683459557592869, -0.011050334200263023, -0.0629248321056366, -0.020358361303806305, 0.027565527707338333, -0.051844075322151184, 0.0036001314874738455, -0.04125865176320076, 0.021667081862688065, -0.03918202221393585, 0.005944565869867802, 0.02921918034553528, -0.0647161453962326, -0.030137913301587105, 0.011338621377944946, 0.004206616431474686, 0.06848467141389847, -0.04436603561043739, 0.011145642027258873, 0.00671335170045495, -0.022856472060084343, -0.03629698604345322, 0.021677164360880852, -0.01616574265062809, -0.029725348576903343, 0.04714467376470566, -0.07595286518335342, -0.01114354282617569, -0.05538168549537659, -0.06733524054288864, -0.009271914139389992, -0.016309654340147972, -0.0007764878682792187, 0.01815621927380562, -0.04132835939526558, 0.005852625705301762, 0.04500987380743027, 0.047537799924612045, 0.023954417556524277, -0.03528818488121033, 0.004087876062840223, 0.07356235384941101, 0.013899533078074455, -0.04304195195436478, 0.033787984400987625, 0.022272588685154915, -0.08599972724914551, -0.03389006853103638, 0.013272962532937527, 0.02510868012905121, 0.008408239111304283, -0.0027425012085586786, 0.007520722225308418, 0.05596097931265831, -0.04345329478383064, -0.02969018556177616, 0.04052073135972023, -0.013579410500824451, -0.025394819676876068, -0.29549819231033325, 0.008242613635957241, 0.02250831201672554, -0.009701301343739033, 0.015147845260798931, -0.08123497664928436, -0.007157999090850353, -0.0017636537086218596, 0.052427999675273895, 0.05887182056903839, 0.060224853456020355, -0.0076050772331655025, -0.01476234756410122, 0.003948220517486334, 0.04333058372139931, 0.02903638780117035, 0.0347854383289814, -0.010854832828044891, -0.04294221103191376, 0.019919071346521378, -0.008614789694547653, 0.03813225403428078, 0.018958576023578644, -0.07451113313436508, 0.025055482983589172, 0.016159582883119583, 0.060776419937610626, -0.061319880187511444, 0.10344203561544418, -0.014169366098940372, -0.03331982344388962, 0.08040609210729599, 0.006898241117596626, 0.04155474156141281, 0.007229025475680828, -0.06827423721551895, 0.046549439430236816, -0.00970226339995861, -0.003991692792624235, -0.03702116012573242, -0.049982666969299316, 0.021131131798028946, 0.06248609721660614, -0.09751998633146286, -0.0222947895526886, 0.054153744131326675, -0.033131297677755356, -0.004633647855371237, -0.03965790942311287, -0.015424326993525028, -0.0010087104747071862, -0.009466398507356644, -0.0005615500849671662, 0.026689117774367332, 0.0551237016916275, -0.04009793698787689, -0.058814406394958496, -0.018039895221590996, -0.03883862495422363, 0.003773452015593648, 0.019056979566812515, -0.05659156292676926, 0.015259169042110443, -0.030948376283049583, 0.021628260612487793, 0.04425162076950073, 0.03906390815973282, 0.019514944404363632, 0.055474478751420975, -0.03592894971370697, -0.02148461528122425, 0.13215039670467377, 0.04090091958642006, 0.030793936923146248, 0.061094317585229874, 0.010049859993159771, -0.0008633775287307799, -0.04211392253637314, -0.049356989562511444, 0.018700143322348595, 0.09766269475221634, 0.01770133338868618, 0.051330141723155975, 0.011147985234856606, 0.038287170231342316, 0.04998299852013588, 0.07419462502002716, -0.04670580103993416, 0.03670808672904968, 0.027156827971339226, -0.06380259245634079, 0.025188270956277847, -0.014240291900932789, -0.006749841850250959, -0.004125954583287239, -0.010973338969051838, -0.26825517416000366, -0.004617115017026663, 0.07013873755931854, 0.037105172872543335, 0.03521306440234184, 0.008864759467542171, 0.04069790244102478, -0.033735938370227814, 0.014142770320177078, -0.03107372671365738, -0.15256865322589874, 0.029730796813964844, 0.036602653563022614, -0.04409399628639221, -0.041352640837430954, 0.028024109080433846, 0.061333514750003815, -0.03837442025542259, -0.009985651820898056, -0.014619464986026287, -0.0017062423285096884, -0.05074722692370415, 0.14374122023582458, -0.028390951454639435, 0.0021826699376106262, -0.035860057920217514, -0.033062588423490524, -0.0752488523721695, 0.03622684255242348, 0.010946430265903473, 0.02566477842628956, 0.060038935393095016, 0.07007536292076111, -0.010396579280495644, -0.010016012005507946, -0.013949879445135593, -0.010278037749230862, 0.016618523746728897, 0.03382270783185959, -0.04252198711037636, 0.013208404183387756, -0.053705405443906784, 0.0012549083912745118, -0.08417237550020218, 0.09556147456169128, 0.004913525655865669, 0.011302849277853966, -0.023404497653245926, -0.0384330153465271, 0.03480537608265877, 0.02861173078417778, -0.03895252197980881, 0.04464635252952576, -0.024513790383934975, 0.054529495537281036, 0.06826760619878769, -0.03036677837371826, 0.018311986699700356, 0.014571009203791618, 0.017280761152505875, 0.04370497912168503, -0.06854525953531265, 0.030597206205129623, -0.01624625362455845, 0.0004702892038039863], '8972e66c-a028-4e86-829c-ec2c5bf17daf': [-0.029092375189065933, 0.0518580861389637, -0.00867366325110197, -0.0028868624940514565, 0.03272680565714836, 0.011861113831400871, -0.003911382053047419, -0.004448423627763987, 0.04909658804535866, -0.03731079027056694, 0.017724517732858658, -0.06107572093605995, 0.05852445214986801, 0.03174716606736183, 0.05437644571065903, 0.02291383408010006, -0.051558803766965866, 0.006565675605088472, 0.00488173495978117, -0.004455616232007742, -0.0023283613845705986, -0.014405403286218643, 0.061695393174886703, -0.06401088088750839, 0.08951766043901443, 0.017037151381373405, -0.009972984902560711, -0.09291886538267136, -0.043316930532455444, -0.25646406412124634, 0.04255345091223717, -0.031832072883844376, 0.03593625873327255, -0.0009804327273741364, -0.030924195423722267, -0.015084340237081051, -0.02507258951663971, -0.04122414067387581, 0.0014142851578071713, 0.03419725224375725, 0.08636646717786789, 0.025854753330349922, -0.038623448461294174, -0.041794199496507645, -0.00020910377497784793, 0.006791412364691496, -0.0534132644534111, -0.039939526468515396, -0.0021849325858056545, -0.0063835312612354755, -0.01946408860385418, -0.05540810525417328, -0.01934940181672573, -0.001880908152088523, 0.030524704605340958, 0.016827939078211784, 0.04691660776734352, 0.00565289007499814, 0.03345145657658577, 0.027800513431429863, 0.0072847153060138226, 0.06953879445791245, -0.12558843195438385, 0.04800816625356674, 0.05472274124622345, 0.0439886637032032, -0.0455351285636425, -0.02664736472070217, 0.02697853557765484, 0.046532709151506424, -0.0082974499091506, -0.04569379240274429, 0.007310955785214901, 0.029514579102396965, 0.09237682074308395, 0.022054515779018402, 0.028851183131337166, 0.000811316363979131, 0.04220770671963692, -0.017039291560649872, 0.018359562382102013, 0.05992576479911804, 0.047553788870573044, -0.02673710323870182, 0.05245254561305046, 0.04230990260839462, 0.010682783089578152, -0.027514182031154633, -0.05799093469977379, -0.062098413705825806, -0.02814190648496151, -0.020007992163300514, -0.007534478325396776, 0.04293261468410492, -0.010143098421394825, -0.013645551167428493, 0.07069004327058792, -0.004688297398388386, 0.005233406089246273, 0.3754977881908417, 0.0172272976487875, -0.030283253639936447, -0.013214750215411186, 0.03155568614602089, 0.022182557731866837, -0.06257223337888718, 0.003995147999376059, 0.004534158390015364, -0.03846428170800209, 0.0551852211356163, -0.0053416164591908455, -0.007041459437459707, 0.01492473017424345, -0.04382529854774475, 0.006381764076650143, 0.012715887278318405, -0.0026366058737039566, 0.013535759411752224, 0.0060910508036613464, -0.01204940676689148, 0.019034050405025482, -0.022821536287665367, -0.015583336353302002, -0.01258467510342598, 0.0038153526838868856, 0.022583724930882454, 0.046032752841711044, 0.07836627960205078, 0.035883236676454544, 0.01581074856221676, 0.021862734109163284, -0.03080383688211441, -0.057962603867053986, -0.03443823382258415, 0.0541599839925766, 0.0053442963398993015, -0.0005931901978328824, -0.021479805931448936, -0.033240608870983124, -0.024955175817012787, -0.035746462643146515, -0.01482244674116373, 0.02314416877925396, -0.04856593534350395, -0.042070433497428894, 0.13701032102108002, -0.02529660426080227, -0.02531677484512329, -0.04948515444993973, -0.05116327479481697, 0.002390788635239005, 0.028153741732239723, -0.00256478413939476, 0.0021851048804819584, 0.03909650817513466, 0.05011987313628197, 0.008975335396826267, -0.007370846811681986, -0.055843401700258255, -0.0005274837021715939, -0.06288085132837296, -0.060688622295856476, 0.007570924703031778, 0.09124969691038132, -0.003965519834309816, -0.04634102061390877, 0.01663336530327797, 0.01848463900387287, 0.016981229186058044, -0.03815726190805435, -0.0012642713263630867, -0.054741330444812775, -0.0166506115347147, -0.011413805186748505, 0.03837636858224869, 0.031068289652466774, -0.08333469927310944, -0.024096405133605003, -0.004408051259815693, 0.02602521702647209, 0.06459557265043259, -0.05294235050678253, -0.030947338789701462, -0.013824823312461376, -0.04073430225253105, 0.008667685091495514, -0.0014442137908190489, 0.00692609092220664, -0.06270989030599594, -0.011857125908136368, -0.04170672968029976, 0.018114687874913216, -0.06989872455596924, 0.0021649692207574844, 0.000997880706563592, -0.012579798698425293, -0.01713578961789608, 0.027087049558758736, -0.025341706350445747, -0.034908320754766464, 0.063004270195961, 0.06183982267975807, -0.006798850372433662, -0.047964613884687424, -0.04787490889430046, 0.044780194759368896, -0.005582344252616167, 0.003659716807305813, 0.026824865490198135, 0.03125986456871033, -0.056685756891965866, -0.018531696870923042, -0.004070913884788752, -0.010439502075314522, -0.013641067780554295, -0.00933306384831667, 0.014683992601931095, 0.07594862580299377, -0.024381471797823906, 0.015219873748719692, 0.02784373052418232, -0.005363952834159136, -0.03153340145945549, -0.3399222791194916, -0.02454911358654499, 0.03766832500696182, 0.021106505766510963, 0.0168342012912035, -0.0684531182050705, -0.010539497248828411, 0.007637407630681992, 0.019499585032463074, 0.03672155737876892, 0.10148303955793381, 0.04354167357087135, -0.04552576318383217, -0.05293841287493706, 0.0005842771497555077, 0.0481937974691391, 0.0294045303016901, -0.02560308389365673, -0.023672334849834442, 0.008027502335608006, 0.009618801064789295, 0.0323520228266716, 0.006544171366840601, -0.06694663316011429, 0.03514339402318001, -0.010025208815932274, 0.10240919142961502, -0.0673643946647644, 0.07354218512773514, 0.025015344843268394, -0.004438958130776882, 0.05982128158211708, -0.03075462393462658, -0.00342179206199944, 0.014806185849010944, -0.05324693024158478, 0.043818239122629166, 0.007121073082089424, -0.010857485234737396, -0.03599671274423599, -0.0456712432205677, 0.011057302355766296, 0.05395520478487015, -0.08887633681297302, 0.005985807161778212, 0.026893487200140953, -0.07693088799715042, -0.03884713351726532, -0.008681977167725563, -0.015880057588219643, 0.025316989049315453, -0.015142906457185745, -0.01615351438522339, 0.045340295881032944, -0.005142789799720049, -0.007517361547797918, -0.10214923322200775, -0.05429492145776749, -0.08053266257047653, -0.007585891522467136, 0.008134759962558746, -0.0006149338441900909, -0.023000648245215416, -0.03645852953195572, 0.001305640209466219, 0.012991644442081451, 0.026385676115751266, 0.015242628753185272, 0.0531785823404789, 0.00917008612304926, -0.011356831528246403, 0.05286061018705368, 0.03566459193825722, 0.03261546045541763, 0.03161733224987984, 0.029157578945159912, -0.0285967905074358, 0.014530261047184467, -0.04139421880245209, 0.028727319091558456, 0.10202211141586304, 0.013084564357995987, 0.06616348773241043, 0.007140969391912222, 0.015103225596249104, 0.026964722201228142, 0.02791004069149494, -0.029961278662085533, 0.046341780573129654, 0.03826921433210373, -0.07765355706214905, -0.038894303143024445, 0.009108156897127628, -0.0014422236708924174, 0.012052906677126884, 0.006105612963438034, -0.2645706832408905, -0.0025088596157729626, 0.02756611816585064, 0.0484495535492897, 0.02622411400079727, 0.008982167579233646, 0.02598458342254162, -0.03465462848544121, 0.002074899384751916, -0.01783110201358795, -0.12035506218671799, 0.06941969692707062, 0.044674430042505264, -0.03491068258881569, -0.03737377002835274, 0.028916893526911736, 0.04266705736517906, -0.0023983758874237537, -0.014387723058462143, 0.032120876014232635, -0.04519479349255562, -0.0015982103068381548, 0.13786490261554718, -0.03147043660283089, -0.007483204361051321, -0.03447115793824196, -0.05856303125619888, -0.026612047106027603, 0.057783979922533035, 0.04522298648953438, 0.014662516303360462, 0.06295669078826904, 0.05261548236012459, 0.025542622432112694, 0.014913221821188927, 0.041840240359306335, 0.0032492249738425016, 0.004374094307422638, 0.04486488178372383, -0.014567233622074127, 0.007897811941802502, -0.0637688934803009, -0.0017685393104329705, -0.08820722997188568, 0.08119679987430573, 0.0007938179187476635, -0.026676075533032417, 0.013553143478929996, -0.052522510290145874, 0.005624216515570879, 0.01355944387614727, -0.02659337781369686, 0.02227119915187359, -0.02353658340871334, 0.06762752681970596, 0.0493038110435009, -0.03873772546648979, 0.02191438525915146, -0.0018511771922931075, 0.0008716419688425958, 0.050773318856954575, -0.08376100659370422, 0.03916999697685242, -0.011086558923125267, -0.0047568995505571365], '542e88c8-14d9-4d10-962b-9b56f7afec3c': [-0.04598843306303024, 0.023716723546385765, -0.022584859281778336, 0.018909091129899025, 0.039642006158828735, 0.025396939367055893, 0.015484130941331387, -0.026408398523926735, 0.01357252150774002, -0.012287916615605354, 0.003591844579204917, -0.05303383991122246, 0.06770575791597366, 0.0873434990644455, 0.02343132719397545, 0.024288371205329895, -0.04877050593495369, 0.016655614599585533, 0.00010485765960766003, -0.04005560651421547, -0.0075031728483736515, -0.058675963431596756, 0.03987438976764679, -0.07089053839445114, 0.062493640929460526, -0.001343242242000997, -0.026867829263210297, -0.04616514965891838, 0.004056357778608799, -0.24630717933177948, 0.04588591307401657, -0.03932064771652222, 0.025966424494981766, 0.03305922448635101, -0.04539773613214493, -0.027989918366074562, -0.035777490586042404, -0.020093709230422974, -0.0319170318543911, -0.0036850376054644585, 0.07439741492271423, 0.034904856234788895, 0.0031358590349555016, 0.004692097194492817, 0.003395628649741411, -0.009298955090343952, -0.05461323261260986, -0.07105422019958496, -0.013426396995782852, -0.009547322988510132, -0.009864795953035355, -0.02765994891524315, 0.005141506437212229, 0.015732524916529655, -0.007242809049785137, 0.004837277811020613, 0.028250522911548615, 0.03676415607333183, 0.047417912632226944, 0.011419907212257385, 0.04877179488539696, 0.07823248207569122, -0.12039218097925186, 0.060548365116119385, 0.026507899165153503, 0.06656897068023682, -0.018489951267838478, -0.010564463213086128, 0.021407602354884148, 0.0726327896118164, -0.00741857523098588, -0.05292091146111488, 0.005813027266412973, 0.0019475086592137814, 0.0726379007101059, 0.05172546207904816, 0.05547383055090904, -0.008638087660074234, 0.0615215077996254, -0.0011027343571186066, 0.027854476124048233, 0.042768869549036026, 0.03910835459828377, -0.0029599028639495373, 0.038094256073236465, 0.03776203840970993, 0.025313913822174072, -0.03684607893228531, 0.020449906587600708, -0.035670485347509384, -0.028492091223597527, -0.035830527544021606, 0.010746876709163189, 0.04731615632772446, -0.04099137708544731, -0.029157675802707672, 0.05325287580490112, 0.01825045421719551, -0.004760395735502243, 0.33956170082092285, -0.004874940495938063, -0.030498601496219635, -0.00787750631570816, -0.0015011776704341173, 0.047700874507427216, -0.07311975955963135, -0.0007874649600125849, 0.015051893889904022, -0.052669890224933624, 0.06567569822072983, -0.0003896390553563833, -0.05487002804875374, 0.0030089695937931538, -0.010421806015074253, -0.012073848396539688, -7.814995478838682e-05, 0.007974246516823769, 0.049612607806921005, 0.0028171625453978777, 0.018222671002149582, -0.014078653417527676, -0.005437782499939203, -0.038713715970516205, -0.016671277582645416, -0.0012300414964556694, 0.01223582774400711, 0.011691490188241005, 0.1078105941414833, 0.04536206275224686, 0.007489887531846762, 0.049146782606840134, -0.05815758928656578, -0.051525626331567764, 0.0034695928916335106, 0.03720204904675484, 0.004191873595118523, 0.018484707921743393, -0.002988165244460106, -0.05181409418582916, -0.03582815080881119, -0.020524637773633003, 0.052385084331035614, 0.04238643869757652, -0.02007899060845375, -0.06619971245527267, 0.13735894858837128, -0.004414536524564028, -0.02310427837073803, -0.061695944517850876, -0.049303822219371796, 0.027535956352949142, 0.03057674877345562, 0.008212585933506489, 0.0019412707770243287, -0.007316632196307182, 0.06309899687767029, -0.014303749427199364, -0.006360057275742292, -0.08729194104671478, -0.00228940905071795, -0.04999305307865143, -0.018859026953577995, -0.020744716748595238, 0.06923256069421768, 0.025207210332155228, -0.057741429656744, -0.004830791149288416, 0.0018878186820074916, 0.04474871605634689, -0.04514341056346893, 0.0014052273472771049, -0.039155006408691406, -0.02455247938632965, -0.06773817539215088, -0.01481710746884346, 0.03058614954352379, -0.0941011980175972, 0.016607504338026047, -0.027938002720475197, 0.03228485956788063, 0.029047096148133278, -0.0708879753947258, -0.00515847047790885, 0.02904612198472023, 0.011438393034040928, 0.0012810411863029003, -0.009010259062051773, -0.011399588547647, -0.0021626201923936605, 0.020810898393392563, -0.02206631563603878, 0.01902977004647255, -0.026147888973355293, -0.005868824664503336, -0.004245060961693525, -0.06218927353620529, 0.03969619423151016, 0.02727568708360195, -0.07959230989217758, 0.014935245737433434, 0.04619656875729561, 0.0750945657491684, 0.013888516463339329, -0.004851298872381449, -0.013966341502964497, 0.03281925246119499, -0.008057507686316967, -0.012130326591432095, 0.05648491159081459, 0.007181508932262659, -0.09239719063043594, 0.0077644577249884605, -0.015711171552538872, -0.01480580773204565, -0.025658167898654938, -0.024530529975891113, 0.012320058420300484, 0.07037889212369919, -0.029650283977389336, 0.032176028937101364, 0.027518082410097122, -0.01860288344323635, -0.027082838118076324, -0.33647266030311584, -0.018347695469856262, 0.02439122088253498, 0.0015708126593381166, 0.013354633934795856, -0.0983654037117958, -0.020124316215515137, 0.028286950662732124, 0.05541127547621727, 0.037101954221725464, 0.08783727884292603, 0.039493758231401443, -0.03541982173919678, -0.04488112032413483, -0.008437545038759708, 0.04950947314500809, 0.036590829491615295, -0.03504002466797829, 0.00470359530299902, 0.031672198325395584, 0.028407659381628036, 0.04802019149065018, 0.017477158457040787, -0.07921526581048965, -0.009643455035984516, -0.01723966747522354, 0.08447372913360596, -0.053774237632751465, 0.09387221932411194, 0.031142327934503555, -0.022207893431186676, 0.034525830298662186, -0.02625305950641632, 0.018599504604935646, 0.03713657706975937, -0.05115090683102608, 0.04617414250969887, -0.01440818328410387, -0.004145605023950338, -0.03817208856344223, -0.07949063926935196, -0.018789013847708702, 0.0169508196413517, -0.08089964091777802, -0.011101238429546356, 0.003134438069537282, -0.05675191059708595, -0.052297819405794144, 0.01623958721756935, 0.004878493025898933, 0.049637410789728165, -0.01474468968808651, -0.01614810898900032, -0.0037131034769117832, 1.4833552995696664e-05, -0.031109632924199104, -0.06012241542339325, -0.06600787490606308, -0.035843294113874435, 0.00041723501635715365, 0.009070605970919132, 0.017437880858778954, -0.025840530171990395, -0.03909718245267868, 0.01993320696055889, 0.008367917500436306, 0.04282210022211075, 0.027498457580804825, 0.048968181014060974, 0.004218556452542543, -0.025145655497908592, 0.08939865976572037, 0.043674957007169724, 0.013899462297558784, 0.05912403017282486, 0.006197570823132992, -0.01310292724519968, -0.02698087878525257, -0.04606503248214722, -0.00816822238266468, 0.06748030334711075, 0.010560586117208004, 0.08847886323928833, -0.010502326302230358, 0.030538801103830338, 0.034174028784036636, 0.03695802390575409, -0.024246329441666603, 0.027989570051431656, 0.04578087851405144, -0.08826805651187897, -0.011777400970458984, -0.015996357426047325, -0.027376795187592506, -0.01485246978700161, -0.005036050453782082, -0.2725208103656769, -0.03506144508719444, 0.019836869090795517, 0.0216913390904665, 0.041555896401405334, 0.0084571847692132, 0.03826635330915451, -0.06268859654664993, -0.012199753895401955, -0.008947190828621387, -0.10976273566484451, 0.05474585294723511, 0.04177049547433853, -0.029685314744710922, -0.021446172147989273, 0.013270345516502857, 0.06761665642261505, -0.04301361367106438, 0.0033926654141396284, -0.0011931052431464195, -0.04169929027557373, -0.023058323189616203, 0.158036008477211, 0.023386633023619652, 0.013934112153947353, -0.04439060762524605, -0.0599483847618103, -0.025863995775580406, 0.0658884048461914, 0.009894391521811485, 0.012117459438741207, 0.054089732468128204, 0.05422031134366989, 0.03294952213764191, -0.0034750658087432384, 0.015207735821604729, -0.004118959419429302, 0.01648063026368618, 0.040982190519571304, 0.009914044290781021, 0.028048237785696983, -0.05175022408366203, -0.013004313223063946, -0.09572038054466248, 0.09705707430839539, -0.018691426143050194, -0.05507928878068924, 4.083010207978077e-05, -0.05835234001278877, 0.026840675622224808, 0.02519867569208145, -0.031108081340789795, 0.0011435608612373471, -0.0656052678823471, 0.04383356124162674, 0.04269464686512947, -0.06784839928150177, 0.02242971397936344, 0.03672896325588226, 0.026162460446357727, 0.028363801538944244, -0.03248683363199234, -0.003929643426090479, 0.006982582621276379, 0.009186253882944584], 'bc71aea8-4100-4845-bb25-59571125e140': [-0.05119409039616585, 0.026469731703400612, -0.015115681104362011, 0.011022498831152916, 0.015587818808853626, 0.05021598935127258, -0.04949561879038811, 0.003775437595322728, 0.05737440288066864, -0.025082604959607124, 0.010711366310715675, -0.07106868177652359, 0.024533603340387344, 0.043446291238069534, 0.009485600516200066, 0.0013764315517619252, -0.04139550030231476, 0.007632625289261341, -0.018350444734096527, -0.027844849973917007, 0.024104785174131393, -0.06568591296672821, 0.020637720823287964, -0.07232125103473663, 0.03307531028985977, 0.03440059348940849, -0.03379525989294052, -0.06036717817187309, -0.004227802623063326, -0.23378798365592957, 0.03916164115071297, 0.016617998480796814, 0.060900378972291946, 0.011484015733003616, -0.06149838864803314, -0.02939966507256031, -0.05234690383076668, -0.01481755543500185, -0.001035613939166069, 0.018316278234124184, 0.04705366864800453, 0.030024955049157143, -0.03446691855788231, -0.03755222260951996, 0.023338600993156433, 0.00834233220666647, -0.014122203923761845, -0.056637849658727646, -0.05077570676803589, 0.013006744906306267, 0.01412376668304205, -0.05087266489863396, -0.047727037221193314, 0.0441739559173584, 0.0340181365609169, 0.0006306845461949706, 0.0208072979003191, 0.03302275016903877, 0.027796220034360886, 0.03887099772691727, -0.0016531986184418201, 0.038174182176589966, -0.1443091630935669, 0.07020240277051926, 0.026289066299796104, 0.04111509025096893, -0.047490786761045456, -0.013061458244919777, 0.012389034032821655, 0.026324592530727386, -0.0045111593790352345, -0.0220006313174963, -0.003224129555746913, 0.018244070932269096, 0.06357678771018982, 0.03553899750113487, 0.059577576816082, 0.012111625634133816, 0.03129411116242409, 3.2344451028620824e-05, 0.01965547539293766, 0.024452822282910347, 0.06507373601198196, -0.00026503606932237744, 0.005163921974599361, -0.01618500053882599, 0.0302716251462698, 0.002628128509968519, -0.027754945680499077, 0.008816828019917011, 0.016589773818850517, -0.006207981612533331, -0.015029029920697212, 0.07527049630880356, -0.03303424268960953, -0.03020162135362625, 0.033267226070165634, 0.03589697554707527, -0.0010683259461075068, 0.3410727381706238, -0.021420544013381004, 0.004526378586888313, -0.023673346266150475, -0.00317657133564353, 0.0030090243089944124, -0.058485668152570724, -0.0021330821327865124, -0.02072407491505146, -0.054641686379909515, 0.03715560957789421, -0.0033521433360874653, 0.022715959697961807, 0.0006689030560664833, -0.05921215936541557, 0.017053233459591866, -0.03893056511878967, 0.05120391771197319, 0.03615584224462509, -0.04048038274049759, 0.03170807659626007, -0.02254815399646759, 0.007790043950080872, -0.041440967470407486, 0.017139095813035965, 0.04551410675048828, 0.01718979701399803, 0.04439959302544594, 0.10494603961706161, 0.07993963360786438, 0.011999412439763546, 0.02075858972966671, 0.012748507782816887, -0.045399367809295654, -0.00862470455467701, 0.0020104378927499056, 0.018254566937685013, 0.006520510651171207, 0.002477517118677497, -0.037137411534786224, 0.0006037384737282991, 0.01366412453353405, 0.02400524728000164, 0.027182426303625107, 0.03451954573392868, -0.0334225632250309, 0.1229955330491066, -0.03550850972533226, -0.025140903890132904, -0.06985089182853699, -0.004921173211187124, 0.018046259880065918, 0.09081853926181793, -0.01739547587931156, 0.0014809409622102976, 0.037855666130781174, 0.06390172243118286, -0.019725138321518898, -0.026262257248163223, -0.08193720132112503, -0.023792985826730728, -0.05391313508152962, -0.058335401117801666, 0.031894758343696594, 0.09247026592493057, 0.00010728348570410162, -0.05315130576491356, -0.06293191760778427, 0.03502732515335083, 0.04760843887925148, -0.05136502534151077, 0.032546158879995346, -0.05931317061185837, 0.007078894879668951, -0.017048034816980362, -0.01960490271449089, 0.04219476133584976, -0.07427965849637985, 0.017704878002405167, 0.056797441095113754, 0.03561534360051155, 0.01613885909318924, -0.06254753470420837, 0.02665427327156067, 0.029405925422906876, -0.04004640132188797, -0.015812180936336517, -0.01752977818250656, -0.00998252909630537, -0.0021591871045529842, -0.008118211291730404, -0.0323021225631237, -0.019945243373513222, -0.015554106794297695, -0.017085466533899307, -0.0019661090336740017, -0.018497319892048836, 0.022452931851148605, 0.0410684235394001, -0.06495188921689987, 0.011674649082124233, 0.08472154289484024, 0.06165514886379242, -0.00949263758957386, 0.037720080465078354, -0.04743211343884468, -0.01258133351802826, 0.04582253843545914, -0.05126897618174553, 0.05123769864439964, 0.005606640595942736, -0.08618127554655075, -0.00027297012275084853, -0.001564154401421547, 0.007265294436365366, 0.009310985915362835, -0.021243223920464516, 0.019827868789434433, 0.014038358815014362, -0.00730561837553978, -0.021378619596362114, -0.010651702992618084, -0.05651767924427986, -0.052101802080869675, -0.35275793075561523, -0.01807774417102337, 0.047773245722055435, -0.012433720752596855, -0.004067683592438698, -0.054657451808452606, 0.0020016557537019253, 0.01351388730108738, 0.052799347788095474, 0.022781528532505035, 0.05855030193924904, -0.014628826640546322, -0.013259528204798698, -0.07997605949640274, -0.039804164320230484, 0.03488077223300934, 0.03159644454717636, -0.038801129907369614, -0.0530899353325367, 0.07015668600797653, 0.028920922428369522, -0.001090645557269454, -0.007807933259755373, -0.045124296098947525, 0.030188042670488358, -0.016757022589445114, 0.0948910042643547, -0.04779718443751335, 0.08986783772706985, 0.011365242302417755, -0.01072100643068552, 0.10101676732301712, 0.036173317581415176, 0.031237203627824783, 0.08091133087873459, -0.05559523403644562, -0.0237421914935112, 0.022710464894771576, 0.06621438264846802, -0.016807612031698227, -0.036008019000291824, -0.02241436019539833, 0.05172252655029297, -0.08518742024898529, 0.004163732286542654, -0.011218162253499031, -0.0717434361577034, -0.011595245450735092, -0.00338943675160408, -0.00929035060107708, 0.03651826083660126, 0.016714802011847496, 0.06705955415964127, -0.018855135887861252, 0.010704280808568, -0.06264979392290115, -0.029100148007273674, -0.058255769312381744, -0.03440358117222786, -0.0291666928678751, 0.011552533134818077, -0.0169117022305727, 0.00611377926543355, -0.031148279085755348, -0.021638911217451096, 0.0285338182002306, 0.02177301049232483, 0.033947136253118515, 0.030498681589961052, -0.0009284665575250983, -0.007054183632135391, 0.07357832044363022, 0.0234567541629076, 0.011473819613456726, 0.0698535367846489, 0.017709534615278244, -0.02362237311899662, 0.005400524009019136, 0.00494324741885066, 0.0019906628876924515, 0.04118860512971878, 0.00431778421625495, 0.08389856666326523, 0.024630015715956688, 0.03566545993089676, 0.009606147184967995, 0.08169015496969223, 0.00409592455253005, -0.009097344242036343, 0.050112273544073105, -0.11767980456352234, 0.005916428752243519, -0.03775450587272644, -0.004330250900238752, -0.009491638280451298, -0.002253858372569084, -0.2644771635532379, -0.003698620479553938, 0.05264747515320778, 0.006825014483183622, 0.027997812256217003, -0.046517886221408844, 0.026056451722979546, -0.03551962599158287, 0.007447326090186834, 0.021608805283904076, -0.09575914591550827, -0.003934571519494057, 0.01371025387197733, -0.05778280645608902, -0.025929579511284828, 0.028117042034864426, 0.11680813878774643, -0.07010692358016968, -0.010078617371618748, 0.02312331274151802, -0.01589628867805004, -0.018243806436657906, 0.15027520060539246, 0.0176205076277256, -0.0468565933406353, -0.029456930235028267, -0.04818118363618851, -0.04454297199845314, 0.0449814610183239, 0.02626020275056362, 0.04320978745818138, 0.010238475166261196, 0.033490635454654694, 0.020435964688658714, -0.009883012622594833, 0.017891954630613327, 0.035078685730695724, -0.0016089476412162185, 0.05705774575471878, 0.006773341912776232, 0.05998176336288452, -0.04104255512356758, -0.030806809663772583, -0.0739021748304367, 0.1018209382891655, -0.020368220284581184, -0.02396688610315323, -0.03356337547302246, -0.03632960841059685, -0.016827495768666267, 0.009508061222732067, -0.037309080362319946, -0.019826829433441162, -0.03220125287771225, 0.007814997807145119, 0.024285318329930305, -0.036293983459472656, 0.014782072044909, -0.0068031842820346355, -0.017190340906381607, 0.014057144522666931, -0.08254406601190567, 0.018630044534802437, -0.03169781342148781, 0.012181447818875313], '0b825b6d-a0c3-4b11-9f93-c4a863d4a2ea': [-0.04182010143995285, 0.055547405034303665, -0.034864094108343124, -0.009241696447134018, 0.03208927810192108, 0.05231497809290886, -0.028031988069415092, -0.029449395835399628, -0.0032520839013159275, 0.0003355284279678017, -0.00517180934548378, -0.11480236798524857, 0.042300995439291, 0.05572112277150154, -0.005708926822990179, 0.001198868965730071, -0.050249554216861725, 0.01826237514615059, -0.0015600435435771942, -0.01281344797462225, 0.02672319859266281, -0.0645618662238121, 0.039318934082984924, -0.08997305482625961, 0.017252027988433838, 0.04636490345001221, -0.02567986585199833, -0.033046234399080276, 0.005045366007834673, -0.2244998663663864, 0.030582839623093605, -0.056335076689720154, 0.049206458032131195, 0.024205630645155907, -0.03872731700539589, -0.05297895893454552, -0.05074319988489151, 0.012059601955115795, -0.026766706258058548, -0.0011672055115923285, -0.0041892873123288155, 0.02875564992427826, -0.034206416457891464, -0.028044963255524635, 0.031415440142154694, -0.004088256042450666, -0.01469523273408413, -0.05266188457608223, -0.033774930983781815, -0.01610512286424637, -0.001931851846165955, -0.01798674277961254, -0.04036935418844223, 0.05786411464214325, -0.009904618375003338, -0.022743726149201393, 0.0021104116458445787, 0.0612972192466259, 0.011967071332037449, -0.015829704701900482, 0.028732510283589363, 0.059550974518060684, -0.11092884838581085, 0.03445732966065407, 0.014985383488237858, 0.057319484651088715, 0.004035732243210077, 0.005469040013849735, 0.039886049926280975, 0.06937001645565033, -0.0369131825864315, -0.03220633789896965, -0.013660919852554798, 0.03284391388297081, 0.05085121840238571, 0.02323538064956665, 0.04046114906668663, 0.029714079573750496, 0.029711440205574036, 0.0013717440888285637, 0.024724364280700684, 0.04032222926616669, 0.03414199501276016, -0.0011875588679686189, 0.004337575286626816, -0.01907859742641449, -0.007753236684948206, 0.0004199736285954714, -0.012946932576596737, 0.023567939177155495, 0.004163818433880806, -0.023693617433309555, -0.014456802979111671, 0.060271747410297394, -0.06387589871883392, -0.03612498939037323, 0.05088281258940697, 0.0672621801495552, -0.015525533817708492, 0.3469057083129883, 0.020964527502655983, 0.025204982608556747, -0.05410783365368843, -0.01775180734694004, 0.024346478283405304, -0.07840920984745026, 0.034369394183158875, 0.029123254120349884, -0.04108336940407753, 0.03855857625603676, -0.00012945535127073526, -0.010867888107895851, -0.018075866624712944, -0.03858024254441261, -0.00043037740397267044, -0.010666516609489918, 0.04031207412481308, 0.026443053036928177, -0.025301460176706314, -0.009755994193255901, -0.0025174315087497234, 0.006746757309883833, -0.023039326071739197, -0.03271833434700966, 0.03376973420381546, 0.03904014825820923, 0.01940975710749626, 0.11474882811307907, 0.0885821208357811, 0.0073494212701916695, 0.03200686722993851, -0.011075069196522236, -0.03126018866896629, 0.011521052569150925, 0.0001871700951596722, -0.015322810038924217, -0.043706294149160385, 0.016483459621667862, -0.03601257875561714, -0.06233209744095802, -0.00982798170298338, 0.08043236285448074, 0.043142881244421005, 0.0239826962351799, -0.054928943514823914, 0.132982537150383, -0.0341123528778553, 0.010254890657961369, -0.08649475127458572, -0.038078829646110535, 0.02425394207239151, 0.023196928203105927, 0.009206214919686317, -0.005862602032721043, 0.016607219353318214, 0.05816414952278137, -0.025071173906326294, 0.00960509292781353, -0.058683980256319046, 0.024062804877758026, -0.01473066583275795, -0.0341312550008297, -0.00958145223557949, 0.07988572120666504, 0.00994032621383667, -0.0689203143119812, -0.021685725077986717, 0.0031401468440890312, 0.051004186272621155, -0.06219851225614548, 0.005880287848412991, -0.037201590836048126, 0.009588541463017464, -0.032111164182424545, -0.033070456236600876, 0.04364711046218872, -0.06663314998149872, 0.039257440716028214, 0.016421709209680557, 0.03822076693177223, 0.003129107877612114, -0.050014182925224304, -0.007627633400261402, 0.033039119094610214, -0.0061506424099206924, -0.016564011573791504, -0.011387907899916172, 0.0077448333613574505, -0.005035522859543562, 0.0018933260580524802, -0.006761666852980852, -0.009293324314057827, -0.05395270884037018, -0.02102905884385109, 0.02060576155781746, -0.05880562588572502, 0.05436350405216217, 0.002029782859608531, -0.08151119947433472, -0.010308384895324707, 0.037712469696998596, 0.019875913858413696, 0.015206065028905869, 0.027272621169686317, -0.01156821008771658, -0.00929144024848938, 0.019200289621949196, -0.02740284986793995, 0.08524025976657867, 0.03851068392395973, -0.13278444111347198, -0.010778559371829033, -0.01796611398458481, -0.004970972426235676, -0.02283153496682644, 0.022950340062379837, 0.02209257334470749, 0.025642670691013336, -0.008229829370975494, -0.009684151969850063, -0.0034469841048121452, -0.01693584956228733, -0.042968206107616425, -0.35877561569213867, 0.014683688059449196, 0.002718687988817692, 0.007028589025139809, -0.01618272438645363, -0.09044284373521805, -0.016940753906965256, 0.053215526044368744, 0.04403223097324371, 0.020730534568428993, 0.07140683382749557, 0.029647620394825935, -0.02514290250837803, -0.03235888108611107, -0.0012345961295068264, 0.054264459758996964, 0.00479253800585866, -0.038726065307855606, 0.04021221771836281, 0.027379922568798065, 0.027677584439516068, -0.0019502260256558657, -0.0007845418294891715, -0.0539100281894207, 0.005821453873068094, -0.037104398012161255, 0.0971686840057373, -0.018297746777534485, 0.106076180934906, -0.022893741726875305, -0.03490091860294342, 0.021553097292780876, 0.006370356306433678, 0.025021879002451897, 0.06807225197553635, -0.04607001319527626, -0.00028626524726860225, 0.0444088838994503, 0.05488988757133484, -0.005054828245192766, -0.004912866745144129, -0.018277516588568687, 0.015559201128780842, -0.07554133236408234, -0.005516469478607178, -0.00905601680278778, -0.07589989900588989, -0.030291907489299774, 0.04746122285723686, 0.029870769008994102, 0.06883849948644638, 0.000610816350672394, 0.04230432212352753, 0.007273541297763586, -0.017541401088237762, -0.07086298614740372, -0.021052507683634758, -0.07217739522457123, -0.02759370394051075, 0.01470672432333231, -0.006616235710680485, 0.01897352561354637, 0.006581279449164867, -0.04612768813967705, -0.011030560359358788, 0.0397946871817112, 0.0006712204776704311, 0.04405049979686737, 0.07789930701255798, 0.03202376514673233, 0.0005760940257459879, 0.11126267910003662, 0.022747375071048737, 0.002117391675710678, 0.06740869581699371, -0.04358489066362381, -0.016019372269511223, -0.035088252276182175, -0.015009766444563866, -0.027462182566523552, -0.003782493295148015, 0.0390763022005558, 0.10043296217918396, 0.005798934027552605, 0.020366277545690536, -0.02613009326159954, 0.048148829489946365, 0.005518287420272827, 0.032371994107961655, 0.01099237147718668, -0.10780356824398041, -0.00842682272195816, -0.0018841486889868975, 0.008919942192733288, 0.009195663966238499, 0.000817761174403131, -0.2755504846572876, -0.03644751384854317, 0.030733846127986908, 0.02764885686337948, 0.0027063414454460144, -0.047460563480854034, 0.05559409782290459, -0.04746542498469353, -0.05444005876779556, -0.015241336077451706, -0.12053008377552032, 0.04016682505607605, 0.03505354002118111, -0.0358927845954895, -0.00022273704234976321, 0.04647672176361084, 0.08966916799545288, -0.07806015014648438, 0.03281009569764137, -0.01153996679931879, -0.030294140800833702, -0.01044788584113121, 0.1622685194015503, 0.004896530415862799, -2.6651681764633395e-05, -0.06233515962958336, -0.02724304609000683, -0.03349427878856659, 0.06370802968740463, -0.011294161900877953, 0.05508358031511307, 0.06006325036287308, 0.03314327448606491, 0.022986041381955147, -0.006827882956713438, -0.003232021816074848, 0.003385794349014759, 0.011908404529094696, 0.015982724726200104, -0.0020380003843456507, 0.04650414362549782, -0.013650898821651936, -0.005856143776327372, -0.017069581896066666, 0.06140096113085747, -0.013723769225180149, -0.009509587660431862, -0.007209632080048323, -0.023302042856812477, -0.021819908171892166, 0.022086048498749733, -0.015582012012600899, -0.0022090573329478502, -0.045992445200681686, 0.03625631332397461, 0.05469007045030594, -0.028649037703871727, 0.02605496160686016, -0.026781082153320312, 0.02273082360625267, -0.017607467249035835, -0.046237703412771225, -0.01201360858976841, -0.0025982821825891733, 0.014957123436033726], '8081dad5-b35a-4ea0-83d0-9c803016a5de': [-0.03410191088914871, 0.01677563786506653, -0.040808890014886856, 0.046413619071245193, 0.011935998685657978, 0.028830572962760925, -0.015823235735297203, 0.00546359084546566, 0.053387511521577835, 0.01752067729830742, 0.018392743542790413, -0.08023986220359802, 0.029250435531139374, 0.055165283381938934, -0.033799707889556885, 0.0044016470201313496, -0.04692994803190231, -0.01752804033458233, 0.005654597654938698, -0.03725530952215195, 0.0798453688621521, -0.014071005396544933, 0.015301481820642948, -0.07304839044809341, -0.015498309396207333, -0.007436904590576887, -0.03152598813176155, -0.014497337862849236, -0.008015630766749382, -0.23669999837875366, 0.014254693873226643, -0.0491655170917511, 0.04287045821547508, 0.019333096221089363, -0.06340917944908142, 0.058829016983509064, -0.02801397256553173, -0.0037677499931305647, -0.057201653718948364, 0.05721782147884369, -0.02112903632223606, 0.03317834436893463, -0.04342419654130936, -0.02407054416835308, 0.07788416743278503, 0.026557190343737602, -0.025217493996024132, -0.0632849857211113, -0.02801840379834175, 0.018581580370664597, 0.019704028964042664, -0.04711754247546196, -0.00037093303399160504, 0.058756157755851746, -0.0034712878987193108, 0.003571099601686001, 0.04380730539560318, 0.029306164011359215, 0.00745545607060194, 0.0012068200157955289, -0.025857320055365562, 0.03999188542366028, -0.1372508555650711, 0.06653512269258499, -0.03412061557173729, 0.03382222354412079, -0.017978280782699585, -0.028335845097899437, -0.027792971581220627, 0.097038634121418, -0.016567610204219818, -0.028453899547457695, 0.017949216067790985, -0.013472937047481537, 0.0009461239096708596, 0.03862675651907921, 0.04360532760620117, 0.002348232315853238, 0.058000169694423676, -0.004271163139492273, 0.058017585426568985, -0.003965218551456928, -0.04966546595096588, -0.018333490937948227, 0.022207342088222504, -0.0018902241718024015, -0.0033039990812540054, -0.020704202353954315, -0.002798816654831171, 0.02366369590163231, -0.0524178221821785, -0.011254889890551567, -0.03195009008049965, 0.01996382512152195, -0.03994949907064438, 0.005919951479882002, 0.04672182351350784, 0.07088145613670349, -0.06925409287214279, 0.37310999631881714, 0.009562397375702858, -0.03552311286330223, -0.0529036670923233, -0.015460366383194923, -0.026190098375082016, -0.061131712049245834, -0.011190672405064106, 0.032345615327358246, -0.01327818725258112, 0.04131346568465233, -0.06958886981010437, -0.024641942232847214, -0.01659909263253212, -0.027416568249464035, 0.010842235758900642, -0.025091703981161118, -0.0027041565626859665, 0.033184412866830826, -0.014424367807805538, 0.009390389546751976, -0.010155625641345978, -0.01939460262656212, 0.011070197448134422, 0.018950263038277626, -0.010241114534437656, 0.026537302881479263, 0.03713536262512207, 0.08776630461215973, 0.008541539311408997, 0.06032033637166023, 0.072748564183712, -0.019892141222953796, -0.05153018981218338, 0.023103952407836914, 0.041365060955286026, -0.0005023710546083748, -0.015317646786570549, 0.0012571531115099788, -0.07420830428600311, -0.029711220413446426, -0.026511728763580322, 0.10981153696775436, -0.0011698849266394973, 0.04072815924882889, -0.05457180365920067, 0.11227038502693176, -0.02917027659714222, -0.014736953191459179, -0.07527251541614532, -0.06433170288801193, 0.038808099925518036, 0.02618785761296749, -0.0036716896574944258, -0.05070468410849571, -0.00878135021775961, 0.022144829854369164, 0.021325210109353065, -0.06327073276042938, -0.07060883939266205, -0.013124051503837109, -0.012840857729315758, -0.035459838807582855, -0.01558049488812685, 0.0590626522898674, -0.007645421661436558, -0.02500605210661888, -0.03819988667964935, 0.014914157800376415, 0.011890877969563007, -0.04808083176612854, 0.03623717650771141, -0.02512737736105919, -0.011913420632481575, -0.017552610486745834, -0.010672951117157936, 0.04971390962600708, -0.0314970463514328, -0.025563040748238564, -0.0034681891556829214, 0.013076066970825195, 0.0024277225602418184, -0.10217597335577011, -0.020820219069719315, 0.02280329167842865, 0.020842790603637695, -0.0064696697518229485, -0.005457339808344841, -0.03262777253985405, 0.009170395322144032, -0.021081827580928802, -0.010450874455273151, 0.021404679864645004, -0.06772203743457794, 0.012137793004512787, -0.006750539410859346, -0.018432509154081345, 0.010486872866749763, 0.04054511338472366, -0.03746999055147171, -0.04158370941877365, 0.015566308982670307, 0.06577310711145401, 0.03187123313546181, -0.014619696885347366, -0.011215290986001492, -0.016241377219557762, 0.019137175753712654, -0.026217777281999588, 0.04645986109972, 0.05181064456701279, -0.10134907811880112, -0.0441749207675457, -0.007323188707232475, 0.013754614628851414, -0.01322823017835617, 0.0006141266203485429, 0.017142565920948982, -0.01065234374254942, -0.014949895441532135, 0.0004493228334467858, -0.002810511738061905, 0.00935613177716732, -0.0040895710699260235, -0.33084118366241455, -0.0007180086686275899, 0.029154689982533455, 0.011054834350943565, 0.026023000478744507, -0.10916918516159058, 0.025270216166973114, 0.0069502415135502815, 0.02625204436480999, 0.0455840528011322, 0.05500912293791771, -0.0403992235660553, -0.008600770495831966, 0.003280828706920147, 0.02557946741580963, 0.019433895125985146, -0.002834276994690299, -0.024024229496717453, 0.02136189118027687, 0.00936681218445301, 0.0185021311044693, 0.010767169296741486, 0.0970839411020279, -0.09551728516817093, -0.01370175275951624, -0.03478251025080681, 0.07152222096920013, -0.026749998331069946, 0.09979664534330368, -0.0038970550522208214, -0.01853121630847454, 0.04580802842974663, 0.05533187836408615, 0.0568237379193306, 0.05322274565696716, -0.06490705162286758, 0.06821166723966599, 0.003586691338568926, 0.012195663526654243, 0.021158544346690178, -0.0205517765134573, 0.010166608728468418, 0.009849394671618938, -0.06215678155422211, -0.022907424718141556, -0.016050439327955246, -0.04251539334654808, -0.0001222648425027728, 0.0007106565753929317, 0.04732736945152283, 0.04571603983640671, 0.0025650192983448505, 0.06622931361198425, -0.016752831637859344, -0.025177979841828346, -0.04508500173687935, -0.08234977722167969, -0.03239106759428978, -0.030414169654250145, -0.024842550978064537, 0.013787096366286278, -0.03845801576972008, 0.016732044517993927, -0.050568196922540665, -0.017591899260878563, -0.003743463195860386, 0.06282373517751694, -0.0048830523155629635, 0.021253647282719612, 0.001050638733431697, 0.014584667980670929, 0.12150061875581741, 0.000699363648891449, 0.022063933312892914, 0.059367354959249496, 0.004106737673282623, -0.025685781612992287, -0.04653577879071236, -0.09336543828248978, 0.024400200694799423, 0.02141731232404709, 0.010602688416838646, 0.04637867584824562, 0.0037551845889538527, 0.06611603498458862, 0.018369106575846672, 0.07482914626598358, 0.0451025664806366, 0.04056491330265999, 0.05864256992936134, -0.05799238383769989, 0.0014484876301139593, -0.006562218070030212, 0.002545461291447282, -0.0002993810921907425, -0.07152348011732101, -0.2763901352882385, -0.021212181076407433, 0.026668580248951912, 0.05374809727072716, 0.013206618838012218, -0.007268542889505625, 0.06338758766651154, -0.02664642035961151, -0.026637377217411995, -0.03363746404647827, -0.0808810442686081, 0.045493029057979584, 0.05863282084465027, 0.004354021977633238, 0.03279227018356323, 0.0510689839720726, 0.09429135173559189, -0.07560738176107407, 0.019836483523249626, -0.013376048766076565, 0.013109085150063038, -0.003117924788966775, 0.1408488154411316, -0.04216832295060158, -0.006186116021126509, -0.01278977282345295, -0.030246298760175705, -0.043695177882909775, 0.0808940902352333, -0.02721930481493473, 0.048195306211709976, 0.04012817144393921, 0.07383459806442261, 0.014983797445893288, 0.007064140867441893, 0.02077154442667961, -0.039014577865600586, 0.021237099543213844, 0.03513995558023453, -0.008017513900995255, 0.029941406100988388, 0.024796733632683754, 0.035652030259370804, 0.030196217820048332, -0.0030499715358018875, 0.012116753496229649, 0.00022739525593351573, 0.028810396790504456, -0.06523288041353226, 5.8688761782832444e-05, 0.03156471624970436, 0.01447000727057457, 0.02695079892873764, -0.034589942544698715, 0.062402136623859406, 0.0031935940496623516, -0.03711871802806854, -0.011585565283894539, -0.028929904103279114, 0.002676265314221382, 0.032637905329465866, -0.03320954367518425, 0.02669454738497734, -0.012471916154026985, -0.007910075597465038], '426f08c2-0273-418a-a0f0-3a6ee9a61fee': [-0.043090637773275375, 0.015974748879671097, -0.0510181188583374, 0.012339283712208271, 0.021131351590156555, -0.006431601941585541, -0.061067692935466766, -0.017128504812717438, 0.0036826974246650934, -0.0002216051216237247, -0.02056126482784748, -0.09997926652431488, 0.011608568951487541, 0.06078445538878441, -0.04576217755675316, -0.005397294647991657, -0.04891775920987129, 0.02138594351708889, -0.04661767557263374, -0.018298372626304626, 0.018310172483325005, -0.02728208526968956, -0.013470767997205257, -0.03370897099375725, 0.01475575938820839, 0.028190461918711662, -0.022985676303505898, -0.06216021627187729, 0.00918883178383112, -0.2015712857246399, 0.04940510913729668, -0.015416792593896389, 0.011728223413228989, -0.02361985296010971, -0.018595000728964806, 0.03265930339694023, -0.028230959549546242, 0.04001472517848015, -0.02586195059120655, 0.02864064835011959, 0.04203125834465027, 0.03313889354467392, -0.059109244495630264, -0.00017694279085844755, 0.03581685200333595, -0.0816008672118187, -0.025559846311807632, -0.012581918388605118, 0.01288338378071785, 0.05841103568673134, -0.015586847439408302, -0.010849843733012676, -0.022445261478424072, 0.02174827829003334, -0.006441693287342787, 0.006125946994870901, 0.031560420989990234, 0.0444830060005188, 0.01912146992981434, -0.025279220193624496, -0.01454148255288601, 0.047909513115882874, -0.19052298367023468, 0.06656020879745483, -0.007207049522548914, 0.022725937888026237, -0.011995036154985428, -0.008552061393857002, 3.052420652238652e-05, 0.09077358990907669, -0.0650133565068245, 0.03426574170589447, 0.029277509078383446, 0.08360111713409424, 0.014977261424064636, 0.006763010285794735, 0.04805610328912735, 0.01183339487761259, 0.016824927181005478, 0.019779104739427567, 0.0019983246456831694, 0.042130954563617706, 0.025147343054413795, -0.030659714713692665, 0.013412969186902046, -0.011853093281388283, -0.03511032089591026, 0.0016151487361639738, 0.020901663228869438, 0.015865107998251915, -0.00493662990629673, -0.020335715264081955, -0.007643582299351692, 0.07814303785562515, -0.08810748904943466, -0.06666014343500137, 0.04219833016395569, 0.04022521153092384, 0.001415865495800972, 0.35534149408340454, 0.0030700298957526684, -0.011140197515487671, -0.04993056133389473, -0.015531391836702824, 0.007299398072063923, -0.008986755274236202, 0.023301130160689354, 0.01918710768222809, -0.009798794984817505, 0.03248244896531105, -0.013311847113072872, 0.0207884032279253, 0.02079702541232109, -0.07549922913312912, 0.021271005272865295, -0.031578194350004196, 0.027124306187033653, -0.00837606843560934, 0.0017645707121118903, 0.05470266565680504, 0.0024092369712889194, -0.001518641016446054, -0.01874646544456482, -0.013242802582681179, -0.006227926351130009, 0.05092686414718628, 0.02773434668779373, 0.06073387339711189, 0.03066229075193405, -0.0014751951675862074, 0.05056339129805565, 0.011834267526865005, -0.07002558559179306, -0.0028685545548796654, -0.022315915673971176, 0.0011313214199617505, 0.014547445811331272, -0.003179041901603341, -0.01968497969210148, -0.005888880230486393, 0.007252635434269905, 0.028858736157417297, 0.06208864599466324, 0.019849447533488274, -0.0349414236843586, 0.14362439513206482, -0.025248181074857712, -0.05506884679198265, -0.10175691545009613, -0.015991823747754097, 0.03271199017763138, 0.05727576091885567, 0.04524839296936989, -0.03690188750624657, 0.03153665363788605, 0.08320848643779755, 0.025271287187933922, -0.007204984314739704, -0.05078815296292305, 0.003467914881184697, -0.007442675065249205, -0.030002105981111526, -0.011720662005245686, 0.04993661865592003, 0.08467482030391693, -0.03315754234790802, 0.006067395210266113, 0.014868296682834625, 0.014029055833816528, -0.03943102806806564, 0.05613899603486061, -0.03805501013994217, -0.050558075308799744, 0.007119299843907356, -0.03299065679311752, 0.027136128395795822, -0.03899490460753441, 0.036762744188308716, 0.019979961216449738, 0.05016695708036423, 0.011624790728092194, -0.008021097630262375, -0.0018253613961860538, 0.03264904022216797, 0.025326760485768318, 0.009405847638845444, -0.036257304251194, -0.017642445862293243, 0.010214259847998619, -0.016912205144762993, -0.016443422064185143, 0.04274759069085121, -0.03034510649740696, -0.007406046148389578, 0.012869431637227535, -0.037907812744379044, 0.03762106969952583, -0.018366597592830658, -0.020530464127659798, 0.021610358729958534, 0.04403486102819443, 0.035125426948070526, 0.009514743462204933, -0.016473660245537758, -0.006065217778086662, -0.013814018107950687, -0.0131582822650671, -0.008778931573033333, 0.025441130623221397, 0.005072711035609245, -0.07387348264455795, -0.011102604679763317, -0.025194015353918076, 0.0037174862809479237, -0.07991720736026764, -0.023718267679214478, 0.02714637853205204, 0.008790121413767338, -0.017864765599370003, 0.014848197810351849, -0.011272598057985306, -0.049024347215890884, -0.010597320273518562, -0.38389554619789124, 0.0008721378981135786, 0.022803258150815964, -0.004503507632762194, 0.02245597168803215, -0.09125605970621109, 0.014717948623001575, 0.051930200308561325, -0.015316014178097248, 0.02750042825937271, 0.07231689989566803, -0.006990925408899784, -0.0008250036044046283, -0.05141478404402733, -0.012402928434312344, 0.01981525309383869, 0.024238476529717445, -0.07381253689527512, 0.02332208678126335, 0.048173148185014725, 0.015989968553185463, 0.0038920340593904257, 0.004389508161693811, -0.08548527210950851, 0.05240320414304733, -0.042329348623752594, 0.11536290496587753, -0.0012975017307326198, 0.07157319039106369, -0.06833091378211975, 0.008096061646938324, 0.010602143593132496, 0.014051279984414577, -0.018046600744128227, 0.0669073536992073, -0.030683519318699837, 0.022410530596971512, 0.06529120355844498, 0.047267377376556396, 0.012055681087076664, -0.021059701219201088, 0.028449324890971184, 0.018507156521081924, -0.0925479605793953, -0.0022063495125621557, -0.0035275956615805626, -0.03131842240691185, -0.09908079355955124, 0.048398274928331375, 0.005150697194039822, 0.018284928053617477, 0.028911888599395752, 0.05247702822089195, -0.016153130680322647, 0.007330721244215965, -0.034805797040462494, -0.07336919754743576, 0.008727673441171646, -0.017406726256012917, -0.033681727945804596, -0.007299621589481831, 0.020141910761594772, 0.04175461083650589, -0.048956193029880524, 0.010502303019165993, -0.02165057137608528, 0.01823701523244381, 0.012370756827294827, 0.08060123026371002, 0.03060103952884674, 0.026188924908638, 0.06700338423252106, 0.03030332177877426, 0.01677042990922928, 0.03893999755382538, -0.0008343355730175972, -0.04326328635215759, 0.03707146272063255, -0.05052171275019646, 0.010236341506242752, 0.01506253145635128, -0.02284572273492813, 0.04989650472998619, 0.03822966665029526, 0.035379715263843536, 0.013722209259867668, 0.061281587928533554, 0.011455483734607697, 0.0439767986536026, 0.01907351054251194, -0.08862554281949997, -0.03210325539112091, -0.027002280578017235, 0.04222928732633591, 0.0630265399813652, 0.033961374312639236, -0.28107452392578125, -0.0018623725045472383, 0.009641281329095364, 0.04187046363949776, 0.022907886654138565, -0.03348974883556366, 0.023745886981487274, -0.04777601361274719, -0.019024645909667015, -0.00809897668659687, -0.06683376431465149, 0.057738643139600754, -0.008348457515239716, -0.05254780873656273, -0.035427361726760864, 0.03892774134874344, 0.10683603584766388, -0.05042639002203941, -0.0006337554077617824, -0.0516216903924942, -0.006825104355812073, -0.027670063078403473, 0.13985109329223633, -0.02635396271944046, -0.022935718297958374, -0.048190440982580185, -0.062469977885484695, -0.053898558020591736, 0.09328768402338028, -0.008152191527187824, 0.0023927660658955574, 0.043233659118413925, 0.06792940199375153, 0.024340756237506866, 0.013771521858870983, 0.03787960484623909, -0.01193932630121708, -0.007274172734469175, 0.0009441753500141203, 0.01768544502556324, 0.013937246054410934, 0.002839369000867009, -0.008588235825300217, -0.001344954245723784, 0.027658501639962196, -0.0440906397998333, -0.0351225882768631, -0.06301882117986679, -0.0021217854227870703, 0.017876140773296356, 0.02735821157693863, -0.0049316068179905415, -0.061091098934412, -0.012438639998435974, 0.045658212155103683, 0.041131287813186646, -0.015676913782954216, -0.004363261163234711, -0.0021780282258987427, -0.01393669843673706, -0.04630950093269348, -0.07528488337993622, -0.0036816373467445374, -0.01282187458127737, 0.016918417066335678], 'd3415939-c466-4dfe-9018-3d21344c007e': [-0.08783604949712753, 0.052507854998111725, 0.006132050883024931, 0.03261042386293411, 0.03520366922020912, 0.006555419415235519, -0.03302018344402313, 0.01948661170899868, 0.038586024194955826, -0.0009284532279707491, 0.02738613821566105, -0.0539495088160038, 0.023309629410505295, 0.046841368079185486, -0.052502796053886414, -0.014638015069067478, -0.04231303930282593, 0.008546361699700356, -0.012841528281569481, -0.06917621940374374, 0.029905302450060844, -0.04065392538905144, -0.011823653243482113, -0.03196388855576515, 0.024058444425463676, 0.02973165363073349, -0.05912671983242035, 0.011175517924129963, -0.04729073867201805, -0.23588867485523224, 0.06057362258434296, -0.057660434395074844, 0.049836449325084686, -0.001014609937556088, -0.021123439073562622, 0.04908297210931778, -0.020328521728515625, -0.0027100308798253536, -0.053065184503793716, 0.044328540563583374, 0.04410337656736374, 0.05012365058064461, -0.06026695296168327, -0.010049481876194477, 0.03293228521943092, -0.01831595040857792, -0.046456824988126755, -0.01719866879284382, -0.045390769839286804, 0.0687759593129158, -0.008991863578557968, -0.03613441064953804, 0.005531754344701767, 0.008449088782072067, -0.015519063919782639, -0.03090493753552437, 0.06956890970468521, 0.05169783905148506, 0.03361337259411812, -0.02869814820587635, 0.006382748484611511, 0.0073480140417814255, -0.18998365104198456, 0.05480130761861801, 0.003953053615987301, 0.007938811555504799, -0.03471681848168373, -0.06815395504236221, -0.03084712289273739, 0.06067203730344772, -0.01976068876683712, -0.00504349684342742, 0.06160811707377434, 0.040931250900030136, 0.0007709035999141634, 0.018755896016955376, 0.04040354862809181, 0.0010767248459160328, 0.04757136106491089, -0.011999079026281834, 0.022649021819233894, 0.001970501383766532, -0.006392751820385456, -0.01167234592139721, 0.058762647211551666, -0.02462642453610897, 0.004377954173833132, 0.04593494534492493, 0.009734026156365871, -0.006256528198719025, -0.002339060651138425, -0.017041902989149094, -0.04092755541205406, 0.057927921414375305, -0.045080263167619705, 0.009769470430910587, 0.0386383943259716, 0.034704867750406265, -0.04354628175497055, 0.3605542480945587, -0.03979140892624855, 0.015743933618068695, -0.027345500886440277, 0.05083624646067619, -0.008730593137443066, -0.053318340331315994, 0.013818864710628986, -0.008152413181960583, -0.0124673405662179, -0.016915198415517807, -0.0022613168694078922, -0.0025906600058078766, 0.07636073976755142, -0.051099058240652084, -0.03437688201665878, 0.006654697936028242, 0.022516675293445587, 0.05681673809885979, -0.01242415513843298, 0.03268580138683319, -0.005622098222374916, 0.010349460877478123, 0.038056354969739914, 0.02450481615960598, 0.05477223917841911, 0.025322867557406425, 0.027173055335879326, 0.09933322668075562, 0.037220221012830734, 0.03568322956562042, 0.028630806133151054, -0.02279062196612358, -0.04726914316415787, 0.01263095811009407, 0.01725725084543228, 0.010816622525453568, -0.000599672261159867, -0.03261641040444374, -0.005993552040308714, 0.029871368780732155, -0.027064165100455284, 0.04722623527050018, 0.01663905382156372, 0.00418097572401166, -0.041804924607276917, 0.17422541975975037, 0.003906604368239641, 0.0014669313095510006, -0.03305488079786301, -0.0659429132938385, 0.04062478616833687, 0.04246600717306137, 0.027771126478910446, -0.007673946209251881, 0.030864905565977097, 0.05654342100024223, -0.028474383056163788, -0.003762694075703621, -0.09665440768003464, 0.016390640288591385, -0.0756223201751709, -0.020142657682299614, -0.044707950204610825, 0.02995649352669716, -0.0038105924613773823, -0.016875766217708588, -0.06080292910337448, -0.006113462150096893, 0.014317790977656841, -0.042086921632289886, 0.04492146521806717, -0.0006081178435124457, -0.025792574509978294, -0.0451086163520813, 0.011422830633819103, -0.03070656768977642, -0.017840296030044556, -0.019373876973986626, 0.03469337522983551, 0.009392911568284035, 0.05153156816959381, -0.03905211389064789, 0.011108441278338432, 0.005495528690516949, 0.011697749607264996, 0.015853991732001305, -0.04715970158576965, -0.043471649289131165, 0.0019366330234333873, 0.04430319368839264, -0.07653043419122696, -0.026209769770503044, -0.027665933594107628, 0.010614615865051746, -0.013790514320135117, -0.03970639407634735, -0.023208972066640854, -0.004890806972980499, -0.015586101450026035, 0.0374043807387352, 0.0915408730506897, 0.030711201950907707, 0.03985506296157837, -0.04455262050032616, -0.018693488091230392, 0.013489711098372936, -0.028119420632719994, -0.024405673146247864, 0.020267460495233536, 0.05387850105762482, -0.0794634073972702, -0.052659496665000916, -0.0005890752654522657, 0.024505792185664177, -0.012112649157643318, -0.014100350439548492, 0.03305184841156006, -0.003054619999602437, -0.03591557592153549, 0.03388574719429016, 0.018028171733021736, -0.05214622989296913, -0.0033272635191679, -0.33630990982055664, -0.008733240887522697, 0.04506519064307213, 0.008240684866905212, 0.08995696157217026, -0.11361071467399597, 0.03527327626943588, -0.028255019336938858, 0.029151059687137604, -0.0031834193505346775, 0.05685536935925484, 0.03468203917145729, 0.005113804247230291, -0.06610260903835297, 0.004989974666386843, 0.015461768954992294, 0.03276435285806656, -0.016191434115171432, -0.023608382791280746, 0.013743193820118904, 0.023300765082240105, 0.0004320777370594442, 0.03865249454975128, -0.09386410564184189, 0.00906514935195446, -0.030737007036805153, 0.096840038895607, -0.04575195163488388, 0.07102581113576889, -0.016434164717793465, 0.006997103802859783, 0.035535890609025955, 0.043814100325107574, 0.0021970283705741167, 0.06429337710142136, -0.03972959890961647, 0.031036242842674255, 0.028775401413440704, 0.03030480071902275, 0.0017336923629045486, -0.004483041353523731, 0.003222235245630145, 0.05498829856514931, -0.09622151404619217, -0.0043124547228217125, 0.036058299243450165, -0.015504925511777401, -0.015002546831965446, -0.0151209169998765, 0.024398198351264, 0.03452213481068611, 0.03103863261640072, 0.07381168007850647, -0.028341732919216156, 0.0069947624579072, -0.049363505095243454, -0.10391999781131744, 0.024699639528989792, -0.06136496737599373, -0.003406000090762973, 0.02183111384510994, -0.04080399125814438, 0.010052837431430817, -0.037000395357608795, 0.04468371346592903, -0.03288272023200989, 0.03220263123512268, 0.020240124315023422, 0.017349204048514366, 0.019188178703188896, -0.030313899740576744, 0.036974143236875534, -0.02043573558330536, 0.017144888639450073, 0.03116491436958313, 0.0274202860891819, -0.019040580838918686, -0.0004735141119454056, -0.03582772612571716, 0.0024647607933729887, -7.535110489698127e-05, -0.015705881640315056, 0.05269259959459305, 0.05334233492612839, 0.007742008194327354, -0.03101247362792492, 0.05767481029033661, -0.019964680075645447, 0.01980004832148552, 0.02765844576060772, -0.11348319053649902, -0.04520059749484062, -0.04772564023733139, 0.005258410237729549, 0.04470221325755119, 0.008569600991904736, -0.24910703301429749, -0.06136200577020645, 0.01866147108376026, 0.043367497622966766, -0.015528068877756596, -0.04276188090443611, 0.03461795672774315, -0.05756543576717377, -0.04633660614490509, -0.03954211249947548, -0.06498382985591888, 0.026014598086476326, 0.03310970962047577, -0.022475039586424828, 0.016559727489948273, 0.006889814510941505, 0.04676705226302147, -0.041267141699790955, 0.03472462669014931, 0.009744387120008469, -0.0036540578585118055, 0.02224847488105297, 0.1329362690448761, -0.006663699634373188, -0.06932439655065536, 0.005639410112053156, -0.031755466014146805, -0.05542351305484772, 0.07736419886350632, 0.038642484694719315, 0.004622283391654491, 0.025270333513617516, 0.11034458130598068, 0.016491374000906944, 0.020866505801677704, 0.044008247554302216, -0.021908579394221306, -0.025703925639390945, 0.027452198788523674, -0.01789029873907566, 0.06540476530790329, 0.01969282142817974, 0.017504164949059486, 0.0011432365281507373, 0.09446050226688385, -0.0032877607736736536, -0.02787652797996998, -0.011082115583121777, -0.06799353659152985, 0.01793418452143669, -0.030056465417146683, 0.036365289241075516, -0.028142988681793213, -0.05436111241579056, 0.03973326086997986, 0.018608087673783302, -0.0021824706345796585, -0.004125812090933323, -0.02641022764146328, 0.0002096140815410763, -0.017722172662615776, -0.03126591816544533, 0.05646200105547905, -0.04586876928806305, -0.006321163848042488], '9a70d22e-e788-4806-a617-3a8de5a3deb7': [-0.04189478978514671, 0.007264554966241121, -0.020607177168130875, -0.00286183413118124, 0.03465082868933678, -0.03410402685403824, -0.020888278260827065, 0.016660021618008614, 0.013001606799662113, 0.004586014896631241, -0.013609055429697037, -0.07638467103242874, -0.0014840865042060614, 0.015253135934472084, -0.017625100910663605, -0.00244515691883862, -0.05788903310894966, -0.0097381342202425, -0.023504232987761497, -0.019693713635206223, 0.035684164613485336, 0.008899841457605362, 0.008695386350154877, -0.049561116844415665, 0.012343382462859154, 0.05048906058073044, -0.024370089173316956, -0.028369829058647156, 0.0425601564347744, -0.19925875961780548, 0.042056187987327576, -0.0388130322098732, 0.010745182633399963, 0.05061476677656174, -0.04355420917272568, 0.023895474150776863, -0.017001930624246597, 0.01653718575835228, -0.01952368952333927, 0.034373875707387924, 0.021062202751636505, 0.005610238295048475, -0.008840415626764297, -0.022391805425286293, 0.05382908135652542, -0.06535894423723221, -0.05518316105008125, 0.006673414725810289, -0.013995221816003323, 0.07794944941997528, -0.02664683386683464, -0.032768458127975464, -0.045563068240880966, 0.03143874183297157, 0.010998659767210484, 0.009324610233306885, 0.027870815247297287, 0.07199553400278091, -0.0033527063205838203, 0.004546226002275944, 0.024235188961029053, 0.04408479854464531, -0.18407246470451355, 0.06242607906460762, -0.05720159783959389, 0.06737688928842545, 0.004328557755798101, 0.01632632128894329, -0.00892977137118578, 0.06761956214904785, -0.0640370324254036, -0.012059644795954227, 0.028747618198394775, 0.07526073604822159, 0.011410722509026527, 0.04083514213562012, 0.030538838356733322, 0.007928535342216492, 0.034613560885190964, 0.022132718935608864, 0.024866096675395966, 0.03450002521276474, 0.001454047509469092, 0.012024394236505032, 0.0048257592134177685, 0.006918890867382288, -0.018540961667895317, 0.018248334527015686, 0.007293017115443945, 0.00846862606704235, 0.0013619860401377082, -0.023236600682139397, 0.041527919471263885, 0.07979898154735565, -0.07558077573776245, -0.031686823815107346, 0.0394575297832489, 0.008825776167213917, -0.021762197837233543, 0.3354038894176483, 0.009333949536085129, 0.006159214302897453, -0.0342399962246418, -0.045297324657440186, 0.020657338201999664, -0.04528385400772095, 0.014129162766039371, 0.008619082160294056, -0.024920281022787094, 0.056945767253637314, -0.0366620235145092, -0.015777096152305603, 0.033889539539813995, -0.07115750759840012, 0.0017970154294744134, -0.016100287437438965, 0.030515991151332855, -0.009791546501219273, 0.03277904912829399, 0.04780073091387749, -0.010105359368026257, 0.014742524363100529, -0.0025702763814479113, -0.023623384535312653, 0.014504680410027504, 0.048759330064058304, 0.01616554893553257, 0.061898715794086456, 0.041664011776447296, 0.04221447929739952, 0.040159761905670166, 0.007482336368411779, -0.07088726758956909, -0.011833355762064457, 0.012610185891389847, -0.03237486630678177, -0.0005497850361280143, 0.020113861188292503, -0.03474976122379303, 0.027878079563379288, 0.044084127992391586, 0.05314669385552406, 0.034977272152900696, 0.018198056146502495, -0.03473922982811928, 0.1508139669895172, -0.013883511535823345, -0.047757573425769806, -0.08162901550531387, -0.0320877879858017, 0.05300562083721161, 0.07642350345849991, 0.039680738002061844, -0.05241050943732262, 0.0269206203520298, 0.10144127160310745, 0.003538859775289893, 0.020701253786683083, -0.07662615925073624, -0.018904972821474075, -0.03966823220252991, -0.03957733139395714, -0.06428632140159607, 0.06327047944068909, 0.02393769659101963, -0.0267037320882082, -0.02849685028195381, 0.05320072919130325, 0.03663519397377968, -0.08611467480659485, 0.0470045767724514, -0.005935173016041517, -0.05433833971619606, 0.01681714877486229, -0.03371617570519447, 0.04265840724110603, -0.03951399400830269, 0.0017237808788195252, 0.02067212574183941, 0.0655658170580864, -0.010597994551062584, -0.03728845342993736, -0.045110687613487244, 0.04075912758708, -0.005544835701584816, 0.015943588688969612, -0.05755229666829109, -0.05109367519617081, 0.023609744384884834, -0.007014227565377951, 0.020197419449687004, 0.08873216062784195, -0.04964093863964081, 0.010630513541400433, -0.0016029690159484744, -0.041682060807943344, 0.0072183492593467236, 0.0006873119273222983, -0.011168698780238628, 0.01494396198540926, 0.06094640865921974, 0.05781835690140724, 0.002779305214062333, -0.0015893243253231049, -0.0263349711894989, -0.04886521026492119, -0.0035492905881255865, -0.041184939444065094, 0.008309532888233662, 0.006984316743910313, -0.07046592980623245, 0.0013227867893874645, -0.02898884192109108, 0.023761853575706482, -0.03069702908396721, -0.02089732512831688, 0.025374356657266617, 0.01055007055401802, -0.02709364891052246, 0.023711875081062317, -0.03441621735692024, -0.033895622938871384, -0.023291882127523422, -0.3665006756782532, -0.0015889315400272608, 0.02053530514240265, 0.0359988696873188, 0.010957496240735054, -0.0950973853468895, -0.019452501088380814, 0.009773921221494675, 0.01180911622941494, 0.015626631677150726, 0.07014142721891403, 0.0007822735351510346, -0.006633432116359472, -0.053058743476867676, -0.007726600859314203, 0.0036269512493163347, -0.007053091190755367, -0.05560776963829994, 0.0003734910278581083, 0.010024268180131912, 0.02892133593559265, -0.029546186327934265, -0.01938953995704651, -0.11120546609163284, 0.009932229295372963, -0.011812970042228699, 0.0829828530550003, -0.0317603275179863, 0.06265159696340561, -0.051467061042785645, 0.0684795081615448, -0.004489236976951361, 0.028357237577438354, -0.024195408448576927, 0.08271071314811707, -0.0601477287709713, 0.018660707399249077, 0.06362759321928024, 0.042750317603349686, 0.027778374031186104, 0.006854414939880371, -0.00422307476401329, 0.0023082096595317125, -0.049158573150634766, -0.04127999767661095, 0.0019688750617206097, -0.0026305541396141052, -0.062024712562561035, 0.0509953647851944, 0.005771426949650049, 0.0104352543130517, 0.08859870582818985, 0.034822799265384674, -0.01041531190276146, -0.040945496410131454, -0.0511556938290596, -0.023342303931713104, -0.01982155628502369, -0.019554907456040382, -0.030452553182840347, 0.025587880983948708, 0.03335950896143913, 0.039760250598192215, -0.019830098375678062, 0.012255335226655006, -0.009072089567780495, 0.03911856934428215, 0.018360506743192673, 0.0656108632683754, 0.032474417239427567, -0.027425173670053482, 0.08638609200716019, -0.012775309383869171, 0.027119165286421776, 0.03890875354409218, 0.01655179262161255, -0.05926724895834923, 0.003823467530310154, -0.04792415350675583, 0.013040433637797832, 0.01180756650865078, -0.02577895112335682, 0.05595932528376579, -0.004679111298173666, 0.02718339115381241, 0.011390752159059048, 0.04129914939403534, 0.02356008253991604, 0.026161732152104378, 0.03169742226600647, -0.0727384015917778, -0.047690242528915405, -0.02652072161436081, 0.03231940418481827, 0.04249199479818344, -0.004869528114795685, -0.2964770793914795, 0.005697328131645918, -0.03162947669625282, -0.0058401464484632015, 0.03350019082427025, -0.004062943160533905, 0.05322406440973282, -0.05966804549098015, -0.03293537721037865, -0.015752645209431648, -0.03899882733821869, 0.004602392204105854, 0.028624622151255608, -0.040927086025476456, -0.03456173464655876, 0.03653617948293686, 0.11236824095249176, -0.04935527220368385, 0.02056783437728882, -0.043593909591436386, 0.01811145432293415, -0.04172155633568764, 0.18237918615341187, 0.027802955359220505, -0.013090482912957668, -0.03473660349845886, -0.02252271957695484, -0.035196706652641296, 0.0886010229587555, -0.019017141312360764, -0.005662175826728344, 0.04143267869949341, 0.0662221610546112, 0.022388942539691925, 0.02351163886487484, -0.0012183173093944788, -0.030407404527068138, 0.006285552866756916, 0.006729986052960157, 0.0191522017121315, 0.009750104509294033, 0.03475651517510414, -0.021000122651457787, -0.017753632739186287, 0.06544830650091171, -0.02804548852145672, -0.02037157118320465, -0.06889257580041885, -0.025561535730957985, -0.0007132787723094225, 0.008212069980800152, 0.012164927087724209, -0.056591760367155075, -0.054852813482284546, 0.019650129601359367, 0.020624838769435883, -0.04228229820728302, -0.01770707778632641, -0.008713980205357075, 0.026456845924258232, -0.03269258886575699, -0.053204961121082306, -0.005110169295221567, -0.009057686664164066, 0.012776501476764679], '636d12f6-e916-45b9-aa9f-bd3e3503851f': [-0.016006313264369965, 0.004356021527200937, -0.04016329348087311, 0.041546545922756195, 0.05210708826780319, -0.010182981379330158, 0.02562207169830799, 0.03193318843841553, 0.03823273628950119, -0.026807226240634918, -0.004631113726645708, -0.0967392772436142, 0.019236763939261436, 0.02175326459109783, -0.03465605154633522, -0.0062397844158113, -0.034439537674188614, -0.020772380754351616, -0.018545519560575485, -0.055075451731681824, 0.04362893104553223, 0.01657824218273163, 0.012654874473810196, -0.027930332347750664, 0.03758639842271805, 0.030768685042858124, -0.014127060770988464, -0.018491776660084724, 0.04065116122364998, -0.2179897576570511, 0.04079126939177513, -0.054185204207897186, 0.02239011973142624, 0.028226954862475395, -0.03242626413702965, 0.05343800038099289, 0.003322941018268466, 0.02949700318276882, -0.03923507407307625, 0.04112304002046585, 0.013942182064056396, 0.002351375063881278, 0.017978480085730553, -0.010200543329119682, 0.07201893627643585, -0.06949032843112946, -0.03280014544725418, -0.0071930414997041225, -0.010956431739032269, 0.06904777884483337, 0.01850542426109314, -0.03430178761482239, -0.031170032918453217, 0.04001476243138313, 0.037977784872055054, 0.012470416724681854, 0.021598991006612778, 0.05165516585111618, 0.011635162867605686, 0.013172036036849022, 0.04889078065752983, 0.009416517801582813, -0.1906903088092804, 0.03226547688245773, -0.052468057721853256, 0.027661345899105072, -0.024913722649216652, 0.028792431578040123, -0.03617740422487259, 0.07762700319290161, -0.03981097415089607, -0.02114560455083847, 0.06984463334083557, 0.06261434406042099, 0.01201864704489708, 0.026691535487771034, 0.022167108952999115, -0.0038277525454759598, 0.012388257309794426, 0.00764100207015872, 0.032958146184682846, 0.009973999112844467, 0.012777440249919891, 0.006630997639149427, 0.033731695264577866, -0.020494146272540092, 0.01339719258248806, -0.004469105042517185, 0.03341647982597351, -0.026955222710967064, 0.013480830937623978, -0.019805975258350372, 0.03832295164465904, 0.06480074673891068, -0.03702303394675255, -0.02065134607255459, 0.05864884331822395, 0.020391864702105522, -0.0161058958619833, 0.34202760457992554, -0.0025608795695006847, -0.018116697669029236, -0.05404515564441681, -0.040778134018182755, 0.021375877782702446, -0.06751339882612228, 0.021043000742793083, -0.007189815863966942, -0.007468905299901962, 0.06176752224564552, -0.010745251551270485, -0.0375702790915966, 0.0004902777727693319, -0.030192965641617775, -0.01959380879998207, 0.012529236264526844, -0.00880109891295433, 0.022061578929424286, 0.052306778728961945, 0.023037947714328766, -0.04661140963435173, 0.006908494513481855, 0.030184518545866013, 0.011898159049451351, 0.039655789732933044, 0.036733273416757584, -0.013127909041941166, 0.07715590298175812, 0.03882676735520363, 0.03165949136018753, 0.04614045470952988, 0.0003174516896251589, -0.07025673240423203, -0.034362733364105225, 0.05198712274432182, -0.03701275959610939, 0.004939517471939325, 0.0040984610095620155, -0.02731240540742874, 0.01964757777750492, 0.03279463201761246, 0.03568478673696518, 0.04243045300245285, 0.02224818803369999, -0.018249036744236946, 0.14885322749614716, 0.003923395648598671, -0.04518850892782211, -0.03783062845468521, -0.043212998658418655, 0.03239813446998596, 0.08146506547927856, 0.012170306406915188, -0.06963888555765152, 0.0031235222704708576, 0.06529983133077621, 0.0034895564895123243, 0.011984535492956638, -0.06161431968212128, -0.00852531660348177, -0.04777698591351509, -0.030012736096978188, -0.11107282340526581, 0.048165418207645416, 0.03794120252132416, -0.002015262609347701, -0.04947056621313095, 0.04552575945854187, 0.02492445521056652, -0.08446133136749268, 0.009303836151957512, 0.007661385927349329, -0.01542503759264946, 0.003825932741165161, -0.010484534315764904, 0.0199525598436594, -0.042622651904821396, -0.015466364100575447, 0.0021294497419148684, 0.037303004413843155, 0.03193807974457741, -0.04476809874176979, -0.01701115258038044, 0.02929745428264141, -0.017499050125479698, 0.04704393818974495, -0.06535512953996658, -0.047415923327207565, 0.03444403037428856, 0.010298260487616062, 0.0005474408390000463, 0.07118160277605057, -0.03313145413994789, 0.020213117823004723, -0.009154395200312138, -0.02534209005534649, -0.01596258208155632, -0.0076247649267315865, -0.0382230319082737, -0.04542664438486099, 0.015000985935330391, 0.043037861585617065, 0.0270821675658226, 0.007128668017685413, -0.019959470257163048, -0.03867686167359352, 0.0027376553043723106, -0.06676984578371048, 0.03886379674077034, 0.008179198019206524, -0.04363008216023445, -0.006246343720704317, -0.0385037325322628, 0.005614868365228176, -0.07244493067264557, -0.02139868400990963, 0.040713854134082794, 0.037393879145383835, -0.02476504072546959, 0.04532892256975174, -0.0027360303793102503, -0.04400462657213211, -0.030838316306471825, -0.3542003929615021, -0.0406891405582428, 0.028521059080958366, 0.03612573817372322, 0.045811977237463, -0.10667970776557922, -0.03423625975847244, -0.0058470298536121845, 0.013044089078903198, -0.0021657885517925024, 0.04526408761739731, -0.023362310603260994, -0.015668241307139397, -0.05975186079740524, -0.0008557605906389654, 0.027602605521678925, -0.01450284756720066, -0.030184851959347725, -0.05467069149017334, 0.0075432779267430305, 0.03939189016819, -0.030713172629475594, -0.016166890040040016, -0.08816158771514893, 0.024646848440170288, 0.0093464320525527, 0.08570995181798935, -0.040873099118471146, 0.05881328508257866, -0.0015991540858522058, 0.05332544073462486, 0.005768988747149706, -0.00016635611245874316, -0.045292824506759644, 0.07033411413431168, -0.060608766973018646, 0.03561164438724518, 0.03644108027219772, 0.0020463252440094948, 0.030586540699005127, -0.02012849785387516, 0.007346043828874826, 0.04787961766123772, -0.03519758954644203, -0.07658762484788895, 0.049026213586330414, 0.01207743026316166, -0.05020930990576744, 0.02917061373591423, -0.0076680537313222885, 0.01733570359647274, 0.08227415382862091, 0.01225588470697403, -0.011928490363061428, -0.024363571777939796, -0.05772658437490463, -0.008889619261026382, -0.0171993225812912, -0.02826998196542263, -0.024523863568902016, 0.027616865932941437, 0.023238806053996086, 0.02163112722337246, -0.025146199390292168, -0.0042115445248782635, -0.013816186226904392, 0.02097226306796074, 0.029594242572784424, 0.03251735866069794, 0.03885847330093384, -0.07837319374084473, 0.08748739212751389, -0.02367842197418213, -0.007320931646972895, 0.05450296401977539, 0.019435562193393707, -0.067618727684021, 0.020184334367513657, -0.03152661398053169, -0.004233508370816708, 0.030160602182149887, -0.03918473422527313, 0.07048913836479187, 0.014456769451498985, 0.06982910633087158, 0.003406994976103306, 0.056424807757139206, -0.020569900050759315, 0.015351788140833378, 0.050795041024684906, -0.06968961656093597, -0.03358568996191025, -0.038412101566791534, 0.021695785224437714, 0.024774322286248207, -0.013750018551945686, -0.2613695561885834, 0.0005976290558464825, 0.012566071934998035, -0.005877388175576925, 0.014352072961628437, 0.00805998221039772, 0.034550368785858154, -0.04953932389616966, -0.02015695348381996, 0.021805064752697945, -0.00431250873953104, -0.027132920920848846, 0.027040917426347733, -0.03733052313327789, -0.03207965940237045, 0.013430340215563774, 0.1365189254283905, -0.04565461724996567, 0.022138109430670738, -0.02161228656768799, 0.023762619122862816, -0.02145644836127758, 0.19595125317573547, 0.036876995116472244, -0.027681903913617134, -0.08783849328756332, -0.034959230571985245, -0.0309344120323658, 0.07205655425786972, 0.009137026034295559, -0.009194289334118366, 0.01632642187178135, 0.10213049501180649, 0.031186863780021667, 0.043644651770591736, 0.01994483731687069, -0.04503672197461128, -0.017235271632671356, 0.013938807882368565, -0.0048654647544026375, 0.04809430614113808, 0.027548031881451607, -0.037966541945934296, -0.02652759850025177, 0.06218056380748749, -0.0068687261082232, -0.032138071954250336, -0.05547862499952316, -0.01962108723819256, 0.017482029274106026, 0.004668180365115404, 0.01384535152465105, -0.05033235251903534, -0.08323158323764801, 0.005667202640324831, -0.007271676789969206, -0.07034609466791153, -0.018591871485114098, 0.025227611884474754, 0.007522720377892256, 0.0041898139752447605, -0.010281786322593689, 0.0009697819477878511, -0.036352552473545074, 0.006309458054602146], '871193e4-41b7-40a4-81bb-f8551cafee12': [-0.10118597745895386, 0.045842189341783524, -0.0014804602833464742, -0.008100627921521664, 0.020490406081080437, 0.030237125232815742, -0.054710373282432556, -0.014051789417862892, 0.034659598022699356, 0.004066583700478077, -0.006399267818778753, -0.08731195330619812, 0.02612137794494629, 0.04317900910973549, -0.06473346054553986, -0.0062661622650921345, -0.07536423951387405, -0.0328209288418293, 0.017727959901094437, -0.03735746443271637, 0.05703315511345863, -0.03882819786667824, -0.04362408444285393, 0.03804045170545578, 0.004434226546436548, 0.03664890304207802, -0.013439232483506203, -0.04267576336860657, -0.02457769587635994, -0.21677592396736145, 0.012570182792842388, -0.07048244029283524, 0.019773440435528755, -0.034857191145420074, -0.01621861383318901, 0.05673880875110626, -0.018672941252589226, 0.017605314031243324, -0.03401578962802887, 0.05979844555258751, 0.022904226556420326, 0.04572535306215286, -0.02045455016195774, -0.02362641878426075, 0.014729716815054417, -0.02474081516265869, -0.033606965094804764, 0.005843729712069035, 0.0018316280329599977, 0.03693252056837082, -0.0016643527196720243, 0.0033055662643164396, 0.024384213611483574, 0.013599894009530544, -0.0005192747921682894, 0.0025890341494232416, 0.09753812104463577, 0.07413647323846817, 0.053570833057165146, -0.05172186344861984, -0.016669640317559242, 0.030819782987236977, -0.19377802312374115, 0.05361899361014366, -0.01700553297996521, 0.02300037071108818, -0.03999203070998192, -0.0411539264023304, -0.022424370050430298, 0.05700230598449707, -0.023486247286200523, -0.03340625390410423, 0.03816192224621773, 0.02953747659921646, 0.0038166050799191, 0.01729942299425602, 0.03011474944651127, 0.018064668402075768, 0.027778977528214455, -0.013323888182640076, 0.01694481633603573, 0.0066837421618402, 0.015348398126661777, -0.015743540599942207, 0.03699313476681709, -0.00862609501928091, 0.02319810725748539, 0.045895833522081375, -0.014087246730923653, 0.001428856048732996, -0.017114857211709023, -0.03242608904838562, -0.03236379474401474, 0.06294260919094086, -0.0414702482521534, -0.0367305651307106, 0.020075682550668716, 0.03652927279472351, -0.04216969758272171, 0.3458210527896881, -0.06997158378362656, 0.0016717774560675025, -0.05833149328827858, 0.02918868325650692, 0.008449990302324295, -0.07817376405000687, 0.019040048122406006, 0.014419219456613064, 0.003145012306049466, -0.023554304614663124, -0.03076283447444439, -0.011135871522128582, 0.05994269251823425, -0.06989037990570068, -0.035286907106637955, 0.026966722682118416, 0.053488489240407944, 0.006476024631410837, -0.02819625288248062, 0.050767410546541214, -0.008998224511742592, 0.0180747639387846, 0.055334966629743576, 0.028486017137765884, 0.03172547370195389, 0.033844657242298126, 0.08051379024982452, 0.06311684101819992, -0.005584596656262875, 0.029937131330370903, 0.03256504237651825, -0.02571372129023075, -0.0845700353384018, 0.018185146152973175, 0.021772757172584534, 0.029842818155884743, -0.0025943531654775143, -0.030828353017568588, -0.03301413357257843, -0.02769167535007, -0.024011624976992607, 0.009702581912279129, 0.012763199396431446, -0.00037086912197992206, -0.053837355226278305, 0.12135148793458939, 0.02392316423356533, -0.011626357212662697, -0.028403807431459427, -0.07033631205558777, 0.01465048361569643, 0.048962220549583435, 0.01217082142829895, -0.020179618149995804, 0.036191802471876144, 0.05873629450798035, 0.023077471181750298, -0.012673769146203995, -0.08043030649423599, -0.029040036723017693, -0.06935535371303558, -0.037289343774318695, 0.012407747097313404, 0.04749744012951851, -0.0027067146729677916, -0.026761474087834358, 0.01921543851494789, 0.030467022210359573, 0.044157300144433975, -0.04728904739022255, 0.03053409792482853, -0.008378175087273121, 0.0029071031603962183, -0.05347181111574173, 0.03432008624076843, -0.0027948429342359304, 0.0248051006346941, 0.01841755397617817, 0.0209072045981884, 0.03088005632162094, 0.029080267995595932, -0.04821653291583061, 0.019564032554626465, 0.02958311326801777, 0.028241537511348724, 0.04193134978413582, -0.03744086995720863, -0.04091719165444374, 0.017556944862008095, 0.017648935317993164, -0.03202417492866516, -0.04013403505086899, 0.0027653747238218784, 0.009482273831963539, -0.029051652178168297, -0.03508679196238518, -0.038896918296813965, 0.02730497717857361, -0.04267314076423645, 0.013136794790625572, 0.042663559317588806, 0.03424864634871483, 0.0009459051652811468, -0.024509770795702934, -0.00045670472900383174, 0.039554618299007416, -0.033214930444955826, -0.022085880860686302, 0.02334318868815899, 0.031027860939502716, -0.043749939650297165, -0.032652877271175385, 0.016197312623262405, -0.03012114018201828, 0.017326412722468376, -0.008576007559895515, 0.044092316180467606, 0.01362637709826231, -0.053658854216337204, 0.076816126704216, -0.029577478766441345, -0.03944014385342598, 0.008276550099253654, -0.3341507911682129, -0.043213147670030594, 0.01336091198027134, 0.020823990926146507, 0.09618581831455231, -0.0869506299495697, 0.00876527838408947, -0.017789168283343315, 0.03093438409268856, -0.012393172830343246, 0.07077104598283768, 0.026174310594797134, -0.019798245280981064, -0.10515963286161423, -0.0020028192084282637, 0.03812405839562416, 0.00014155312965158373, 0.01697712391614914, -0.04191941022872925, 0.016322853043675423, 0.010655119083821774, -0.016637995839118958, 0.04039672017097473, -0.09319532662630081, 0.022851979359984398, -0.02046559564769268, 0.14093858003616333, -0.07191195338964462, 0.07043373584747314, -0.03481354936957359, 0.021589817479252815, 0.04466135427355766, -0.011431318707764149, 0.009592873975634575, 0.0865955650806427, -0.09550432115793228, 0.03501884266734123, 0.046412792056798935, 0.04367484524846077, 0.013278970494866371, -0.021541470661759377, -0.011104957200586796, 0.08368782699108124, -0.05677763372659683, -0.02313842438161373, -0.017191488295793533, -0.012576916255056858, -0.0009472488309256732, -0.03371359035372734, -0.015045727603137493, 0.027596810832619667, -0.004040601197630167, 0.044795963913202286, -0.01628790609538555, -0.007661874871701002, -0.036986056715250015, -0.07994963228702545, 0.014885470271110535, -0.06257463246583939, -0.01915339007973671, -0.01981707476079464, -0.047478754073381424, 0.03673873096704483, -0.02659016288816929, 0.03691849112510681, -0.03603273630142212, 0.02132580243051052, 0.04195132106542587, 0.000917506986297667, 0.006861377041786909, -0.020269576460123062, 0.060633204877376556, -0.06925045698881149, -0.010324259288609028, 0.05762898176908493, 0.01440350990742445, -0.04277995973825455, 0.01552064623683691, -0.030609561130404472, 0.011672497726976871, -0.005238039884716272, -0.03749610483646393, 0.03538701310753822, 0.0852675810456276, 0.03157062828540802, -0.008946412242949009, 0.04429006949067116, 0.03576405346393585, 0.057802386581897736, 0.05542327091097832, -0.039812952280044556, -0.06641983240842819, 0.008585607632994652, 0.00031652688630856574, 0.04158349335193634, -0.01932508684694767, -0.2348010540008545, -0.04719321057200432, 0.05979576334357262, 0.06790542602539062, 0.025330711156129837, -0.048371609300374985, -0.014418612234294415, -0.031188692897558212, -0.013231300748884678, -0.05632776767015457, -0.08320341259241104, 0.07957830280065536, 0.047986891120672226, 0.001749012852087617, 0.015027866698801517, 0.02135118469595909, 0.06040283292531967, -0.03593886271119118, 0.024653825908899307, 0.020573340356349945, -0.03343445062637329, -0.00013111744192428887, 0.10061366856098175, -0.00443979213014245, -0.07966552674770355, 0.001768357353284955, -0.01890234276652336, -0.022314809262752533, 0.07650648057460785, 0.006233362015336752, 0.014536428265273571, 0.017020441591739655, 0.12012673914432526, 0.02610652521252632, -0.007581546436995268, 0.046242572367191315, -0.03596017509698868, 0.0139338793233037, 0.042942434549331665, 0.008706883527338505, 0.039580799639225006, 0.032008130103349686, -0.004308648407459259, -0.014916529878973961, 0.08661118894815445, -0.006726118270307779, -0.042745642364025116, -0.03202523663640022, -0.04822409152984619, -0.019167236983776093, -0.054611966013908386, 0.030997948721051216, -0.03420546278357506, -0.057274751365184784, -0.017727473750710487, 0.05874241143465042, 0.03361096978187561, -0.0020972229540348053, 0.018449701368808746, -0.009791858494281769, 0.02880680561065674, -0.05401680991053581, 0.07999546825885773, -0.05838383361697197, 0.010203187353909016]}, text_id_to_ref_doc_id={'7640c971-d974-4a3c-a75b-072b5008ec05': '7392c46d-5b4d-436e-a7c1-b3283f21c096', '04ccfe3c-9f63-4c80-afbd-de2a307aa69c': 'f648df64-0a96-4e99-a75f-bc250606c95f', '093521af-dd8f-4619-9022-e5eada65779a': '55b33995-c5a4-4fd0-b273-d624f524fe2b', 'e42b80bb-1d8a-4683-b0f2-cb990c8103d6': 'bad7ee9f-8397-49c7-aca1-22da2107d17c', 'cf0809ed-8cec-4993-b359-5f6dc8e9c4c1': '69a74af0-200c-4f3d-9995-8d9461dbe8b1', 'a210186a-4ca8-49b8-87e2-273595024777': '47440797-be04-4c3e-92bf-e6a0f1d16040', '3d199ae9-9787-41d4-bde5-efd220aee357': 'fa508c27-f9ab-4b63-8508-5a1baeb708c4', '3048529c-f4aa-4266-bd70-ef21f4f9bc47': '4f968278-465f-4073-9468-bc9beb3839bb', '92c049e4-0b98-4564-baf9-c63d186125b3': '8288ff90-f499-40b7-bfd9-55647dabd13e', '8476e1b3-b9cc-427f-bd26-dae9013263d4': '6ca99dcc-f0c1-49d3-8aeb-180b877f2a00', 'd844248f-f515-4da4-94e1-26e939335820': '772b9db4-473c-490d-b7bd-8dd33cf61f11', '1558bd5a-19c5-4ce9-8a51-a391588ddfcd': '4a2cda1d-1a27-48a1-ba21-2be43b90da91', 'fc731157-a527-4712-be13-e352c3567a31': '96b53d13-6ac1-40da-aa24-1f8afe0ecfcb', 'aed5196b-e68a-47f4-b9a8-f59785ccce55': 'b78ea85e-05c7-4b25-86fb-89793ca403c8', 'e6887d47-75c4-4050-8d98-53fe3e232c13': '28e732bb-d22b-47a5-b332-a8b6634faf14', '7a58867c-9dfd-4b7b-ac50-14bc9b1fdabc': 'e7020f88-8394-467b-9b6a-5c611ef616e2', '25439d0e-a06a-4b07-83e2-944bdca8690e': 'adbfeec2-5a5f-4ff4-9aef-1474496dc35e', '13e9062c-84eb-4aba-bde6-87032e8411c3': '10a790e5-5165-4b89-bd06-8e554e694b9d', 'c43d09d4-188a-436f-ac94-8d6ddef65372': '4611a9e2-15bf-402e-9373-af165e09db4c', 'cc8f10f8-93c8-45b1-8e96-909ea9271f51': '23cc4249-e09f-49b7-9dc6-02d5669dfc39', '8972e66c-a028-4e86-829c-ec2c5bf17daf': '1c34b811-bb5c-4b74-a7c8-5132e5f0fbd8', '542e88c8-14d9-4d10-962b-9b56f7afec3c': '523d422c-6f89-49f0-8548-2ceb6209177a', 'bc71aea8-4100-4845-bb25-59571125e140': 'f22d37ed-ada0-4778-9e4d-4588c832f236', '0b825b6d-a0c3-4b11-9f93-c4a863d4a2ea': '808a7ae9-6b1a-41ee-b194-63087b7fdcb7', '8081dad5-b35a-4ea0-83d0-9c803016a5de': '8805232e-3503-418b-b19e-e81313da17ec', '426f08c2-0273-418a-a0f0-3a6ee9a61fee': '35d354fc-bc8b-46b6-8c25-6bd0de7c4bbe', 'd3415939-c466-4dfe-9018-3d21344c007e': 'cbeecace-e833-4199-8735-5a0bb1513094', '9a70d22e-e788-4806-a617-3a8de5a3deb7': '6f3147e3-bb89-45f3-96da-190140a2d457', '636d12f6-e916-45b9-aa9f-bd3e3503851f': '729179ed-47b7-4fae-a665-f616a811afd9', '871193e4-41b7-40a4-81bb-f8551cafee12': '22ad2972-52c0-45df-9571-738f1682ff77'}, metadata_dict={'7640c971-d974-4a3c-a75b-072b5008ec05': {'page_label': '1', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '7392c46d-5b4d-436e-a7c1-b3283f21c096', 'doc_id': '7392c46d-5b4d-436e-a7c1-b3283f21c096', 'ref_doc_id': '7392c46d-5b4d-436e-a7c1-b3283f21c096'}, '04ccfe3c-9f63-4c80-afbd-de2a307aa69c': {'page_label': '2', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': 'f648df64-0a96-4e99-a75f-bc250606c95f', 'doc_id': 'f648df64-0a96-4e99-a75f-bc250606c95f', 'ref_doc_id': 'f648df64-0a96-4e99-a75f-bc250606c95f'}, '093521af-dd8f-4619-9022-e5eada65779a': {'page_label': '3', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '55b33995-c5a4-4fd0-b273-d624f524fe2b', 'doc_id': '55b33995-c5a4-4fd0-b273-d624f524fe2b', 'ref_doc_id': '55b33995-c5a4-4fd0-b273-d624f524fe2b'}, 'e42b80bb-1d8a-4683-b0f2-cb990c8103d6': {'page_label': '4', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': 'bad7ee9f-8397-49c7-aca1-22da2107d17c', 'doc_id': 'bad7ee9f-8397-49c7-aca1-22da2107d17c', 'ref_doc_id': 'bad7ee9f-8397-49c7-aca1-22da2107d17c'}, 'cf0809ed-8cec-4993-b359-5f6dc8e9c4c1': {'page_label': '5', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '69a74af0-200c-4f3d-9995-8d9461dbe8b1', 'doc_id': '69a74af0-200c-4f3d-9995-8d9461dbe8b1', 'ref_doc_id': '69a74af0-200c-4f3d-9995-8d9461dbe8b1'}, 'a210186a-4ca8-49b8-87e2-273595024777': {'page_label': '6', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '47440797-be04-4c3e-92bf-e6a0f1d16040', 'doc_id': '47440797-be04-4c3e-92bf-e6a0f1d16040', 'ref_doc_id': '47440797-be04-4c3e-92bf-e6a0f1d16040'}, '3d199ae9-9787-41d4-bde5-efd220aee357': {'page_label': '7', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': 'fa508c27-f9ab-4b63-8508-5a1baeb708c4', 'doc_id': 'fa508c27-f9ab-4b63-8508-5a1baeb708c4', 'ref_doc_id': 'fa508c27-f9ab-4b63-8508-5a1baeb708c4'}, '3048529c-f4aa-4266-bd70-ef21f4f9bc47': {'page_label': '8', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '4f968278-465f-4073-9468-bc9beb3839bb', 'doc_id': '4f968278-465f-4073-9468-bc9beb3839bb', 'ref_doc_id': '4f968278-465f-4073-9468-bc9beb3839bb'}, '92c049e4-0b98-4564-baf9-c63d186125b3': {'page_label': '9', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '8288ff90-f499-40b7-bfd9-55647dabd13e', 'doc_id': '8288ff90-f499-40b7-bfd9-55647dabd13e', 'ref_doc_id': '8288ff90-f499-40b7-bfd9-55647dabd13e'}, '8476e1b3-b9cc-427f-bd26-dae9013263d4': {'page_label': '10', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '6ca99dcc-f0c1-49d3-8aeb-180b877f2a00', 'doc_id': '6ca99dcc-f0c1-49d3-8aeb-180b877f2a00', 'ref_doc_id': '6ca99dcc-f0c1-49d3-8aeb-180b877f2a00'}, 'd844248f-f515-4da4-94e1-26e939335820': {'page_label': '11', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '772b9db4-473c-490d-b7bd-8dd33cf61f11', 'doc_id': '772b9db4-473c-490d-b7bd-8dd33cf61f11', 'ref_doc_id': '772b9db4-473c-490d-b7bd-8dd33cf61f11'}, '1558bd5a-19c5-4ce9-8a51-a391588ddfcd': {'page_label': '12', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '4a2cda1d-1a27-48a1-ba21-2be43b90da91', 'doc_id': '4a2cda1d-1a27-48a1-ba21-2be43b90da91', 'ref_doc_id': '4a2cda1d-1a27-48a1-ba21-2be43b90da91'}, 'fc731157-a527-4712-be13-e352c3567a31': {'page_label': '13', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '96b53d13-6ac1-40da-aa24-1f8afe0ecfcb', 'doc_id': '96b53d13-6ac1-40da-aa24-1f8afe0ecfcb', 'ref_doc_id': '96b53d13-6ac1-40da-aa24-1f8afe0ecfcb'}, 'aed5196b-e68a-47f4-b9a8-f59785ccce55': {'page_label': '14', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': 'b78ea85e-05c7-4b25-86fb-89793ca403c8', 'doc_id': 'b78ea85e-05c7-4b25-86fb-89793ca403c8', 'ref_doc_id': 'b78ea85e-05c7-4b25-86fb-89793ca403c8'}, 'e6887d47-75c4-4050-8d98-53fe3e232c13': {'page_label': '15', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '28e732bb-d22b-47a5-b332-a8b6634faf14', 'doc_id': '28e732bb-d22b-47a5-b332-a8b6634faf14', 'ref_doc_id': '28e732bb-d22b-47a5-b332-a8b6634faf14'}, '7a58867c-9dfd-4b7b-ac50-14bc9b1fdabc': {'page_label': '16', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': 'e7020f88-8394-467b-9b6a-5c611ef616e2', 'doc_id': 'e7020f88-8394-467b-9b6a-5c611ef616e2', 'ref_doc_id': 'e7020f88-8394-467b-9b6a-5c611ef616e2'}, '25439d0e-a06a-4b07-83e2-944bdca8690e': {'page_label': '17', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': 'adbfeec2-5a5f-4ff4-9aef-1474496dc35e', 'doc_id': 'adbfeec2-5a5f-4ff4-9aef-1474496dc35e', 'ref_doc_id': 'adbfeec2-5a5f-4ff4-9aef-1474496dc35e'}, '13e9062c-84eb-4aba-bde6-87032e8411c3': {'page_label': '18', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '10a790e5-5165-4b89-bd06-8e554e694b9d', 'doc_id': '10a790e5-5165-4b89-bd06-8e554e694b9d', 'ref_doc_id': '10a790e5-5165-4b89-bd06-8e554e694b9d'}, 'c43d09d4-188a-436f-ac94-8d6ddef65372': {'page_label': '19', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '4611a9e2-15bf-402e-9373-af165e09db4c', 'doc_id': '4611a9e2-15bf-402e-9373-af165e09db4c', 'ref_doc_id': '4611a9e2-15bf-402e-9373-af165e09db4c'}, 'cc8f10f8-93c8-45b1-8e96-909ea9271f51': {'page_label': '20', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '23cc4249-e09f-49b7-9dc6-02d5669dfc39', 'doc_id': '23cc4249-e09f-49b7-9dc6-02d5669dfc39', 'ref_doc_id': '23cc4249-e09f-49b7-9dc6-02d5669dfc39'}, '8972e66c-a028-4e86-829c-ec2c5bf17daf': {'page_label': '21', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '1c34b811-bb5c-4b74-a7c8-5132e5f0fbd8', 'doc_id': '1c34b811-bb5c-4b74-a7c8-5132e5f0fbd8', 'ref_doc_id': '1c34b811-bb5c-4b74-a7c8-5132e5f0fbd8'}, '542e88c8-14d9-4d10-962b-9b56f7afec3c': {'page_label': '22', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '523d422c-6f89-49f0-8548-2ceb6209177a', 'doc_id': '523d422c-6f89-49f0-8548-2ceb6209177a', 'ref_doc_id': '523d422c-6f89-49f0-8548-2ceb6209177a'}, 'bc71aea8-4100-4845-bb25-59571125e140': {'page_label': '23', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': 'f22d37ed-ada0-4778-9e4d-4588c832f236', 'doc_id': 'f22d37ed-ada0-4778-9e4d-4588c832f236', 'ref_doc_id': 'f22d37ed-ada0-4778-9e4d-4588c832f236'}, '0b825b6d-a0c3-4b11-9f93-c4a863d4a2ea': {'page_label': '24', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '808a7ae9-6b1a-41ee-b194-63087b7fdcb7', 'doc_id': '808a7ae9-6b1a-41ee-b194-63087b7fdcb7', 'ref_doc_id': '808a7ae9-6b1a-41ee-b194-63087b7fdcb7'}, '8081dad5-b35a-4ea0-83d0-9c803016a5de': {'page_label': '25', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '8805232e-3503-418b-b19e-e81313da17ec', 'doc_id': '8805232e-3503-418b-b19e-e81313da17ec', 'ref_doc_id': '8805232e-3503-418b-b19e-e81313da17ec'}, '426f08c2-0273-418a-a0f0-3a6ee9a61fee': {'page_label': '26', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '35d354fc-bc8b-46b6-8c25-6bd0de7c4bbe', 'doc_id': '35d354fc-bc8b-46b6-8c25-6bd0de7c4bbe', 'ref_doc_id': '35d354fc-bc8b-46b6-8c25-6bd0de7c4bbe'}, 'd3415939-c466-4dfe-9018-3d21344c007e': {'page_label': '27', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': 'cbeecace-e833-4199-8735-5a0bb1513094', 'doc_id': 'cbeecace-e833-4199-8735-5a0bb1513094', 'ref_doc_id': 'cbeecace-e833-4199-8735-5a0bb1513094'}, '9a70d22e-e788-4806-a617-3a8de5a3deb7': {'page_label': '28', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '6f3147e3-bb89-45f3-96da-190140a2d457', 'doc_id': '6f3147e3-bb89-45f3-96da-190140a2d457', 'ref_doc_id': '6f3147e3-bb89-45f3-96da-190140a2d457'}, '636d12f6-e916-45b9-aa9f-bd3e3503851f': {'page_label': '29', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '729179ed-47b7-4fae-a665-f616a811afd9', 'doc_id': '729179ed-47b7-4fae-a665-f616a811afd9', 'ref_doc_id': '729179ed-47b7-4fae-a665-f616a811afd9'}, '871193e4-41b7-40a4-81bb-f8551cafee12': {'page_label': '30', 'file_name': 'transformer.pdf', 'file_path': 'f:\\\\Llama_index_Project\\\\Study_Material\\\\..\\\\Study_Material\\\\data\\\\transformer.pdf', 'file_type': 'application/pdf', 'file_size': 4445724, 'creation_date': '2025-05-10', 'last_modified_date': '2025-02-02', '_node_type': 'TextNode', 'document_id': '22ad2972-52c0-45df-9571-738f1682ff77', 'doc_id': '22ad2972-52c0-45df-9571-738f1682ff77', 'ref_doc_id': '22ad2972-52c0-45df-9571-738f1682ff77'}})), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x000002B8201B6A80>, property_graph_store=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"../src/vdb\")\n",
    "storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x2b820126db0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the index from storage\n",
    "index = load_index_from_storage(storage_context)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever at 0x2b820343350>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Groq(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x000002B81967AAE0>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x000002B8001FCB80>, completion_to_prompt=<function default_completion_to_prompt at 0x000002B80081F420>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='llama3-70b-8192', temperature=0.1, max_tokens=None, logprobs=None, top_logprobs=0, additional_kwargs={}, max_retries=3, timeout=60.0, default_headers=None, reuse_client=True, api_key='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', api_base='https://api.groq.com/openai/v1', api_version='', strict=False, reasoning_effort=None, modalities=None, audio_config=None, context_window=3900, is_chat_model=True, is_function_calling_model=True, tokenizer=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "Settings.llm = Groq(model=\"llama3-70b-8192\")\n",
    "Settings.llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classic greeting! Hello World, indeed! It's great to have you on this platform. Is there something on your mind that you'd like to chat about, or are you just looking to explore and see what's out there? I'm here to help with any questions or topics you'd like to discuss!\n"
     ]
    }
   ],
   "source": [
    "response=Settings.llm.complete(\"Hello World!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine at 0x2b82017d8b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(llm=Settings.llm)\n",
    "response_synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x2b820007c80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine(retriever=retriever,response_synthesizer=response_synthesizer)\n",
    "query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Arrr, me hearty! Me name be Captain Zephyr \"Blackheart\" McSnively, the most feared and revered pirate to ever sail the seven seas! Me reputation precedes me, and me exploits be the stuff o' legend! Me ship, the \"Maverick's Revenge\", be me home, me pride, and me ticket to adventure and riches!\n",
      "\n",
      "Now, what be bringin' ye to these fair waters? Are ye lookin' to join me crew, or are ye lookin' to cross swords with the greatest pirate that ever lived? Either way, ye be in fer a wild ride!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "\n",
    "\n",
    "resp = Settings.llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The principle of a transformer is based on the concept of electromagnetic induction, which states that a changing magnetic field induces an electromotive force (EMF) in a conductor. The transformer works on the principle of mutual induction, where two coils are placed close to each other, and the magnetic field generated by one coil induces an EMF in the other coil.\n",
      "\n",
      "Here's a step-by-step explanation of the principle of a transformer:\n",
      "\n",
      "1. **Primary Coil**: The primary coil is connected to an AC power source, which causes an alternating current (AC) to flow through it. This creates a magnetic field around the primary coil.\n",
      "2. **Magnetic Field**: The magnetic field generated by the primary coil induces an electromotive force (EMF) in the secondary coil.\n",
      "3. **Secondary Coil**: The secondary coil is placed close to the primary coil, and the magnetic field generated by the primary coil induces an EMF in the secondary coil.\n",
      "4. **Induction**: The EMF induced in the secondary coil is proportional to the rate of change of the magnetic flux linking the secondary coil.\n",
      "5. **Transformer Action**: The EMF induced in the secondary coil causes a current to flow in the secondary circuit.\n",
      "6. **Step-up or Step-down**: Depending on the turns ratio of the primary and secondary coils, the transformer can either step-up or step-down the voltage.\n",
      "\n",
      "**Key Principles**:\n",
      "\n",
      "1. **Mutual Induction**: The transformer works on the principle of mutual induction, where the magnetic field generated by one coil induces an EMF in the other coil.\n",
      "2. **Electromagnetic Induction**: The transformer uses electromagnetic induction to transfer energy from the primary coil to the secondary coil.\n",
      "3. **Turns Ratio**: The turns ratio of the primary and secondary coils determines the voltage transformation ratio.\n",
      "4. **Step-up or Step-down**: The transformer can either step-up or step-down the voltage, depending on the turns ratio.\n",
      "\n",
      "**Advantages**:\n",
      "\n",
      "1. **Voltage Transformation**: The transformer can transform voltage levels, making it possible to transmit power over long distances with minimal loss of energy.\n",
      "2. **Isolation**: The transformer provides electrical isolation between the primary and secondary circuits, making it safe to use in applications where isolation is required.\n",
      "3. **Efficiency**: The transformer is a highly efficient device, with efficiencies ranging from 95% to 99%.\n",
      "\n",
      "In summary, the principle of a transformer is based on the concept of electromagnetic induction, where a changing magnetic field induces an EMF in a conductor. The transformer works on the principle of mutual induction, where two coils are placed close to each other, and the magnetic field generated by one coil induces an EMF in the other coil."
     ]
    }
   ],
   "source": [
    "response = Settings.llm.stream_complete(\"Principle of Transformer\")\n",
    "for r in response:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The principle of the Transformer is based on Self-Attention, which enables the model to focus on relevant tokens in the target sequence while ensuring that future tokens aren't attended to. Additionally, Cross-Attention allows the decoder to relevant parts of the source sequence, and the Feedforward Layer refines the representations of each token independently.\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "response = query_engine.query(\"Principle of Transformer\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What is a transformer model?\",\n",
    "    \"Explain the positional encoding in transformers\",\n",
    "    \"How does multi-head attention work?\",\n",
    "    \"What are the special tokens used in transformer models?\",\n",
    "    \"How is the vocabulary created for transformer models?\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
